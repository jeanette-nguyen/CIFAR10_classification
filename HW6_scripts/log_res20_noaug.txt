Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'resnet20'
Epoch: [0/80][0/250]	LR: 0.1	Time 1.272 (1.272)	Data 0.903 (0.903)	Loss 2.3536 (2.3536)	Prec@1 13.500 (13.500)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.032 (0.047)	Data 0.020 (0.029)	Loss 1.8039 (1.8043)	Prec@1 32.000 (31.371)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.033 (0.040)	Data 0.019 (0.025)	Loss 1.2127 (1.5933)	Prec@1 56.500 (40.294)
 * Training Prec@1 43.176
main.py:153: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.187 (0.187)	Loss 1.3249 (1.3249)	Prec@1 51.500 (51.500)
 * Testing Prec@1 51.270
main.py:190: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:191: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:199: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 0.446 (0.446)	Data 0.417 (0.417)	Loss 1.3079 (1.3079)	Prec@1 51.500 (51.500)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.029 (0.038)	Data 0.017 (0.025)	Loss 1.0502 (1.0969)	Prec@1 61.500 (60.411)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.021 (0.024)	Loss 0.8648 (1.0397)	Prec@1 65.000 (62.649)
 * Training Prec@1 63.440
Test: [0/50]	Time 0.624 (0.624)	Loss 1.2723 (1.2723)	Prec@1 59.500 (59.500)
 * Testing Prec@1 57.310
Epoch: [2/80][0/250]	LR: 0.1	Time 0.124 (0.124)	Data 0.105 (0.105)	Loss 0.8349 (0.8349)	Prec@1 73.500 (73.500)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.031 (0.070)	Data 0.019 (0.057)	Loss 0.7239 (0.8327)	Prec@1 74.500 (70.713)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.029 (0.053)	Data 0.018 (0.040)	Loss 0.6914 (0.8034)	Prec@1 75.000 (71.522)
 * Training Prec@1 72.166
Test: [0/50]	Time 0.625 (0.625)	Loss 0.8034 (0.8034)	Prec@1 71.000 (71.000)
 * Testing Prec@1 70.970
Epoch: [3/80][0/250]	LR: 0.1	Time 0.902 (0.902)	Data 0.882 (0.882)	Loss 0.7297 (0.7297)	Prec@1 73.500 (73.500)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.034 (0.052)	Data 0.021 (0.039)	Loss 0.6225 (0.6574)	Prec@1 80.500 (76.708)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.039 (0.043)	Data 0.022 (0.030)	Loss 0.7133 (0.6555)	Prec@1 75.000 (77.072)
 * Training Prec@1 77.220
Test: [0/50]	Time 0.815 (0.815)	Loss 0.6212 (0.6212)	Prec@1 78.500 (78.500)
 * Testing Prec@1 75.380
Epoch: [4/80][0/250]	LR: 0.1	Time 0.095 (0.095)	Data 0.076 (0.076)	Loss 0.4641 (0.4641)	Prec@1 84.000 (84.000)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.033 (0.045)	Data 0.021 (0.027)	Loss 0.5134 (0.5530)	Prec@1 81.500 (80.599)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.030 (0.041)	Data 0.016 (0.025)	Loss 0.5152 (0.5612)	Prec@1 79.500 (80.341)
 * Training Prec@1 80.352
Test: [0/50]	Time 0.238 (0.238)	Loss 0.7017 (0.7017)	Prec@1 78.000 (78.000)
 * Testing Prec@1 72.710
Epoch: [5/80][0/250]	LR: 0.1	Time 0.392 (0.392)	Data 0.367 (0.367)	Loss 0.4478 (0.4478)	Prec@1 85.000 (85.000)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.036 (0.064)	Data 0.022 (0.040)	Loss 0.4197 (0.4743)	Prec@1 84.500 (83.347)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.034 (0.054)	Data 0.020 (0.035)	Loss 0.5332 (0.4886)	Prec@1 81.000 (83.012)
 * Training Prec@1 82.858
Test: [0/50]	Time 0.139 (0.139)	Loss 0.5952 (0.5952)	Prec@1 80.500 (80.500)
 * Testing Prec@1 75.750
Epoch: [6/80][0/250]	LR: 0.1	Time 0.342 (0.342)	Data 0.321 (0.321)	Loss 0.3630 (0.3630)	Prec@1 88.000 (88.000)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.042 (0.036)	Data 0.028 (0.024)	Loss 0.5305 (0.4146)	Prec@1 80.000 (85.436)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.031 (0.036)	Data 0.018 (0.024)	Loss 0.4702 (0.4321)	Prec@1 83.000 (84.724)
 * Training Prec@1 84.580
Test: [0/50]	Time 0.254 (0.254)	Loss 0.6918 (0.6918)	Prec@1 79.500 (79.500)
 * Testing Prec@1 74.360
Epoch: [7/80][0/250]	LR: 0.1	Time 1.092 (1.092)	Data 1.065 (1.065)	Loss 0.3964 (0.3964)	Prec@1 86.000 (86.000)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.031 (0.067)	Data 0.018 (0.054)	Loss 0.4568 (0.3596)	Prec@1 83.500 (87.609)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.030 (0.079)	Data 0.018 (0.065)	Loss 0.4860 (0.3815)	Prec@1 83.000 (86.754)
 * Training Prec@1 86.490
Test: [0/50]	Time 1.736 (1.736)	Loss 0.6230 (0.6230)	Prec@1 79.000 (79.000)
 * Testing Prec@1 78.050
Epoch: [8/80][0/250]	LR: 0.1	Time 0.100 (0.100)	Data 0.076 (0.076)	Loss 0.2903 (0.2903)	Prec@1 90.000 (90.000)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.033 (0.034)	Data 0.022 (0.021)	Loss 0.2214 (0.3253)	Prec@1 94.000 (88.634)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.046 (0.038)	Data 0.033 (0.023)	Loss 0.3638 (0.3446)	Prec@1 86.000 (87.898)
 * Training Prec@1 87.622
Test: [0/50]	Time 0.823 (0.823)	Loss 0.6263 (0.6263)	Prec@1 81.500 (81.500)
 * Testing Prec@1 79.400
Epoch: [9/80][0/250]	LR: 0.1	Time 0.532 (0.532)	Data 0.505 (0.505)	Loss 0.3181 (0.3181)	Prec@1 90.500 (90.500)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.043 (0.044)	Data 0.030 (0.030)	Loss 0.3451 (0.2810)	Prec@1 87.000 (89.995)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.047 (0.067)	Data 0.032 (0.047)	Loss 0.2475 (0.3011)	Prec@1 92.000 (89.346)
 * Training Prec@1 89.012
Test: [0/50]	Time 0.788 (0.788)	Loss 0.7319 (0.7319)	Prec@1 78.000 (78.000)
 * Testing Prec@1 74.890
Epoch: [10/80][0/250]	LR: 0.1	Time 0.301 (0.301)	Data 0.283 (0.283)	Loss 0.3090 (0.3090)	Prec@1 90.000 (90.000)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.635 (0.058)	Data 0.623 (0.046)	Loss 0.4067 (0.2640)	Prec@1 86.000 (90.639)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.030 (0.054)	Data 0.017 (0.041)	Loss 0.2890 (0.2847)	Prec@1 89.000 (89.933)
 * Training Prec@1 89.680
Test: [0/50]	Time 0.638 (0.638)	Loss 0.5103 (0.5103)	Prec@1 81.500 (81.500)
 * Testing Prec@1 80.080
Epoch: [11/80][0/250]	LR: 0.1	Time 0.112 (0.112)	Data 0.090 (0.090)	Loss 0.2590 (0.2590)	Prec@1 90.500 (90.500)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.031 (0.033)	Data 0.018 (0.020)	Loss 0.2260 (0.2216)	Prec@1 92.000 (92.421)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.030 (0.033)	Data 0.018 (0.020)	Loss 0.2748 (0.2443)	Prec@1 91.000 (91.488)
 * Training Prec@1 91.116
Test: [0/50]	Time 0.566 (0.566)	Loss 0.9682 (0.9682)	Prec@1 74.500 (74.500)
 * Testing Prec@1 73.480
Epoch: [12/80][0/250]	LR: 0.1	Time 0.587 (0.587)	Data 0.565 (0.565)	Loss 0.2197 (0.2197)	Prec@1 92.000 (92.000)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.030 (0.047)	Data 0.018 (0.034)	Loss 0.2140 (0.2021)	Prec@1 93.500 (92.941)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.036 (0.073)	Data 0.023 (0.047)	Loss 0.2706 (0.2251)	Prec@1 90.000 (92.062)
 * Training Prec@1 91.652
Test: [0/50]	Time 1.262 (1.262)	Loss 0.7239 (0.7239)	Prec@1 80.500 (80.500)
 * Testing Prec@1 78.720
Epoch: [13/80][0/250]	LR: 0.1	Time 0.126 (0.126)	Data 0.103 (0.103)	Loss 0.2037 (0.2037)	Prec@1 92.000 (92.000)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.032 (0.067)	Data 0.021 (0.045)	Loss 0.2294 (0.1763)	Prec@1 92.500 (93.936)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.029 (0.082)	Data 0.018 (0.060)	Loss 0.2736 (0.2020)	Prec@1 90.000 (92.930)
 * Training Prec@1 92.576
Test: [0/50]	Time 1.091 (1.091)	Loss 0.7649 (0.7649)	Prec@1 77.500 (77.500)
 * Testing Prec@1 78.250
Epoch: [14/80][0/250]	LR: 0.1	Time 0.520 (0.520)	Data 0.498 (0.498)	Loss 0.1256 (0.1256)	Prec@1 95.500 (95.500)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.030 (0.049)	Data 0.017 (0.036)	Loss 0.2107 (0.1685)	Prec@1 91.000 (94.228)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.033 (0.041)	Data 0.021 (0.029)	Loss 0.2429 (0.1897)	Prec@1 91.500 (93.274)
 * Training Prec@1 92.880
Test: [0/50]	Time 0.234 (0.234)	Loss 0.8090 (0.8090)	Prec@1 78.500 (78.500)
 * Testing Prec@1 73.640
Epoch: [15/80][0/250]	LR: 0.1	Time 1.393 (1.393)	Data 1.369 (1.369)	Loss 0.1814 (0.1814)	Prec@1 94.000 (94.000)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.029 (0.048)	Data 0.018 (0.035)	Loss 0.1176 (0.1627)	Prec@1 96.000 (94.277)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.033 (0.041)	Data 0.020 (0.028)	Loss 0.1789 (0.1701)	Prec@1 94.000 (94.012)
 * Training Prec@1 93.782
Test: [0/50]	Time 0.179 (0.179)	Loss 0.8502 (0.8502)	Prec@1 76.500 (76.500)
 * Testing Prec@1 76.120
Epoch: [16/80][0/250]	LR: 0.1	Time 0.379 (0.379)	Data 0.359 (0.359)	Loss 0.1555 (0.1555)	Prec@1 95.500 (95.500)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.034 (0.049)	Data 0.022 (0.036)	Loss 0.1085 (0.1522)	Prec@1 97.000 (94.604)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.043 (0.070)	Data 0.030 (0.057)	Loss 0.1767 (0.1647)	Prec@1 93.000 (94.177)
 * Training Prec@1 93.958
Test: [0/50]	Time 0.629 (0.629)	Loss 0.7500 (0.7500)	Prec@1 78.500 (78.500)
 * Testing Prec@1 77.450
Epoch: [17/80][0/250]	LR: 0.1	Time 1.035 (1.035)	Data 1.016 (1.016)	Loss 0.0862 (0.0862)	Prec@1 97.500 (97.500)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.049 (0.062)	Data 0.037 (0.048)	Loss 0.2354 (0.1259)	Prec@1 91.000 (95.604)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.035 (0.065)	Data 0.023 (0.042)	Loss 0.3407 (0.1504)	Prec@1 87.500 (94.659)
 * Training Prec@1 94.364
Test: [0/50]	Time 0.457 (0.457)	Loss 0.5480 (0.5480)	Prec@1 82.500 (82.500)
 * Testing Prec@1 77.270
Epoch: [18/80][0/250]	LR: 0.1	Time 0.128 (0.128)	Data 0.108 (0.108)	Loss 0.1493 (0.1493)	Prec@1 95.500 (95.500)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.029 (0.060)	Data 0.017 (0.047)	Loss 0.1553 (0.1164)	Prec@1 93.000 (96.040)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.033 (0.049)	Data 0.021 (0.036)	Loss 0.1107 (0.1286)	Prec@1 96.000 (95.507)
 * Training Prec@1 95.088
Test: [0/50]	Time 0.375 (0.375)	Loss 0.8866 (0.8866)	Prec@1 80.500 (80.500)
 * Testing Prec@1 76.190
Epoch: [19/80][0/250]	LR: 0.1	Time 0.431 (0.431)	Data 0.408 (0.408)	Loss 0.1177 (0.1177)	Prec@1 96.500 (96.500)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.033 (0.092)	Data 0.017 (0.079)	Loss 0.1157 (0.1220)	Prec@1 96.000 (95.777)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.031 (0.073)	Data 0.018 (0.059)	Loss 0.1717 (0.1261)	Prec@1 94.500 (95.488)
 * Training Prec@1 95.228
Test: [0/50]	Time 0.296 (0.296)	Loss 1.0687 (1.0687)	Prec@1 77.000 (77.000)
 * Testing Prec@1 74.060
Epoch: [20/80][0/250]	LR: 0.1	Time 1.425 (1.425)	Data 1.406 (1.406)	Loss 0.0914 (0.0914)	Prec@1 97.500 (97.500)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.033 (0.082)	Data 0.020 (0.069)	Loss 0.2212 (0.1313)	Prec@1 93.500 (95.351)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.031 (0.059)	Data 0.018 (0.046)	Loss 0.1301 (0.1327)	Prec@1 94.500 (95.219)
 * Training Prec@1 95.148
Test: [0/50]	Time 0.144 (0.144)	Loss 0.7876 (0.7876)	Prec@1 78.000 (78.000)
 * Testing Prec@1 76.410
Epoch: [21/80][0/250]	LR: 0.1	Time 0.931 (0.931)	Data 0.909 (0.909)	Loss 0.1213 (0.1213)	Prec@1 96.500 (96.500)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.038 (0.043)	Data 0.026 (0.031)	Loss 0.1396 (0.0969)	Prec@1 94.500 (96.564)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.031 (0.039)	Data 0.018 (0.026)	Loss 0.1701 (0.1123)	Prec@1 94.500 (96.027)
 * Training Prec@1 95.802
Test: [0/50]	Time 0.818 (0.818)	Loss 0.7353 (0.7353)	Prec@1 79.000 (79.000)
 * Testing Prec@1 77.710
Epoch: [22/80][0/250]	LR: 0.1	Time 0.514 (0.514)	Data 0.494 (0.494)	Loss 0.0834 (0.0834)	Prec@1 97.500 (97.500)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.030 (0.063)	Data 0.018 (0.040)	Loss 0.0724 (0.0936)	Prec@1 97.000 (96.748)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.037 (0.058)	Data 0.024 (0.041)	Loss 0.1235 (0.1032)	Prec@1 96.500 (96.346)
 * Training Prec@1 96.088
Test: [0/50]	Time 0.197 (0.197)	Loss 0.8949 (0.8949)	Prec@1 78.000 (78.000)
 * Testing Prec@1 77.210
Epoch: [23/80][0/250]	LR: 0.1	Time 0.726 (0.726)	Data 0.704 (0.704)	Loss 0.0651 (0.0651)	Prec@1 97.500 (97.500)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.031 (0.102)	Data 0.018 (0.089)	Loss 0.0826 (0.0997)	Prec@1 98.000 (96.485)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.042 (0.069)	Data 0.031 (0.056)	Loss 0.1222 (0.1062)	Prec@1 96.500 (96.244)
 * Training Prec@1 96.020
Test: [0/50]	Time 1.441 (1.441)	Loss 1.1052 (1.1052)	Prec@1 76.000 (76.000)
 * Testing Prec@1 75.410
Epoch: [24/80][0/250]	LR: 0.1	Time 0.092 (0.092)	Data 0.067 (0.067)	Loss 0.0729 (0.0729)	Prec@1 96.500 (96.500)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.048 (0.049)	Data 0.029 (0.035)	Loss 0.2119 (0.0979)	Prec@1 93.500 (96.455)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.031 (0.042)	Data 0.019 (0.028)	Loss 0.0602 (0.0983)	Prec@1 97.500 (96.475)
 * Training Prec@1 96.314
Test: [0/50]	Time 0.321 (0.321)	Loss 0.8529 (0.8529)	Prec@1 76.000 (76.000)
 * Testing Prec@1 76.750
Epoch: [25/80][0/250]	LR: 0.1	Time 0.542 (0.542)	Data 0.520 (0.520)	Loss 0.0649 (0.0649)	Prec@1 98.500 (98.500)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.032 (0.042)	Data 0.020 (0.028)	Loss 0.0646 (0.0902)	Prec@1 97.500 (96.748)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.084 (0.038)	Data 0.022 (0.025)	Loss 0.0944 (0.1112)	Prec@1 98.500 (96.002)
 * Training Prec@1 95.824
Test: [0/50]	Time 0.545 (0.545)	Loss 0.9284 (0.9284)	Prec@1 77.000 (77.000)
 * Testing Prec@1 77.320
Epoch: [26/80][0/250]	LR: 0.1	Time 0.115 (0.115)	Data 0.093 (0.093)	Loss 0.1170 (0.1170)	Prec@1 95.000 (95.000)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.035 (0.052)	Data 0.022 (0.033)	Loss 0.0410 (0.0778)	Prec@1 99.000 (97.277)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.047 (0.059)	Data 0.033 (0.041)	Loss 0.1115 (0.0857)	Prec@1 96.000 (96.928)
 * Training Prec@1 96.826
Test: [0/50]	Time 0.195 (0.195)	Loss 1.0440 (1.0440)	Prec@1 79.000 (79.000)
 * Testing Prec@1 78.170
Epoch: [27/80][0/250]	LR: 0.1	Time 0.155 (0.155)	Data 0.123 (0.123)	Loss 0.0786 (0.0786)	Prec@1 97.000 (97.000)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.033 (0.056)	Data 0.021 (0.042)	Loss 0.0825 (0.0766)	Prec@1 96.500 (97.332)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.031 (0.045)	Data 0.018 (0.032)	Loss 0.0892 (0.0866)	Prec@1 98.000 (97.002)
 * Training Prec@1 96.840
Test: [0/50]	Time 0.225 (0.225)	Loss 0.8747 (0.8747)	Prec@1 76.500 (76.500)
 * Testing Prec@1 77.160
Epoch: [28/80][0/250]	LR: 0.1	Time 0.348 (0.348)	Data 0.325 (0.325)	Loss 0.0634 (0.0634)	Prec@1 98.500 (98.500)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.037 (0.055)	Data 0.022 (0.041)	Loss 0.0473 (0.0695)	Prec@1 98.000 (97.748)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.035 (0.065)	Data 0.018 (0.046)	Loss 0.1300 (0.0768)	Prec@1 94.000 (97.378)
 * Training Prec@1 97.238
Test: [0/50]	Time 0.193 (0.193)	Loss 0.8132 (0.8132)	Prec@1 82.000 (82.000)
 * Testing Prec@1 79.850
Epoch: [29/80][0/250]	LR: 0.1	Time 0.533 (0.533)	Data 0.513 (0.513)	Loss 0.0856 (0.0856)	Prec@1 97.000 (97.000)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.030 (0.061)	Data 0.018 (0.047)	Loss 0.0835 (0.0703)	Prec@1 97.000 (97.614)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.034 (0.049)	Data 0.020 (0.035)	Loss 0.1343 (0.0905)	Prec@1 94.000 (96.811)
 * Training Prec@1 96.568
Test: [0/50]	Time 1.328 (1.328)	Loss 0.6862 (0.6862)	Prec@1 83.500 (83.500)
 * Testing Prec@1 79.880
Epoch: [30/80][0/250]	LR: 0.1	Time 0.992 (0.992)	Data 0.970 (0.970)	Loss 0.0784 (0.0784)	Prec@1 97.000 (97.000)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.030 (0.043)	Data 0.017 (0.030)	Loss 0.0402 (0.0817)	Prec@1 99.500 (97.124)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.032 (0.039)	Data 0.019 (0.025)	Loss 0.0444 (0.0847)	Prec@1 98.500 (96.983)
 * Training Prec@1 96.920
Test: [0/50]	Time 0.768 (0.768)	Loss 0.8891 (0.8891)	Prec@1 79.500 (79.500)
 * Testing Prec@1 80.500
Epoch: [31/80][0/250]	LR: 0.1	Time 0.395 (0.395)	Data 0.377 (0.377)	Loss 0.0937 (0.0937)	Prec@1 96.500 (96.500)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.042 (0.045)	Data 0.026 (0.032)	Loss 0.0452 (0.0649)	Prec@1 97.500 (97.837)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.031 (0.046)	Data 0.018 (0.033)	Loss 0.0691 (0.0739)	Prec@1 98.000 (97.396)
 * Training Prec@1 97.120
Test: [0/50]	Time 0.160 (0.160)	Loss 0.9033 (0.9033)	Prec@1 79.000 (79.000)
 * Testing Prec@1 79.780
Epoch: [32/80][0/250]	LR: 0.1	Time 0.098 (0.098)	Data 0.073 (0.073)	Loss 0.0667 (0.0667)	Prec@1 97.000 (97.000)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.033 (0.039)	Data 0.021 (0.026)	Loss 0.0646 (0.0706)	Prec@1 97.500 (97.515)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.036 (0.052)	Data 0.022 (0.039)	Loss 0.0958 (0.0750)	Prec@1 97.500 (97.343)
 * Training Prec@1 97.174
Test: [0/50]	Time 0.568 (0.568)	Loss 1.0399 (1.0399)	Prec@1 80.500 (80.500)
 * Testing Prec@1 78.690
Epoch: [33/80][0/250]	LR: 0.1	Time 1.204 (1.204)	Data 1.183 (1.183)	Loss 0.0402 (0.0402)	Prec@1 98.500 (98.500)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.030 (0.045)	Data 0.019 (0.032)	Loss 0.1307 (0.0715)	Prec@1 95.500 (97.446)
Epoch: [33/80][200/250]	LR: 0.1	Time 1.128 (0.056)	Data 1.109 (0.043)	Loss 0.1437 (0.0764)	Prec@1 95.500 (97.279)
 * Training Prec@1 97.102
Test: [0/50]	Time 0.303 (0.303)	Loss 0.8987 (0.8987)	Prec@1 79.500 (79.500)
 * Testing Prec@1 80.810
Epoch: [34/80][0/250]	LR: 0.1	Time 0.591 (0.591)	Data 0.568 (0.568)	Loss 0.0900 (0.0900)	Prec@1 98.500 (98.500)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.029 (0.062)	Data 0.017 (0.049)	Loss 0.0456 (0.0792)	Prec@1 98.000 (97.233)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.033 (0.048)	Data 0.020 (0.035)	Loss 0.1069 (0.0835)	Prec@1 95.000 (97.045)
 * Training Prec@1 96.762
Test: [0/50]	Time 0.618 (0.618)	Loss 1.0164 (1.0164)	Prec@1 78.500 (78.500)
 * Testing Prec@1 77.600
Epoch: [35/80][0/250]	LR: 0.1	Time 0.832 (0.832)	Data 0.812 (0.812)	Loss 0.1335 (0.1335)	Prec@1 95.000 (95.000)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.035 (0.042)	Data 0.021 (0.029)	Loss 0.0626 (0.0848)	Prec@1 98.500 (96.990)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.031 (0.038)	Data 0.019 (0.025)	Loss 0.0879 (0.0767)	Prec@1 96.000 (97.289)
 * Training Prec@1 97.130
Test: [0/50]	Time 0.176 (0.176)	Loss 0.8583 (0.8583)	Prec@1 78.000 (78.000)
 * Testing Prec@1 79.430
Epoch: [36/80][0/250]	LR: 0.1	Time 0.468 (0.468)	Data 0.447 (0.447)	Loss 0.0759 (0.0759)	Prec@1 97.000 (97.000)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.037 (0.038)	Data 0.025 (0.025)	Loss 0.0268 (0.0622)	Prec@1 99.000 (97.847)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.022 (0.023)	Loss 0.0610 (0.0660)	Prec@1 97.500 (97.749)
 * Training Prec@1 97.526
Test: [0/50]	Time 0.110 (0.110)	Loss 0.8688 (0.8688)	Prec@1 82.500 (82.500)
 * Testing Prec@1 80.460
Epoch: [37/80][0/250]	LR: 0.1	Time 0.104 (0.104)	Data 0.072 (0.072)	Loss 0.0183 (0.0183)	Prec@1 100.000 (100.000)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.030 (0.035)	Data 0.018 (0.022)	Loss 0.0620 (0.0833)	Prec@1 97.500 (97.109)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.055 (0.035)	Data 0.043 (0.022)	Loss 0.1015 (0.0836)	Prec@1 95.500 (96.955)
 * Training Prec@1 96.916
Test: [0/50]	Time 0.667 (0.667)	Loss 0.8400 (0.8400)	Prec@1 79.000 (79.000)
 * Testing Prec@1 80.310
Epoch: [38/80][0/250]	LR: 0.1	Time 1.469 (1.469)	Data 0.166 (0.166)	Loss 0.0355 (0.0355)	Prec@1 98.500 (98.500)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.031 (0.086)	Data 0.018 (0.043)	Loss 0.0623 (0.0545)	Prec@1 98.000 (98.173)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.036 (0.059)	Data 0.023 (0.031)	Loss 0.0915 (0.0634)	Prec@1 97.500 (97.811)
 * Training Prec@1 97.586
Test: [0/50]	Time 0.647 (0.647)	Loss 1.0126 (1.0126)	Prec@1 77.000 (77.000)
 * Testing Prec@1 78.250
Epoch: [39/80][0/250]	LR: 0.1	Time 0.408 (0.408)	Data 0.382 (0.382)	Loss 0.0849 (0.0849)	Prec@1 96.500 (96.500)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.038 (0.040)	Data 0.021 (0.027)	Loss 0.0926 (0.0692)	Prec@1 96.500 (97.564)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.033 (0.037)	Data 0.020 (0.024)	Loss 0.0518 (0.0734)	Prec@1 97.500 (97.443)
 * Training Prec@1 97.356
Test: [0/50]	Time 0.685 (0.685)	Loss 0.7602 (0.7602)	Prec@1 82.000 (82.000)
 * Testing Prec@1 81.130
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.093 (0.093)	Data 0.071 (0.071)	Loss 0.0493 (0.0493)	Prec@1 97.500 (97.500)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.035)	Data 0.023 (0.021)	Loss 0.0113 (0.0347)	Prec@1 100.000 (98.916)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.039)	Data 0.023 (0.026)	Loss 0.0078 (0.0276)	Prec@1 100.000 (99.209)
 * Training Prec@1 99.278
Test: [0/50]	Time 0.170 (0.170)	Loss 0.6423 (0.6423)	Prec@1 85.000 (85.000)
 * Testing Prec@1 83.570
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.091 (0.091)	Data 0.073 (0.073)	Loss 0.0147 (0.0147)	Prec@1 100.000 (100.000)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.033 (0.039)	Data 0.021 (0.026)	Loss 0.0109 (0.0088)	Prec@1 99.500 (99.906)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.036)	Data 0.025 (0.024)	Loss 0.0118 (0.0087)	Prec@1 100.000 (99.913)
 * Training Prec@1 99.900
Test: [0/50]	Time 0.447 (0.447)	Loss 0.6508 (0.6508)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.780
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.154 (0.154)	Data 0.132 (0.132)	Loss 0.0076 (0.0076)	Prec@1 100.000 (100.000)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.043 (0.035)	Data 0.032 (0.022)	Loss 0.0067 (0.0064)	Prec@1 100.000 (99.975)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.034)	Data 0.021 (0.022)	Loss 0.0037 (0.0063)	Prec@1 100.000 (99.970)
 * Training Prec@1 99.968
Test: [0/50]	Time 0.813 (0.813)	Loss 0.6602 (0.6602)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.860
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.226 (0.226)	Data 0.202 (0.202)	Loss 0.0045 (0.0045)	Prec@1 100.000 (100.000)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.034 (0.038)	Data 0.022 (0.025)	Loss 0.0030 (0.0051)	Prec@1 100.000 (99.995)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.040 (0.044)	Data 0.024 (0.031)	Loss 0.0059 (0.0051)	Prec@1 100.000 (99.990)
 * Training Prec@1 99.986
Test: [0/50]	Time 0.834 (0.834)	Loss 0.6553 (0.6553)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.850
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.130 (0.130)	Data 0.102 (0.102)	Loss 0.0045 (0.0045)	Prec@1 100.000 (100.000)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.033 (0.034)	Data 0.020 (0.021)	Loss 0.0055 (0.0040)	Prec@1 100.000 (99.995)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.019 (0.036)	Data 0.007 (0.023)	Loss 0.0030 (0.0040)	Prec@1 100.000 (99.993)
 * Training Prec@1 99.992
Test: [0/50]	Time 1.927 (1.927)	Loss 0.6724 (0.6724)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.840
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.748 (0.748)	Data 0.724 (0.724)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.030 (0.041)	Data 0.017 (0.028)	Loss 0.0034 (0.0037)	Prec@1 100.000 (99.995)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.031 (0.050)	Data 0.019 (0.025)	Loss 0.0038 (0.0038)	Prec@1 100.000 (99.990)
 * Training Prec@1 99.990
Test: [0/50]	Time 0.147 (0.147)	Loss 0.6951 (0.6951)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.810
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.577 (0.577)	Data 0.558 (0.558)	Loss 0.0033 (0.0033)	Prec@1 100.000 (100.000)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.030 (0.051)	Data 0.018 (0.038)	Loss 0.0028 (0.0031)	Prec@1 100.000 (100.000)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.046)	Data 0.021 (0.033)	Loss 0.0042 (0.0032)	Prec@1 100.000 (99.998)
 * Training Prec@1 99.998
Test: [0/50]	Time 0.552 (0.552)	Loss 0.6775 (0.6775)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.830
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 0.558 (0.558)	Data 0.537 (0.537)	Loss 0.0028 (0.0028)	Prec@1 100.000 (100.000)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.038)	Data 0.023 (0.025)	Loss 0.0032 (0.0031)	Prec@1 100.000 (99.995)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.030 (0.079)	Data 0.019 (0.055)	Loss 0.0022 (0.0030)	Prec@1 100.000 (99.998)
 * Training Prec@1 99.998
Test: [0/50]	Time 1.364 (1.364)	Loss 0.6647 (0.6647)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.920
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.103 (0.103)	Data 0.075 (0.075)	Loss 0.0028 (0.0028)	Prec@1 100.000 (100.000)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.034 (0.047)	Data 0.021 (0.027)	Loss 0.0026 (0.0026)	Prec@1 100.000 (100.000)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.031 (0.046)	Data 0.019 (0.025)	Loss 0.0037 (0.0027)	Prec@1 100.000 (99.998)
 * Training Prec@1 99.998
Test: [0/50]	Time 0.580 (0.580)	Loss 0.6845 (0.6845)	Prec@1 85.000 (85.000)
 * Testing Prec@1 83.910
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.099 (0.099)	Data 0.070 (0.070)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.033)	Data 0.023 (0.020)	Loss 0.0027 (0.0029)	Prec@1 100.000 (99.985)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.034)	Data 0.026 (0.020)	Loss 0.0020 (0.0027)	Prec@1 100.000 (99.993)
 * Training Prec@1 99.994
Test: [0/50]	Time 0.328 (0.328)	Loss 0.6758 (0.6758)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.930
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.130 (0.130)	Data 0.107 (0.107)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.031 (0.035)	Data 0.019 (0.022)	Loss 0.0028 (0.0024)	Prec@1 100.000 (100.000)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.030 (0.034)	Data 0.018 (0.021)	Loss 0.0020 (0.0023)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.300 (0.300)	Loss 0.6857 (0.6857)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.950
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 1.405 (1.405)	Data 1.386 (1.386)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.032 (0.077)	Data 0.020 (0.064)	Loss 0.0015 (0.0024)	Prec@1 100.000 (100.000)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.034 (0.057)	Data 0.020 (0.044)	Loss 0.0029 (0.0022)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.111 (0.111)	Loss 0.6931 (0.6931)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.800
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.574 (0.574)	Data 0.551 (0.551)	Loss 0.0022 (0.0022)	Prec@1 100.000 (100.000)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.034 (0.074)	Data 0.021 (0.061)	Loss 0.0030 (0.0021)	Prec@1 100.000 (100.000)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.043 (0.082)	Data 0.031 (0.070)	Loss 0.0014 (0.0021)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.127 (0.127)	Loss 0.7018 (0.7018)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.890
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 1.554 (1.554)	Data 1.531 (1.531)	Loss 0.0020 (0.0020)	Prec@1 100.000 (100.000)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.033 (0.049)	Data 0.020 (0.036)	Loss 0.0027 (0.0020)	Prec@1 100.000 (100.000)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.048 (0.041)	Data 0.032 (0.028)	Loss 0.0011 (0.0021)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.106 (0.106)	Loss 0.6985 (0.6985)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.860
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.282 (0.282)	Data 0.263 (0.263)	Loss 0.0036 (0.0036)	Prec@1 100.000 (100.000)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.066)	Data 0.025 (0.040)	Loss 0.0010 (0.0019)	Prec@1 100.000 (100.000)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.057)	Data 0.025 (0.034)	Loss 0.0018 (0.0019)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.782 (0.782)	Loss 0.7069 (0.7069)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.950
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.590 (0.590)	Data 0.569 (0.569)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.038 (0.047)	Data 0.024 (0.034)	Loss 0.0017 (0.0018)	Prec@1 100.000 (100.000)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.032 (0.051)	Data 0.020 (0.038)	Loss 0.0007 (0.0018)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.411 (0.411)	Loss 0.6998 (0.6998)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.940
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.108 (0.108)	Data 0.078 (0.078)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.034)	Data 0.023 (0.021)	Loss 0.0013 (0.0018)	Prec@1 100.000 (100.000)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.034)	Data 0.016 (0.021)	Loss 0.0009 (0.0018)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.343 (0.343)	Loss 0.7163 (0.7163)	Prec@1 83.000 (83.000)
 * Testing Prec@1 83.770
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.312 (0.312)	Data 0.290 (0.290)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.030 (0.051)	Data 0.017 (0.038)	Loss 0.0014 (0.0018)	Prec@1 100.000 (100.000)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.057 (0.045)	Data 0.045 (0.031)	Loss 0.0016 (0.0018)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 1.485 (1.485)	Loss 0.6989 (0.6989)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.050
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.252 (0.252)	Data 0.233 (0.233)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.044 (0.036)	Data 0.032 (0.024)	Loss 0.0018 (0.0017)	Prec@1 100.000 (100.000)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.044 (0.036)	Data 0.030 (0.023)	Loss 0.0015 (0.0017)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.559 (0.559)	Loss 0.7166 (0.7166)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.890
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.518 (0.518)	Data 0.493 (0.493)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.032 (0.045)	Data 0.021 (0.032)	Loss 0.0014 (0.0017)	Prec@1 100.000 (100.000)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.034 (0.040)	Data 0.023 (0.027)	Loss 0.0019 (0.0017)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.330 (0.330)	Loss 0.6915 (0.6915)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.910
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.160 (0.160)	Data 0.136 (0.136)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.044)	Data 0.022 (0.031)	Loss 0.0041 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.035 (0.053)	Data 0.022 (0.036)	Loss 0.0013 (0.0016)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.448 (0.448)	Loss 0.6993 (0.6993)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.940
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.551 (0.551)	Data 0.530 (0.530)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.031 (0.045)	Data 0.018 (0.032)	Loss 0.0011 (0.0018)	Prec@1 100.000 (99.995)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.032 (0.051)	Data 0.021 (0.037)	Loss 0.0011 (0.0017)	Prec@1 100.000 (99.998)
 * Training Prec@1 99.998
Test: [0/50]	Time 0.205 (0.205)	Loss 0.6842 (0.6842)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.000
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.346 (0.346)	Data 0.323 (0.323)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.032 (0.037)	Data 0.018 (0.024)	Loss 0.0018 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.032 (0.035)	Data 0.019 (0.022)	Loss 0.0024 (0.0015)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.624 (0.624)	Loss 0.7039 (0.7039)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.030
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 1.342 (1.342)	Data 1.308 (1.308)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.079)	Data 0.015 (0.065)	Loss 0.0011 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.064)	Data 0.022 (0.051)	Loss 0.0010 (0.0016)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 1.080 (1.080)	Loss 0.7018 (0.7018)	Prec@1 83.500 (83.500)
 * Testing Prec@1 84.030
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 1.028 (1.028)	Data 1.008 (1.008)	Loss 0.0031 (0.0031)	Prec@1 100.000 (100.000)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.032 (0.063)	Data 0.021 (0.039)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.031 (0.048)	Data 0.019 (0.029)	Loss 0.0015 (0.0017)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.601 (0.601)	Loss 0.6885 (0.6885)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.980
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.176 (0.176)	Data 0.154 (0.154)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.034)	Data 0.022 (0.022)	Loss 0.0011 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.024 (0.039)	Data 0.011 (0.026)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)
 * Training Prec@1 99.998
Test: [0/50]	Time 0.654 (0.654)	Loss 0.7121 (0.7121)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.820
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 1.010 (1.010)	Data 0.989 (0.989)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.589 (0.059)	Data 0.577 (0.040)	Loss 0.0013 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.038 (0.055)	Data 0.022 (0.038)	Loss 0.0011 (0.0016)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.143 (0.143)	Loss 0.7067 (0.7067)	Prec@1 83.500 (83.500)
 * Testing Prec@1 83.850
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.601 (0.601)	Data 0.581 (0.581)	Loss 0.0025 (0.0025)	Prec@1 100.000 (100.000)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.040)	Data 0.021 (0.027)	Loss 0.0024 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.030 (0.040)	Data 0.019 (0.027)	Loss 0.0026 (0.0016)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.442 (0.442)	Loss 0.7017 (0.7017)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.890
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.458 (0.458)	Data 0.431 (0.431)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.072)	Data 0.021 (0.058)	Loss 0.0020 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.032 (0.066)	Data 0.019 (0.050)	Loss 0.0007 (0.0015)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.527 (0.527)	Loss 0.6966 (0.6966)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.870
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 1.049 (1.049)	Data 1.022 (1.022)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.061)	Data 0.018 (0.035)	Loss 0.0021 (0.0017)	Prec@1 100.000 (100.000)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.034 (0.062)	Data 0.021 (0.041)	Loss 0.0037 (0.0016)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.446 (0.446)	Loss 0.7048 (0.7048)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.710
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.973 (0.973)	Data 0.950 (0.950)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.032 (0.043)	Data 0.020 (0.030)	Loss 0.0011 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.033 (0.038)	Data 0.020 (0.026)	Loss 0.0011 (0.0015)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.505 (0.505)	Loss 0.7136 (0.7136)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.800
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.104 (0.104)	Data 0.082 (0.082)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.034)	Data 0.018 (0.020)	Loss 0.0011 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.040 (0.034)	Data 0.023 (0.021)	Loss 0.0017 (0.0015)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.275 (0.275)	Loss 0.6967 (0.6967)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.020
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.524 (0.524)	Data 0.503 (0.503)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.049)	Data 0.015 (0.036)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.041 (0.062)	Data 0.030 (0.049)	Loss 0.0010 (0.0015)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 1.043 (1.043)	Loss 0.7095 (0.7095)	Prec@1 83.500 (83.500)
 * Testing Prec@1 83.920
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 2.213 (2.213)	Data 0.109 (0.109)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.033 (0.094)	Data 0.022 (0.060)	Loss 0.0030 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.035 (0.075)	Data 0.022 (0.052)	Loss 0.0019 (0.0016)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.564 (0.564)	Loss 0.6932 (0.6932)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.970
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.409 (0.409)	Data 0.386 (0.386)	Loss 0.0015 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.032 (0.037)	Data 0.019 (0.024)	Loss 0.0010 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.033 (0.036)	Data 0.021 (0.023)	Loss 0.0009 (0.0015)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.257 (0.257)	Loss 0.7065 (0.7065)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.850
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.139 (0.139)	Data 0.118 (0.118)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.034)	Data 0.023 (0.020)	Loss 0.0008 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.032 (0.034)	Data 0.020 (0.021)	Loss 0.0010 (0.0015)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.078 (0.078)	Loss 0.7079 (0.7079)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.780
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.641 (0.641)	Data 0.620 (0.620)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.032 (0.039)	Data 0.020 (0.027)	Loss 0.0013 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.031 (0.037)	Data 0.018 (0.024)	Loss 0.0023 (0.0016)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.088 (0.088)	Loss 0.7039 (0.7039)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.900
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 1.232 (1.232)	Data 1.215 (1.215)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.031 (0.045)	Data 0.018 (0.032)	Loss 0.0012 (0.0014)	Prec@1 100.000 (100.000)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.032 (0.040)	Data 0.019 (0.027)	Loss 0.0008 (0.0015)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.257 (0.257)	Loss 0.7014 (0.7014)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.980
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.101 (0.101)	Data 0.076 (0.076)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.026 (0.046)	Data 0.013 (0.028)	Loss 0.0016 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.035 (0.061)	Data 0.022 (0.046)	Loss 0.0016 (0.0015)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.231 (0.231)	Loss 0.7033 (0.7033)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.960
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.094 (0.094)	Data 0.067 (0.067)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.035)	Data 0.018 (0.022)	Loss 0.0014 (0.0015)	Prec@1 100.000 (100.000)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.034 (0.035)	Data 0.021 (0.021)	Loss 0.0013 (0.0015)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 2.037 (2.037)	Loss 0.6963 (0.6963)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.050
