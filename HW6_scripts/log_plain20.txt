Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'plainnet20'
Epoch: [0/80][0/250]	LR: 0.1	Time 0.506 (0.506)	Data 0.118 (0.118)	Loss 2.3471 (2.3471)	Prec@1 5.000 (5.000)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.047 (0.043)	Data 0.030 (0.024)	Loss 1.7205 (1.9544)	Prec@1 31.000 (24.351)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.035 (0.040)	Data 0.023 (0.024)	Loss 1.6676 (1.8322)	Prec@1 41.000 (29.791)
 * Training Prec@1 31.866
main.py:153: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.144 (0.144)	Loss 1.5589 (1.5589)	Prec@1 45.000 (45.000)
 * Testing Prec@1 42.070
main.py:190: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:191: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:199: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 0.129 (0.129)	Data 0.099 (0.099)	Loss 1.6000 (1.6000)	Prec@1 41.000 (41.000)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.023 (0.023)	Loss 1.4349 (1.5003)	Prec@1 50.000 (44.233)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.048 (0.037)	Data 0.031 (0.023)	Loss 1.4436 (1.4302)	Prec@1 50.000 (47.398)
 * Training Prec@1 48.752
Test: [0/50]	Time 0.147 (0.147)	Loss 1.9096 (1.9096)	Prec@1 41.000 (41.000)
 * Testing Prec@1 46.180
Epoch: [2/80][0/250]	LR: 0.1	Time 0.132 (0.132)	Data 0.101 (0.101)	Loss 1.1424 (1.1424)	Prec@1 60.000 (60.000)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.049 (0.042)	Data 0.037 (0.028)	Loss 1.2129 (1.1685)	Prec@1 56.000 (58.198)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.046 (0.041)	Data 0.029 (0.027)	Loss 0.9933 (1.1289)	Prec@1 67.000 (59.433)
 * Training Prec@1 60.092
Test: [0/50]	Time 0.140 (0.140)	Loss 1.1964 (1.1964)	Prec@1 59.500 (59.500)
 * Testing Prec@1 58.260
Epoch: [3/80][0/250]	LR: 0.1	Time 0.143 (0.143)	Data 0.114 (0.114)	Loss 1.2048 (1.2048)	Prec@1 57.000 (57.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.037 (0.038)	Data 0.025 (0.026)	Loss 0.8324 (0.9845)	Prec@1 70.000 (64.837)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.037 (0.037)	Data 0.025 (0.025)	Loss 0.8387 (0.9565)	Prec@1 73.000 (65.898)
 * Training Prec@1 66.258
Test: [0/50]	Time 0.135 (0.135)	Loss 1.6189 (1.6189)	Prec@1 54.000 (54.000)
 * Testing Prec@1 54.280
Epoch: [4/80][0/250]	LR: 0.1	Time 0.151 (0.151)	Data 0.120 (0.120)	Loss 0.9061 (0.9061)	Prec@1 65.500 (65.500)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.034 (0.041)	Data 0.021 (0.026)	Loss 0.9314 (0.8469)	Prec@1 66.500 (70.510)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.026 (0.025)	Loss 0.6872 (0.8336)	Prec@1 73.500 (70.816)
 * Training Prec@1 71.018
Test: [0/50]	Time 0.140 (0.140)	Loss 1.1177 (1.1177)	Prec@1 61.000 (61.000)
 * Testing Prec@1 64.080
Epoch: [5/80][0/250]	LR: 0.1	Time 0.147 (0.147)	Data 0.111 (0.111)	Loss 0.7603 (0.7603)	Prec@1 75.000 (75.000)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.024 (0.025)	Loss 0.6973 (0.7488)	Prec@1 73.500 (73.842)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.040 (0.037)	Data 0.027 (0.025)	Loss 0.6792 (0.7412)	Prec@1 77.500 (74.139)
 * Training Prec@1 74.300
Test: [0/50]	Time 0.146 (0.146)	Loss 0.5994 (0.5994)	Prec@1 80.000 (80.000)
 * Testing Prec@1 74.670
Epoch: [6/80][0/250]	LR: 0.1	Time 0.151 (0.151)	Data 0.119 (0.119)	Loss 0.7455 (0.7455)	Prec@1 74.500 (74.500)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.024 (0.025)	Loss 0.8255 (0.6925)	Prec@1 69.000 (75.995)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.033 (0.037)	Data 0.019 (0.024)	Loss 0.7070 (0.6878)	Prec@1 74.500 (76.112)
 * Training Prec@1 76.248
Test: [0/50]	Time 0.108 (0.108)	Loss 0.6592 (0.6592)	Prec@1 77.000 (77.000)
 * Testing Prec@1 75.070
Epoch: [7/80][0/250]	LR: 0.1	Time 0.133 (0.133)	Data 0.104 (0.104)	Loss 0.8006 (0.8006)	Prec@1 74.000 (74.000)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.022 (0.023)	Loss 0.6749 (0.6399)	Prec@1 75.500 (77.797)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.037 (0.036)	Data 0.024 (0.024)	Loss 0.6101 (0.6403)	Prec@1 83.000 (77.960)
 * Training Prec@1 78.052
Test: [0/50]	Time 0.156 (0.156)	Loss 0.6935 (0.6935)	Prec@1 75.500 (75.500)
 * Testing Prec@1 74.710
Epoch: [8/80][0/250]	LR: 0.1	Time 0.169 (0.169)	Data 0.139 (0.139)	Loss 0.5402 (0.5402)	Prec@1 81.000 (81.000)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.034 (0.040)	Data 0.022 (0.026)	Loss 0.5805 (0.6099)	Prec@1 80.000 (79.010)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.047 (0.040)	Data 0.030 (0.025)	Loss 0.6011 (0.6040)	Prec@1 78.000 (79.050)
 * Training Prec@1 79.194
Test: [0/50]	Time 0.148 (0.148)	Loss 0.7017 (0.7017)	Prec@1 76.000 (76.000)
 * Testing Prec@1 74.220
Epoch: [9/80][0/250]	LR: 0.1	Time 0.141 (0.141)	Data 0.112 (0.112)	Loss 0.5898 (0.5898)	Prec@1 80.500 (80.500)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.022 (0.022)	Loss 0.5902 (0.5869)	Prec@1 80.500 (79.762)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.037 (0.036)	Data 0.026 (0.023)	Loss 0.5471 (0.5823)	Prec@1 82.500 (79.818)
 * Training Prec@1 79.870
Test: [0/50]	Time 0.112 (0.112)	Loss 0.7281 (0.7281)	Prec@1 76.000 (76.000)
 * Testing Prec@1 75.960
Epoch: [10/80][0/250]	LR: 0.1	Time 0.106 (0.106)	Data 0.077 (0.077)	Loss 0.6450 (0.6450)	Prec@1 80.000 (80.000)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.023 (0.022)	Loss 0.5317 (0.5583)	Prec@1 83.000 (80.777)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.021 (0.022)	Loss 0.6281 (0.5523)	Prec@1 79.000 (80.846)
 * Training Prec@1 80.880
Test: [0/50]	Time 0.097 (0.097)	Loss 0.6267 (0.6267)	Prec@1 76.500 (76.500)
 * Testing Prec@1 77.110
Epoch: [11/80][0/250]	LR: 0.1	Time 0.140 (0.140)	Data 0.109 (0.109)	Loss 0.4165 (0.4165)	Prec@1 85.000 (85.000)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.039 (0.038)	Data 0.024 (0.024)	Loss 0.5029 (0.5206)	Prec@1 80.500 (81.851)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.022 (0.024)	Loss 0.4612 (0.5287)	Prec@1 84.000 (81.617)
 * Training Prec@1 81.742
Test: [0/50]	Time 0.118 (0.118)	Loss 0.6891 (0.6891)	Prec@1 79.000 (79.000)
 * Testing Prec@1 78.330
Epoch: [12/80][0/250]	LR: 0.1	Time 0.104 (0.104)	Data 0.073 (0.073)	Loss 0.5166 (0.5166)	Prec@1 83.000 (83.000)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.035 (0.036)	Data 0.022 (0.022)	Loss 0.5643 (0.4988)	Prec@1 80.500 (82.510)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.022 (0.024)	Loss 0.5709 (0.5106)	Prec@1 78.000 (82.189)
 * Training Prec@1 82.202
Test: [0/50]	Time 0.120 (0.120)	Loss 0.5360 (0.5360)	Prec@1 81.000 (81.000)
 * Testing Prec@1 79.980
Epoch: [13/80][0/250]	LR: 0.1	Time 0.160 (0.160)	Data 0.127 (0.127)	Loss 0.5729 (0.5729)	Prec@1 77.000 (77.000)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.047 (0.043)	Data 0.033 (0.027)	Loss 0.5079 (0.4916)	Prec@1 80.500 (82.792)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.048 (0.042)	Data 0.030 (0.027)	Loss 0.5366 (0.4911)	Prec@1 79.500 (83.020)
 * Training Prec@1 83.014
Test: [0/50]	Time 0.114 (0.114)	Loss 0.5617 (0.5617)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.260
Epoch: [14/80][0/250]	LR: 0.1	Time 0.105 (0.105)	Data 0.076 (0.076)	Loss 0.4891 (0.4891)	Prec@1 84.500 (84.500)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.046 (0.042)	Data 0.028 (0.027)	Loss 0.4904 (0.4837)	Prec@1 84.500 (83.153)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.045 (0.039)	Data 0.025 (0.025)	Loss 0.4826 (0.4784)	Prec@1 83.000 (83.458)
 * Training Prec@1 83.426
Test: [0/50]	Time 0.113 (0.113)	Loss 0.8871 (0.8871)	Prec@1 70.500 (70.500)
 * Testing Prec@1 71.670
Epoch: [15/80][0/250]	LR: 0.1	Time 0.107 (0.107)	Data 0.075 (0.075)	Loss 0.6186 (0.6186)	Prec@1 77.500 (77.500)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.039 (0.039)	Data 0.028 (0.025)	Loss 0.3970 (0.4650)	Prec@1 86.500 (84.010)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.035 (0.039)	Data 0.023 (0.025)	Loss 0.4615 (0.4722)	Prec@1 84.000 (83.709)
 * Training Prec@1 83.694
Test: [0/50]	Time 0.151 (0.151)	Loss 0.6631 (0.6631)	Prec@1 80.000 (80.000)
 * Testing Prec@1 78.520
Epoch: [16/80][0/250]	LR: 0.1	Time 0.144 (0.144)	Data 0.112 (0.112)	Loss 0.4369 (0.4369)	Prec@1 86.000 (86.000)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.024 (0.024)	Loss 0.4821 (0.4511)	Prec@1 83.000 (84.579)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.036 (0.037)	Data 0.024 (0.025)	Loss 0.4199 (0.4529)	Prec@1 87.000 (84.470)
 * Training Prec@1 84.466
Test: [0/50]	Time 0.145 (0.145)	Loss 0.5422 (0.5422)	Prec@1 78.500 (78.500)
 * Testing Prec@1 79.050
Epoch: [17/80][0/250]	LR: 0.1	Time 0.137 (0.137)	Data 0.109 (0.109)	Loss 0.5192 (0.5192)	Prec@1 83.000 (83.000)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.067 (0.041)	Data 0.050 (0.025)	Loss 0.4868 (0.4339)	Prec@1 85.500 (84.876)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.024 (0.025)	Loss 0.4702 (0.4435)	Prec@1 82.500 (84.659)
 * Training Prec@1 84.550
Test: [0/50]	Time 0.149 (0.149)	Loss 0.4997 (0.4997)	Prec@1 83.000 (83.000)
 * Testing Prec@1 81.560
Epoch: [18/80][0/250]	LR: 0.1	Time 0.106 (0.106)	Data 0.075 (0.075)	Loss 0.4214 (0.4214)	Prec@1 85.500 (85.500)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.051 (0.040)	Data 0.034 (0.026)	Loss 0.5248 (0.4310)	Prec@1 79.500 (84.866)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.036 (0.040)	Data 0.023 (0.025)	Loss 0.4955 (0.4325)	Prec@1 81.500 (84.866)
 * Training Prec@1 84.888
Test: [0/50]	Time 0.150 (0.150)	Loss 0.5444 (0.5444)	Prec@1 80.500 (80.500)
 * Testing Prec@1 80.920
Epoch: [19/80][0/250]	LR: 0.1	Time 0.164 (0.164)	Data 0.136 (0.136)	Loss 0.3880 (0.3880)	Prec@1 86.500 (86.500)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.038 (0.041)	Data 0.025 (0.026)	Loss 0.4029 (0.4071)	Prec@1 87.000 (86.050)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.025 (0.025)	Loss 0.4783 (0.4177)	Prec@1 84.000 (85.532)
 * Training Prec@1 85.436
Test: [0/50]	Time 0.108 (0.108)	Loss 0.5920 (0.5920)	Prec@1 80.500 (80.500)
 * Testing Prec@1 80.990
Epoch: [20/80][0/250]	LR: 0.1	Time 0.106 (0.106)	Data 0.077 (0.077)	Loss 0.4711 (0.4711)	Prec@1 85.500 (85.500)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.054 (0.040)	Data 0.037 (0.025)	Loss 0.4100 (0.4139)	Prec@1 85.500 (85.614)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.024 (0.025)	Loss 0.4170 (0.4126)	Prec@1 86.500 (85.831)
 * Training Prec@1 85.674
Test: [0/50]	Time 0.111 (0.111)	Loss 0.5400 (0.5400)	Prec@1 81.500 (81.500)
 * Testing Prec@1 80.650
Epoch: [21/80][0/250]	LR: 0.1	Time 0.145 (0.145)	Data 0.117 (0.117)	Loss 0.4552 (0.4552)	Prec@1 83.500 (83.500)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.037 (0.038)	Data 0.025 (0.025)	Loss 0.3984 (0.4074)	Prec@1 85.000 (85.847)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.024 (0.025)	Loss 0.4675 (0.4086)	Prec@1 82.500 (85.873)
 * Training Prec@1 85.820
Test: [0/50]	Time 0.116 (0.116)	Loss 0.5741 (0.5741)	Prec@1 81.000 (81.000)
 * Testing Prec@1 79.560
Epoch: [22/80][0/250]	LR: 0.1	Time 0.109 (0.109)	Data 0.078 (0.078)	Loss 0.3600 (0.3600)	Prec@1 86.000 (86.000)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.037 (0.038)	Data 0.023 (0.025)	Loss 0.3564 (0.3925)	Prec@1 87.000 (86.465)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.023 (0.025)	Loss 0.4184 (0.4018)	Prec@1 85.000 (86.082)
 * Training Prec@1 85.974
Test: [0/50]	Time 0.133 (0.133)	Loss 0.8124 (0.8124)	Prec@1 75.000 (75.000)
 * Testing Prec@1 75.810
Epoch: [23/80][0/250]	LR: 0.1	Time 0.183 (0.183)	Data 0.153 (0.153)	Loss 0.4103 (0.4103)	Prec@1 84.500 (84.500)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.045 (0.039)	Data 0.031 (0.026)	Loss 0.3956 (0.3883)	Prec@1 86.500 (86.460)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.047 (0.039)	Data 0.030 (0.025)	Loss 0.3632 (0.3915)	Prec@1 87.500 (86.351)
 * Training Prec@1 86.328
Test: [0/50]	Time 0.130 (0.130)	Loss 0.4735 (0.4735)	Prec@1 85.000 (85.000)
 * Testing Prec@1 82.800
Epoch: [24/80][0/250]	LR: 0.1	Time 0.095 (0.095)	Data 0.070 (0.070)	Loss 0.3609 (0.3609)	Prec@1 87.500 (87.500)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.023 (0.024)	Loss 0.4284 (0.3820)	Prec@1 82.000 (86.683)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.037 (0.037)	Data 0.025 (0.025)	Loss 0.4679 (0.3861)	Prec@1 85.500 (86.560)
 * Training Prec@1 86.612
Test: [0/50]	Time 0.111 (0.111)	Loss 0.5793 (0.5793)	Prec@1 79.500 (79.500)
 * Testing Prec@1 81.280
Epoch: [25/80][0/250]	LR: 0.1	Time 0.096 (0.096)	Data 0.071 (0.071)	Loss 0.4946 (0.4946)	Prec@1 83.500 (83.500)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.050 (0.043)	Data 0.032 (0.027)	Loss 0.4207 (0.3685)	Prec@1 83.500 (86.921)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.036 (0.041)	Data 0.022 (0.026)	Loss 0.3288 (0.3812)	Prec@1 89.500 (86.694)
 * Training Prec@1 86.684
Test: [0/50]	Time 0.117 (0.117)	Loss 0.4204 (0.4204)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.060
Epoch: [26/80][0/250]	LR: 0.1	Time 0.104 (0.104)	Data 0.078 (0.078)	Loss 0.3149 (0.3149)	Prec@1 88.500 (88.500)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.038 (0.039)	Data 0.024 (0.024)	Loss 0.4420 (0.3715)	Prec@1 83.500 (87.193)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.035 (0.039)	Data 0.024 (0.025)	Loss 0.3443 (0.3742)	Prec@1 89.500 (87.032)
 * Training Prec@1 86.904
Test: [0/50]	Time 0.109 (0.109)	Loss 0.5529 (0.5529)	Prec@1 82.000 (82.000)
 * Testing Prec@1 81.620
Epoch: [27/80][0/250]	LR: 0.1	Time 0.174 (0.174)	Data 0.145 (0.145)	Loss 0.3799 (0.3799)	Prec@1 85.500 (85.500)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.036 (0.040)	Data 0.023 (0.026)	Loss 0.3488 (0.3624)	Prec@1 87.500 (87.332)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.046 (0.039)	Data 0.029 (0.025)	Loss 0.3325 (0.3675)	Prec@1 87.500 (87.251)
 * Training Prec@1 87.176
Test: [0/50]	Time 0.129 (0.129)	Loss 0.7207 (0.7207)	Prec@1 79.000 (79.000)
 * Testing Prec@1 78.920
Epoch: [28/80][0/250]	LR: 0.1	Time 0.183 (0.183)	Data 0.152 (0.152)	Loss 0.3293 (0.3293)	Prec@1 90.500 (90.500)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.037 (0.040)	Data 0.022 (0.025)	Loss 0.3664 (0.3571)	Prec@1 85.000 (87.891)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.023 (0.025)	Loss 0.3275 (0.3623)	Prec@1 87.500 (87.575)
 * Training Prec@1 87.456
Test: [0/50]	Time 0.145 (0.145)	Loss 0.4621 (0.4621)	Prec@1 83.500 (83.500)
 * Testing Prec@1 81.170
Epoch: [29/80][0/250]	LR: 0.1	Time 0.156 (0.156)	Data 0.123 (0.123)	Loss 0.3524 (0.3524)	Prec@1 89.000 (89.000)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.038 (0.039)	Data 0.026 (0.026)	Loss 0.3401 (0.3664)	Prec@1 87.000 (87.243)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.038 (0.040)	Data 0.026 (0.026)	Loss 0.3860 (0.3601)	Prec@1 88.500 (87.632)
 * Training Prec@1 87.502
Test: [0/50]	Time 0.159 (0.159)	Loss 0.5895 (0.5895)	Prec@1 81.500 (81.500)
 * Testing Prec@1 80.680
Epoch: [30/80][0/250]	LR: 0.1	Time 0.177 (0.177)	Data 0.143 (0.143)	Loss 0.3961 (0.3961)	Prec@1 85.500 (85.500)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.025 (0.025)	Loss 0.3567 (0.3472)	Prec@1 87.000 (88.064)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.023 (0.025)	Loss 0.3982 (0.3602)	Prec@1 87.000 (87.532)
 * Training Prec@1 87.566
Test: [0/50]	Time 0.153 (0.153)	Loss 0.5388 (0.5388)	Prec@1 84.500 (84.500)
 * Testing Prec@1 82.340
Epoch: [31/80][0/250]	LR: 0.1	Time 0.116 (0.116)	Data 0.088 (0.088)	Loss 0.3555 (0.3555)	Prec@1 89.500 (89.500)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.024 (0.026)	Loss 0.3177 (0.3484)	Prec@1 89.000 (87.916)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.048 (0.040)	Data 0.030 (0.026)	Loss 0.3518 (0.3528)	Prec@1 86.000 (87.612)
 * Training Prec@1 87.694
Test: [0/50]	Time 0.146 (0.146)	Loss 0.6354 (0.6354)	Prec@1 82.000 (82.000)
 * Testing Prec@1 79.630
Epoch: [32/80][0/250]	LR: 0.1	Time 0.181 (0.181)	Data 0.153 (0.153)	Loss 0.3019 (0.3019)	Prec@1 87.500 (87.500)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.035 (0.039)	Data 0.019 (0.026)	Loss 0.3130 (0.3397)	Prec@1 87.500 (88.163)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.023 (0.025)	Loss 0.5674 (0.3450)	Prec@1 82.500 (87.965)
 * Training Prec@1 87.910
Test: [0/50]	Time 0.118 (0.118)	Loss 0.5293 (0.5293)	Prec@1 84.500 (84.500)
 * Testing Prec@1 82.990
Epoch: [33/80][0/250]	LR: 0.1	Time 0.184 (0.184)	Data 0.153 (0.153)	Loss 0.2828 (0.2828)	Prec@1 91.000 (91.000)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.038 (0.039)	Data 0.026 (0.025)	Loss 0.3164 (0.3383)	Prec@1 85.500 (88.337)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.035 (0.039)	Data 0.021 (0.024)	Loss 0.3173 (0.3448)	Prec@1 90.000 (88.211)
 * Training Prec@1 88.110
Test: [0/50]	Time 0.110 (0.110)	Loss 0.4411 (0.4411)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.280
Epoch: [34/80][0/250]	LR: 0.1	Time 0.152 (0.152)	Data 0.119 (0.119)	Loss 0.3972 (0.3972)	Prec@1 86.500 (86.500)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.037 (0.042)	Data 0.024 (0.027)	Loss 0.4165 (0.3267)	Prec@1 88.000 (88.525)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.037 (0.040)	Data 0.022 (0.026)	Loss 0.3616 (0.3420)	Prec@1 87.500 (88.030)
 * Training Prec@1 87.962
Test: [0/50]	Time 0.131 (0.131)	Loss 0.5114 (0.5114)	Prec@1 85.000 (85.000)
 * Testing Prec@1 82.250
Epoch: [35/80][0/250]	LR: 0.1	Time 0.144 (0.144)	Data 0.115 (0.115)	Loss 0.2839 (0.2839)	Prec@1 90.500 (90.500)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.035 (0.041)	Data 0.022 (0.025)	Loss 0.4048 (0.3285)	Prec@1 88.500 (88.554)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.037 (0.040)	Data 0.025 (0.025)	Loss 0.3735 (0.3312)	Prec@1 88.000 (88.433)
 * Training Prec@1 88.466
Test: [0/50]	Time 0.108 (0.108)	Loss 0.4801 (0.4801)	Prec@1 84.500 (84.500)
 * Testing Prec@1 82.310
Epoch: [36/80][0/250]	LR: 0.1	Time 0.132 (0.132)	Data 0.103 (0.103)	Loss 0.3437 (0.3437)	Prec@1 87.000 (87.000)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.038 (0.038)	Data 0.027 (0.025)	Loss 0.2768 (0.3263)	Prec@1 89.500 (88.807)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.037 (0.037)	Data 0.024 (0.025)	Loss 0.2865 (0.3322)	Prec@1 89.500 (88.609)
 * Training Prec@1 88.586
Test: [0/50]	Time 0.110 (0.110)	Loss 0.4448 (0.4448)	Prec@1 84.000 (84.000)
 * Testing Prec@1 82.490
Epoch: [37/80][0/250]	LR: 0.1	Time 0.143 (0.143)	Data 0.114 (0.114)	Loss 0.3785 (0.3785)	Prec@1 85.000 (85.000)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.039 (0.040)	Data 0.024 (0.025)	Loss 0.3324 (0.3150)	Prec@1 88.500 (89.173)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.038 (0.038)	Data 0.025 (0.024)	Loss 0.3435 (0.3227)	Prec@1 90.000 (88.935)
 * Training Prec@1 88.766
Test: [0/50]	Time 0.094 (0.094)	Loss 0.4821 (0.4821)	Prec@1 83.500 (83.500)
 * Testing Prec@1 82.080
Epoch: [38/80][0/250]	LR: 0.1	Time 0.179 (0.179)	Data 0.150 (0.150)	Loss 0.2950 (0.2950)	Prec@1 89.500 (89.500)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.025 (0.025)	Loss 0.2464 (0.3146)	Prec@1 91.000 (88.767)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.039 (0.038)	Data 0.026 (0.025)	Loss 0.3165 (0.3219)	Prec@1 89.500 (88.761)
 * Training Prec@1 88.708
Test: [0/50]	Time 0.113 (0.113)	Loss 0.3679 (0.3679)	Prec@1 87.000 (87.000)
 * Testing Prec@1 84.280
Epoch: [39/80][0/250]	LR: 0.1	Time 0.113 (0.113)	Data 0.084 (0.084)	Loss 0.3777 (0.3777)	Prec@1 89.000 (89.000)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.038 (0.038)	Data 0.027 (0.026)	Loss 0.3059 (0.3129)	Prec@1 89.000 (89.064)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.038 (0.038)	Data 0.025 (0.026)	Loss 0.2905 (0.3188)	Prec@1 88.000 (88.846)
 * Training Prec@1 88.822
Test: [0/50]	Time 0.120 (0.120)	Loss 0.6219 (0.6219)	Prec@1 80.500 (80.500)
 * Testing Prec@1 80.970
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.100 (0.100)	Data 0.072 (0.072)	Loss 0.2806 (0.2806)	Prec@1 91.000 (91.000)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.037)	Data 0.025 (0.025)	Loss 0.2477 (0.2567)	Prec@1 90.000 (91.163)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.037)	Data 0.024 (0.025)	Loss 0.1701 (0.2381)	Prec@1 93.500 (91.808)
 * Training Prec@1 91.982
Test: [0/50]	Time 0.105 (0.105)	Loss 0.2842 (0.2842)	Prec@1 92.000 (92.000)
 * Testing Prec@1 88.720
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.103 (0.103)	Data 0.074 (0.074)	Loss 0.2231 (0.2231)	Prec@1 95.000 (95.000)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.039)	Data 0.023 (0.024)	Loss 0.1938 (0.2063)	Prec@1 92.500 (92.955)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.038)	Data 0.025 (0.024)	Loss 0.2114 (0.2080)	Prec@1 95.000 (92.913)
 * Training Prec@1 93.010
Test: [0/50]	Time 0.089 (0.089)	Loss 0.2778 (0.2778)	Prec@1 89.500 (89.500)
 * Testing Prec@1 88.910
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.141 (0.141)	Data 0.112 (0.112)	Loss 0.2109 (0.2109)	Prec@1 92.500 (92.500)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.036 (0.040)	Data 0.024 (0.026)	Loss 0.1607 (0.1948)	Prec@1 95.000 (93.376)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.039)	Data 0.025 (0.025)	Loss 0.1706 (0.1928)	Prec@1 93.500 (93.460)
 * Training Prec@1 93.464
Test: [0/50]	Time 0.096 (0.096)	Loss 0.3042 (0.3042)	Prec@1 90.000 (90.000)
 * Testing Prec@1 89.130
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.116 (0.116)	Data 0.090 (0.090)	Loss 0.1378 (0.1378)	Prec@1 94.000 (94.000)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.036 (0.038)	Data 0.024 (0.024)	Loss 0.2162 (0.1884)	Prec@1 92.000 (93.485)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.038)	Data 0.022 (0.024)	Loss 0.2396 (0.1871)	Prec@1 91.500 (93.552)
 * Training Prec@1 93.596
Test: [0/50]	Time 0.112 (0.112)	Loss 0.2701 (0.2701)	Prec@1 90.500 (90.500)
 * Testing Prec@1 89.150
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.145 (0.145)	Data 0.113 (0.113)	Loss 0.1633 (0.1633)	Prec@1 94.000 (94.000)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.038)	Data 0.024 (0.024)	Loss 0.1898 (0.1791)	Prec@1 91.500 (93.812)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.038)	Data 0.024 (0.024)	Loss 0.1495 (0.1781)	Prec@1 93.500 (93.803)
 * Training Prec@1 93.778
Test: [0/50]	Time 0.080 (0.080)	Loss 0.2655 (0.2655)	Prec@1 92.000 (92.000)
 * Testing Prec@1 89.240
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.146 (0.146)	Data 0.113 (0.113)	Loss 0.1258 (0.1258)	Prec@1 95.000 (95.000)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.044 (0.043)	Data 0.028 (0.028)	Loss 0.1487 (0.1760)	Prec@1 96.000 (94.045)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.034 (0.042)	Data 0.020 (0.027)	Loss 0.1800 (0.1749)	Prec@1 93.000 (94.022)
 * Training Prec@1 94.032
Test: [0/50]	Time 0.145 (0.145)	Loss 0.2858 (0.2858)	Prec@1 90.000 (90.000)
 * Testing Prec@1 89.220
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.131 (0.131)	Data 0.102 (0.102)	Loss 0.2119 (0.2119)	Prec@1 92.000 (92.000)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.040)	Data 0.024 (0.026)	Loss 0.2107 (0.1672)	Prec@1 93.000 (94.272)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.046 (0.039)	Data 0.029 (0.025)	Loss 0.1825 (0.1692)	Prec@1 94.000 (94.122)
 * Training Prec@1 94.054
Test: [0/50]	Time 0.138 (0.138)	Loss 0.2319 (0.2319)	Prec@1 90.000 (90.000)
 * Testing Prec@1 88.970
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 0.117 (0.117)	Data 0.086 (0.086)	Loss 0.1686 (0.1686)	Prec@1 96.500 (96.500)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.040 (0.042)	Data 0.025 (0.026)	Loss 0.1830 (0.1592)	Prec@1 93.500 (94.317)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.034 (0.042)	Data 0.022 (0.026)	Loss 0.1989 (0.1641)	Prec@1 93.000 (94.226)
 * Training Prec@1 94.242
Test: [0/50]	Time 0.102 (0.102)	Loss 0.2717 (0.2717)	Prec@1 91.000 (91.000)
 * Testing Prec@1 89.120
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.106 (0.106)	Data 0.077 (0.077)	Loss 0.1308 (0.1308)	Prec@1 95.000 (95.000)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.046 (0.041)	Data 0.028 (0.026)	Loss 0.1931 (0.1571)	Prec@1 92.000 (94.406)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.039)	Data 0.021 (0.025)	Loss 0.1919 (0.1599)	Prec@1 94.000 (94.433)
 * Training Prec@1 94.450
Test: [0/50]	Time 0.133 (0.133)	Loss 0.2735 (0.2735)	Prec@1 90.000 (90.000)
 * Testing Prec@1 89.140
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.116 (0.116)	Data 0.086 (0.086)	Loss 0.1924 (0.1924)	Prec@1 95.500 (95.500)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.038 (0.042)	Data 0.024 (0.026)	Loss 0.1797 (0.1632)	Prec@1 93.000 (94.193)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.039)	Data 0.024 (0.025)	Loss 0.2335 (0.1612)	Prec@1 92.000 (94.301)
 * Training Prec@1 94.378
Test: [0/50]	Time 0.105 (0.105)	Loss 0.2686 (0.2686)	Prec@1 91.500 (91.500)
 * Testing Prec@1 89.210
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.114 (0.114)	Data 0.081 (0.081)	Loss 0.1856 (0.1856)	Prec@1 94.000 (94.000)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.039 (0.038)	Data 0.021 (0.024)	Loss 0.1696 (0.1570)	Prec@1 93.000 (94.554)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.038)	Data 0.024 (0.024)	Loss 0.1726 (0.1580)	Prec@1 93.000 (94.485)
 * Training Prec@1 94.530
Test: [0/50]	Time 0.107 (0.107)	Loss 0.3034 (0.3034)	Prec@1 90.000 (90.000)
 * Testing Prec@1 89.270
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 0.133 (0.133)	Data 0.105 (0.105)	Loss 0.1643 (0.1643)	Prec@1 93.000 (93.000)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.038 (0.040)	Data 0.025 (0.025)	Loss 0.1511 (0.1503)	Prec@1 94.000 (94.762)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.040)	Data 0.022 (0.025)	Loss 0.1815 (0.1526)	Prec@1 94.000 (94.711)
 * Training Prec@1 94.598
Test: [0/50]	Time 0.108 (0.108)	Loss 0.2626 (0.2626)	Prec@1 92.000 (92.000)
 * Testing Prec@1 89.140
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.108 (0.108)	Data 0.079 (0.079)	Loss 0.1741 (0.1741)	Prec@1 94.500 (94.500)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.038)	Data 0.024 (0.024)	Loss 0.1296 (0.1476)	Prec@1 96.500 (94.975)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.047 (0.039)	Data 0.030 (0.025)	Loss 0.2109 (0.1510)	Prec@1 92.500 (94.853)
 * Training Prec@1 94.820
Test: [0/50]	Time 0.104 (0.104)	Loss 0.2976 (0.2976)	Prec@1 90.000 (90.000)
 * Testing Prec@1 89.030
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 0.144 (0.144)	Data 0.116 (0.116)	Loss 0.1544 (0.1544)	Prec@1 94.500 (94.500)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.044)	Data 0.022 (0.029)	Loss 0.1917 (0.1462)	Prec@1 93.500 (94.842)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.042)	Data 0.023 (0.027)	Loss 0.0989 (0.1503)	Prec@1 97.500 (94.756)
 * Training Prec@1 94.770
Test: [0/50]	Time 0.118 (0.118)	Loss 0.2597 (0.2597)	Prec@1 92.500 (92.500)
 * Testing Prec@1 89.220
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.142 (0.142)	Data 0.112 (0.112)	Loss 0.0632 (0.0632)	Prec@1 98.000 (98.000)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.046 (0.042)	Data 0.028 (0.026)	Loss 0.1412 (0.1406)	Prec@1 95.000 (95.149)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.041 (0.043)	Data 0.024 (0.027)	Loss 0.0721 (0.1449)	Prec@1 97.000 (94.945)
 * Training Prec@1 94.916
Test: [0/50]	Time 0.165 (0.165)	Loss 0.2892 (0.2892)	Prec@1 91.500 (91.500)
 * Testing Prec@1 89.300
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.120 (0.120)	Data 0.089 (0.089)	Loss 0.1218 (0.1218)	Prec@1 95.000 (95.000)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.048 (0.046)	Data 0.030 (0.029)	Loss 0.1514 (0.1425)	Prec@1 94.500 (95.059)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.044)	Data 0.022 (0.028)	Loss 0.2455 (0.1457)	Prec@1 90.500 (94.925)
 * Training Prec@1 94.880
Test: [0/50]	Time 0.155 (0.155)	Loss 0.2619 (0.2619)	Prec@1 89.500 (89.500)
 * Testing Prec@1 89.260
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.148 (0.148)	Data 0.115 (0.115)	Loss 0.0967 (0.0967)	Prec@1 95.500 (95.500)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.038 (0.045)	Data 0.024 (0.029)	Loss 0.1938 (0.1369)	Prec@1 94.000 (95.119)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.048 (0.044)	Data 0.031 (0.029)	Loss 0.1349 (0.1407)	Prec@1 95.500 (95.052)
 * Training Prec@1 94.992
Test: [0/50]	Time 0.146 (0.146)	Loss 0.2733 (0.2733)	Prec@1 90.500 (90.500)
 * Testing Prec@1 88.960
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.137 (0.137)	Data 0.106 (0.106)	Loss 0.0601 (0.0601)	Prec@1 99.500 (99.500)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.040)	Data 0.023 (0.025)	Loss 0.1210 (0.1368)	Prec@1 96.000 (95.287)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.040)	Data 0.023 (0.025)	Loss 0.1716 (0.1387)	Prec@1 91.500 (95.206)
 * Training Prec@1 95.212
Test: [0/50]	Time 0.139 (0.139)	Loss 0.2854 (0.2854)	Prec@1 91.500 (91.500)
 * Testing Prec@1 88.810
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.139 (0.139)	Data 0.109 (0.109)	Loss 0.1504 (0.1504)	Prec@1 94.500 (94.500)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.052 (0.042)	Data 0.032 (0.027)	Loss 0.1827 (0.1366)	Prec@1 93.000 (95.252)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.041)	Data 0.025 (0.026)	Loss 0.0912 (0.1382)	Prec@1 97.000 (95.139)
 * Training Prec@1 95.112
Test: [0/50]	Time 0.132 (0.132)	Loss 0.2793 (0.2793)	Prec@1 91.500 (91.500)
 * Testing Prec@1 89.250
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.133 (0.133)	Data 0.103 (0.103)	Loss 0.1593 (0.1593)	Prec@1 95.000 (95.000)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.036 (0.043)	Data 0.024 (0.028)	Loss 0.1312 (0.1347)	Prec@1 96.000 (95.243)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.041 (0.042)	Data 0.028 (0.027)	Loss 0.1746 (0.1371)	Prec@1 93.500 (95.144)
 * Training Prec@1 95.140
Test: [0/50]	Time 0.136 (0.136)	Loss 0.2661 (0.2661)	Prec@1 93.000 (93.000)
 * Testing Prec@1 89.360
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.144 (0.144)	Data 0.116 (0.116)	Loss 0.1133 (0.1133)	Prec@1 94.500 (94.500)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.047 (0.045)	Data 0.030 (0.028)	Loss 0.1313 (0.1252)	Prec@1 95.500 (95.738)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.040 (0.043)	Data 0.025 (0.027)	Loss 0.1402 (0.1265)	Prec@1 95.500 (95.649)
 * Training Prec@1 95.676
Test: [0/50]	Time 0.140 (0.140)	Loss 0.2688 (0.2688)	Prec@1 93.000 (93.000)
 * Testing Prec@1 89.390
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.164 (0.164)	Data 0.133 (0.133)	Loss 0.0877 (0.0877)	Prec@1 97.000 (97.000)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.046 (0.047)	Data 0.029 (0.031)	Loss 0.1424 (0.1180)	Prec@1 94.000 (95.896)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.044 (0.044)	Data 0.027 (0.028)	Loss 0.1171 (0.1224)	Prec@1 94.500 (95.806)
 * Training Prec@1 95.818
Test: [0/50]	Time 0.157 (0.157)	Loss 0.2717 (0.2717)	Prec@1 93.000 (93.000)
 * Testing Prec@1 89.450
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.111 (0.111)	Data 0.085 (0.085)	Loss 0.0954 (0.0954)	Prec@1 95.000 (95.000)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.050 (0.043)	Data 0.034 (0.028)	Loss 0.0828 (0.1171)	Prec@1 97.000 (96.124)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.042)	Data 0.022 (0.027)	Loss 0.1931 (0.1205)	Prec@1 95.500 (95.878)
 * Training Prec@1 95.876
Test: [0/50]	Time 0.140 (0.140)	Loss 0.2655 (0.2655)	Prec@1 93.000 (93.000)
 * Testing Prec@1 89.340
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 0.140 (0.140)	Data 0.112 (0.112)	Loss 0.1036 (0.1036)	Prec@1 97.000 (97.000)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.041 (0.043)	Data 0.022 (0.027)	Loss 0.1355 (0.1240)	Prec@1 94.000 (95.668)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.043 (0.043)	Data 0.023 (0.027)	Loss 0.1394 (0.1211)	Prec@1 94.000 (95.826)
 * Training Prec@1 95.876
Test: [0/50]	Time 0.155 (0.155)	Loss 0.2670 (0.2670)	Prec@1 92.500 (92.500)
 * Testing Prec@1 89.450
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 0.162 (0.162)	Data 0.129 (0.129)	Loss 0.0869 (0.0869)	Prec@1 96.000 (96.000)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.037 (0.042)	Data 0.023 (0.026)	Loss 0.0763 (0.1183)	Prec@1 98.000 (96.059)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.040)	Data 0.023 (0.025)	Loss 0.1768 (0.1187)	Prec@1 94.000 (96.032)
 * Training Prec@1 96.028
Test: [0/50]	Time 0.147 (0.147)	Loss 0.2715 (0.2715)	Prec@1 92.000 (92.000)
 * Testing Prec@1 89.310
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.146 (0.146)	Data 0.116 (0.116)	Loss 0.0584 (0.0584)	Prec@1 99.000 (99.000)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.044 (0.045)	Data 0.030 (0.028)	Loss 0.1028 (0.1201)	Prec@1 96.500 (96.025)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.034 (0.044)	Data 0.017 (0.028)	Loss 0.1120 (0.1178)	Prec@1 97.500 (95.988)
 * Training Prec@1 95.950
Test: [0/50]	Time 0.165 (0.165)	Loss 0.2769 (0.2769)	Prec@1 92.000 (92.000)
 * Testing Prec@1 89.180
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 0.143 (0.143)	Data 0.113 (0.113)	Loss 0.0712 (0.0712)	Prec@1 97.000 (97.000)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.043 (0.046)	Data 0.025 (0.029)	Loss 0.1134 (0.1192)	Prec@1 96.000 (95.802)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.047 (0.044)	Data 0.031 (0.028)	Loss 0.1041 (0.1209)	Prec@1 96.000 (95.741)
 * Training Prec@1 95.766
Test: [0/50]	Time 0.149 (0.149)	Loss 0.2677 (0.2677)	Prec@1 93.000 (93.000)
 * Testing Prec@1 89.300
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.162 (0.162)	Data 0.132 (0.132)	Loss 0.0865 (0.0865)	Prec@1 97.000 (97.000)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.051 (0.044)	Data 0.033 (0.028)	Loss 0.0964 (0.1123)	Prec@1 96.500 (96.050)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.041 (0.042)	Data 0.028 (0.026)	Loss 0.0991 (0.1152)	Prec@1 97.000 (96.045)
 * Training Prec@1 95.972
Test: [0/50]	Time 0.151 (0.151)	Loss 0.2733 (0.2733)	Prec@1 92.000 (92.000)
 * Testing Prec@1 89.460
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.138 (0.138)	Data 0.106 (0.106)	Loss 0.1525 (0.1525)	Prec@1 95.500 (95.500)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.055 (0.051)	Data 0.038 (0.033)	Loss 0.1005 (0.1186)	Prec@1 97.000 (95.931)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.041 (0.047)	Data 0.023 (0.030)	Loss 0.0645 (0.1195)	Prec@1 99.000 (95.886)
 * Training Prec@1 95.958
Test: [0/50]	Time 0.153 (0.153)	Loss 0.2796 (0.2796)	Prec@1 92.500 (92.500)
 * Testing Prec@1 89.300
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 0.114 (0.114)	Data 0.086 (0.086)	Loss 0.1275 (0.1275)	Prec@1 94.500 (94.500)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.036 (0.039)	Data 0.021 (0.023)	Loss 0.0632 (0.1182)	Prec@1 98.500 (96.054)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.040 (0.041)	Data 0.026 (0.026)	Loss 0.1006 (0.1177)	Prec@1 97.000 (96.062)
 * Training Prec@1 96.016
Test: [0/50]	Time 0.142 (0.142)	Loss 0.2661 (0.2661)	Prec@1 92.500 (92.500)
 * Testing Prec@1 89.400
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.133 (0.133)	Data 0.110 (0.110)	Loss 0.1006 (0.1006)	Prec@1 96.500 (96.500)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.048 (0.044)	Data 0.033 (0.028)	Loss 0.1026 (0.1186)	Prec@1 97.000 (95.757)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.042)	Data 0.024 (0.026)	Loss 0.1313 (0.1177)	Prec@1 95.000 (95.928)
 * Training Prec@1 95.928
Test: [0/50]	Time 0.158 (0.158)	Loss 0.2725 (0.2725)	Prec@1 91.500 (91.500)
 * Testing Prec@1 89.590
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.149 (0.149)	Data 0.122 (0.122)	Loss 0.1182 (0.1182)	Prec@1 95.000 (95.000)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.037 (0.043)	Data 0.024 (0.027)	Loss 0.1242 (0.1171)	Prec@1 95.000 (95.901)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.040 (0.042)	Data 0.026 (0.027)	Loss 0.0988 (0.1160)	Prec@1 96.500 (95.950)
 * Training Prec@1 95.916
Test: [0/50]	Time 0.154 (0.154)	Loss 0.2736 (0.2736)	Prec@1 92.500 (92.500)
 * Testing Prec@1 89.370
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.148 (0.148)	Data 0.123 (0.123)	Loss 0.1573 (0.1573)	Prec@1 94.500 (94.500)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.036 (0.046)	Data 0.022 (0.030)	Loss 0.1895 (0.1142)	Prec@1 92.500 (96.173)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.043)	Data 0.022 (0.028)	Loss 0.1030 (0.1146)	Prec@1 96.000 (96.085)
 * Training Prec@1 96.078
Test: [0/50]	Time 0.135 (0.135)	Loss 0.2734 (0.2734)	Prec@1 91.500 (91.500)
 * Testing Prec@1 89.310
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 0.134 (0.134)	Data 0.104 (0.104)	Loss 0.0816 (0.0816)	Prec@1 96.500 (96.500)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.048 (0.045)	Data 0.030 (0.028)	Loss 0.0801 (0.1170)	Prec@1 96.500 (95.965)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.040 (0.045)	Data 0.025 (0.028)	Loss 0.1408 (0.1138)	Prec@1 95.000 (96.172)
 * Training Prec@1 96.098
Test: [0/50]	Time 0.121 (0.121)	Loss 0.2852 (0.2852)	Prec@1 91.500 (91.500)
 * Testing Prec@1 89.380
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.154 (0.154)	Data 0.124 (0.124)	Loss 0.1738 (0.1738)	Prec@1 95.000 (95.000)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.048 (0.049)	Data 0.030 (0.032)	Loss 0.1493 (0.1099)	Prec@1 95.500 (96.327)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.045)	Data 0.020 (0.028)	Loss 0.0956 (0.1134)	Prec@1 95.500 (96.129)
 * Training Prec@1 96.128
Test: [0/50]	Time 0.161 (0.161)	Loss 0.2661 (0.2661)	Prec@1 92.500 (92.500)
 * Testing Prec@1 89.380
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.129 (0.129)	Data 0.100 (0.100)	Loss 0.0781 (0.0781)	Prec@1 97.000 (97.000)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.040 (0.048)	Data 0.027 (0.031)	Loss 0.1083 (0.1136)	Prec@1 97.000 (96.035)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.041 (0.044)	Data 0.025 (0.028)	Loss 0.1416 (0.1164)	Prec@1 94.500 (96.007)
 * Training Prec@1 96.030
Test: [0/50]	Time 0.158 (0.158)	Loss 0.2747 (0.2747)	Prec@1 92.500 (92.500)
 * Testing Prec@1 89.340
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.156 (0.156)	Data 0.125 (0.125)	Loss 0.1002 (0.1002)	Prec@1 95.500 (95.500)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.048 (0.042)	Data 0.035 (0.027)	Loss 0.1351 (0.1133)	Prec@1 96.000 (96.089)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.039 (0.041)	Data 0.027 (0.026)	Loss 0.0816 (0.1141)	Prec@1 98.000 (96.060)
 * Training Prec@1 96.078
Test: [0/50]	Time 0.124 (0.124)	Loss 0.2762 (0.2762)	Prec@1 92.500 (92.500)
 * Testing Prec@1 89.340
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 0.118 (0.118)	Data 0.092 (0.092)	Loss 0.1262 (0.1262)	Prec@1 95.000 (95.000)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.048 (0.044)	Data 0.031 (0.027)	Loss 0.1185 (0.1132)	Prec@1 96.000 (96.129)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.063 (0.042)	Data 0.047 (0.026)	Loss 0.1220 (0.1130)	Prec@1 95.000 (96.085)
 * Training Prec@1 96.040
Test: [0/50]	Time 0.133 (0.133)	Loss 0.2773 (0.2773)	Prec@1 91.500 (91.500)
 * Testing Prec@1 89.340
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.135 (0.135)	Data 0.107 (0.107)	Loss 0.1172 (0.1172)	Prec@1 95.000 (95.000)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.039 (0.043)	Data 0.026 (0.027)	Loss 0.0692 (0.1126)	Prec@1 98.500 (96.144)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.047 (0.042)	Data 0.029 (0.027)	Loss 0.0881 (0.1135)	Prec@1 97.000 (96.095)
 * Training Prec@1 96.088
Test: [0/50]	Time 0.127 (0.127)	Loss 0.2633 (0.2633)	Prec@1 92.000 (92.000)
 * Testing Prec@1 89.410
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.102 (0.102)	Data 0.074 (0.074)	Loss 0.0761 (0.0761)	Prec@1 98.000 (98.000)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.038 (0.042)	Data 0.023 (0.026)	Loss 0.1627 (0.1166)	Prec@1 93.500 (95.970)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.041 (0.041)	Data 0.026 (0.025)	Loss 0.1532 (0.1145)	Prec@1 95.500 (96.087)
 * Training Prec@1 96.074
Test: [0/50]	Time 0.150 (0.150)	Loss 0.2736 (0.2736)	Prec@1 92.000 (92.000)
 * Testing Prec@1 89.420
