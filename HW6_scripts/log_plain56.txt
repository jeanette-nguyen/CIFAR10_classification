Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'plainnet56'
Epoch: [0/80][0/250]	LR: 0.1	Time 0.661 (0.661)	Data 0.122 (0.122)	Loss 2.3367 (2.3367)	Prec@1 11.000 (11.000)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.057 (0.064)	Data 0.001 (0.002)	Loss 2.2629 (2.2837)	Prec@1 12.500 (11.698)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.057 (0.061)	Data 0.001 (0.002)	Loss 2.1391 (2.2305)	Prec@1 21.000 (14.963)
 * Training Prec@1 16.386
main.py:153: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.112 (0.112)	Loss 2.7829 (2.7829)	Prec@1 21.000 (21.000)
 * Testing Prec@1 21.120
main.py:190: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:191: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:199: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 0.156 (0.156)	Data 0.102 (0.102)	Loss 2.0275 (2.0275)	Prec@1 26.000 (26.000)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 2.0594 (2.0479)	Prec@1 25.000 (23.540)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.057 (0.058)	Data 0.001 (0.002)	Loss 2.0276 (2.0220)	Prec@1 22.000 (24.520)
 * Training Prec@1 24.782
Test: [0/50]	Time 0.087 (0.087)	Loss 1.9548 (1.9548)	Prec@1 30.000 (30.000)
 * Testing Prec@1 26.480
Epoch: [2/80][0/250]	LR: 0.1	Time 0.160 (0.160)	Data 0.112 (0.112)	Loss 1.8307 (1.8307)	Prec@1 28.500 (28.500)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 2.0215 (1.9429)	Prec@1 26.000 (27.421)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 1.9552 (1.9327)	Prec@1 26.000 (27.861)
 * Training Prec@1 27.972
Test: [0/50]	Time 0.129 (0.129)	Loss 1.8370 (1.8370)	Prec@1 34.500 (34.500)
 * Testing Prec@1 29.640
Epoch: [3/80][0/250]	LR: 0.1	Time 0.129 (0.129)	Data 0.080 (0.080)	Loss 1.8854 (1.8854)	Prec@1 28.000 (28.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 1.9557 (1.8881)	Prec@1 26.000 (29.574)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 1.8190 (1.8779)	Prec@1 30.000 (29.851)
 * Training Prec@1 30.122
Test: [0/50]	Time 0.094 (0.094)	Loss 1.7539 (1.7539)	Prec@1 34.000 (34.000)
 * Testing Prec@1 31.770
Epoch: [4/80][0/250]	LR: 0.1	Time 0.173 (0.173)	Data 0.116 (0.116)	Loss 1.7780 (1.7780)	Prec@1 32.500 (32.500)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 1.8015 (1.8346)	Prec@1 34.000 (31.520)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.057 (0.058)	Data 0.001 (0.002)	Loss 1.8559 (1.8243)	Prec@1 30.500 (31.955)
 * Training Prec@1 32.270
Test: [0/50]	Time 0.094 (0.094)	Loss 1.8081 (1.8081)	Prec@1 34.500 (34.500)
 * Testing Prec@1 34.960
Epoch: [5/80][0/250]	LR: 0.1	Time 0.133 (0.133)	Data 0.087 (0.087)	Loss 1.6115 (1.6115)	Prec@1 41.000 (41.000)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 1.7402 (1.7464)	Prec@1 33.000 (35.054)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 1.7540 (1.7371)	Prec@1 38.500 (35.448)
 * Training Prec@1 35.746
Test: [0/50]	Time 0.147 (0.147)	Loss 1.7699 (1.7699)	Prec@1 29.500 (29.500)
 * Testing Prec@1 36.120
Epoch: [6/80][0/250]	LR: 0.1	Time 0.152 (0.152)	Data 0.097 (0.097)	Loss 1.6839 (1.6839)	Prec@1 38.500 (38.500)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 1.6745 (1.6724)	Prec@1 39.000 (37.906)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.059 (0.058)	Data 0.001 (0.002)	Loss 1.7083 (1.6618)	Prec@1 36.000 (38.410)
 * Training Prec@1 38.724
Test: [0/50]	Time 0.155 (0.155)	Loss 1.6025 (1.6025)	Prec@1 43.000 (43.000)
 * Testing Prec@1 39.200
Epoch: [7/80][0/250]	LR: 0.1	Time 0.208 (0.208)	Data 0.160 (0.160)	Loss 1.6161 (1.6161)	Prec@1 46.000 (46.000)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 1.5291 (1.6244)	Prec@1 47.500 (40.550)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 1.5788 (1.6127)	Prec@1 42.500 (40.794)
 * Training Prec@1 41.018
Test: [0/50]	Time 0.103 (0.103)	Loss 1.5134 (1.5134)	Prec@1 48.000 (48.000)
 * Testing Prec@1 41.840
Epoch: [8/80][0/250]	LR: 0.1	Time 0.132 (0.132)	Data 0.085 (0.085)	Loss 1.4815 (1.4815)	Prec@1 39.000 (39.000)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 1.4059 (1.5734)	Prec@1 46.500 (41.980)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 1.3945 (1.5596)	Prec@1 45.000 (42.609)
 * Training Prec@1 43.050
Test: [0/50]	Time 0.155 (0.155)	Loss 1.5640 (1.5640)	Prec@1 44.000 (44.000)
 * Testing Prec@1 43.030
Epoch: [9/80][0/250]	LR: 0.1	Time 0.153 (0.153)	Data 0.104 (0.104)	Loss 1.4962 (1.4962)	Prec@1 44.000 (44.000)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.059 (0.059)	Data 0.001 (0.003)	Loss 1.4747 (1.5134)	Prec@1 51.000 (44.941)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 1.5155 (1.4992)	Prec@1 46.500 (45.162)
 * Training Prec@1 45.480
Test: [0/50]	Time 0.124 (0.124)	Loss 1.6296 (1.6296)	Prec@1 43.500 (43.500)
 * Testing Prec@1 41.170
Epoch: [10/80][0/250]	LR: 0.1	Time 0.147 (0.147)	Data 0.105 (0.105)	Loss 1.4982 (1.4982)	Prec@1 39.500 (39.500)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 1.5161 (1.4453)	Prec@1 46.000 (47.485)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.059 (0.059)	Data 0.001 (0.002)	Loss 1.4942 (1.4423)	Prec@1 45.500 (47.669)
 * Training Prec@1 47.940
Test: [0/50]	Time 0.090 (0.090)	Loss 1.3815 (1.3815)	Prec@1 47.000 (47.000)
 * Testing Prec@1 44.760
Epoch: [11/80][0/250]	LR: 0.1	Time 0.149 (0.149)	Data 0.104 (0.104)	Loss 1.3282 (1.3282)	Prec@1 55.000 (55.000)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 1.3801 (1.3967)	Prec@1 47.500 (49.584)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 1.3417 (1.3812)	Prec@1 49.000 (49.970)
 * Training Prec@1 50.252
Test: [0/50]	Time 0.160 (0.160)	Loss 1.2970 (1.2970)	Prec@1 54.000 (54.000)
 * Testing Prec@1 51.310
Epoch: [12/80][0/250]	LR: 0.1	Time 0.135 (0.135)	Data 0.099 (0.099)	Loss 1.3930 (1.3930)	Prec@1 53.500 (53.500)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.059 (0.059)	Data 0.001 (0.002)	Loss 1.3738 (1.3308)	Prec@1 46.500 (51.906)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.057 (0.059)	Data 0.001 (0.002)	Loss 1.2357 (1.3264)	Prec@1 52.000 (52.022)
 * Training Prec@1 52.140
Test: [0/50]	Time 0.083 (0.083)	Loss 1.3161 (1.3161)	Prec@1 51.500 (51.500)
 * Testing Prec@1 52.610
Epoch: [13/80][0/250]	LR: 0.1	Time 0.129 (0.129)	Data 0.090 (0.090)	Loss 1.3157 (1.3157)	Prec@1 50.500 (50.500)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.002 (0.003)	Loss 1.2003 (1.2589)	Prec@1 53.500 (54.327)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 1.3243 (1.2694)	Prec@1 54.500 (54.152)
 * Training Prec@1 54.508
Test: [0/50]	Time 0.111 (0.111)	Loss 1.1634 (1.1634)	Prec@1 59.500 (59.500)
 * Testing Prec@1 55.310
Epoch: [14/80][0/250]	LR: 0.1	Time 0.171 (0.171)	Data 0.116 (0.116)	Loss 1.2490 (1.2490)	Prec@1 57.500 (57.500)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 1.1738 (1.2143)	Prec@1 59.000 (56.762)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 1.1197 (1.2105)	Prec@1 58.500 (56.639)
 * Training Prec@1 56.668
Test: [0/50]	Time 0.144 (0.144)	Loss 1.1681 (1.1681)	Prec@1 58.500 (58.500)
 * Testing Prec@1 55.810
Epoch: [15/80][0/250]	LR: 0.1	Time 0.130 (0.130)	Data 0.078 (0.078)	Loss 1.0827 (1.0827)	Prec@1 63.500 (63.500)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 1.3914 (1.1952)	Prec@1 51.000 (57.020)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 1.1574 (1.1813)	Prec@1 60.000 (57.555)
 * Training Prec@1 57.880
Test: [0/50]	Time 0.137 (0.137)	Loss 1.4612 (1.4612)	Prec@1 44.500 (44.500)
 * Testing Prec@1 49.810
Epoch: [16/80][0/250]	LR: 0.1	Time 0.161 (0.161)	Data 0.101 (0.101)	Loss 1.1382 (1.1382)	Prec@1 57.500 (57.500)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 1.2210 (1.1172)	Prec@1 56.000 (60.173)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.059 (0.058)	Data 0.001 (0.002)	Loss 1.0986 (1.1325)	Prec@1 60.000 (59.774)
 * Training Prec@1 59.814
Test: [0/50]	Time 0.159 (0.159)	Loss 1.1469 (1.1469)	Prec@1 56.000 (56.000)
 * Testing Prec@1 55.790
Epoch: [17/80][0/250]	LR: 0.1	Time 0.169 (0.169)	Data 0.111 (0.111)	Loss 0.9439 (0.9439)	Prec@1 65.500 (65.500)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 1.1573 (1.0828)	Prec@1 59.000 (61.480)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 1.1214 (1.0857)	Prec@1 62.000 (61.512)
 * Training Prec@1 61.466
Test: [0/50]	Time 0.122 (0.122)	Loss 1.1179 (1.1179)	Prec@1 58.500 (58.500)
 * Testing Prec@1 57.770
Epoch: [18/80][0/250]	LR: 0.1	Time 0.193 (0.193)	Data 0.125 (0.125)	Loss 1.0830 (1.0830)	Prec@1 60.500 (60.500)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 1.1855 (1.0445)	Prec@1 55.500 (62.960)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 1.1440 (1.0511)	Prec@1 57.000 (62.876)
 * Training Prec@1 62.882
Test: [0/50]	Time 0.107 (0.107)	Loss 1.0743 (1.0743)	Prec@1 62.500 (62.500)
 * Testing Prec@1 62.960
Epoch: [19/80][0/250]	LR: 0.1	Time 0.135 (0.135)	Data 0.085 (0.085)	Loss 0.8999 (0.8999)	Prec@1 70.000 (70.000)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.059 (0.059)	Data 0.001 (0.002)	Loss 1.0517 (1.0229)	Prec@1 59.500 (64.084)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.059 (0.058)	Data 0.002 (0.002)	Loss 1.0806 (1.0241)	Prec@1 62.500 (64.000)
 * Training Prec@1 64.272
Test: [0/50]	Time 0.097 (0.097)	Loss 1.0098 (1.0098)	Prec@1 62.000 (62.000)
 * Testing Prec@1 62.210
Epoch: [20/80][0/250]	LR: 0.1	Time 0.177 (0.177)	Data 0.127 (0.127)	Loss 1.0646 (1.0646)	Prec@1 59.000 (59.000)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 1.0484 (0.9970)	Prec@1 62.500 (65.079)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.9322 (0.9894)	Prec@1 69.500 (65.502)
 * Training Prec@1 65.668
Test: [0/50]	Time 0.153 (0.153)	Loss 1.0660 (1.0660)	Prec@1 60.500 (60.500)
 * Testing Prec@1 61.950
Epoch: [21/80][0/250]	LR: 0.1	Time 0.166 (0.166)	Data 0.112 (0.112)	Loss 0.8654 (0.8654)	Prec@1 71.500 (71.500)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.7649 (0.9475)	Prec@1 74.500 (66.802)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.059 (0.059)	Data 0.002 (0.002)	Loss 0.9108 (0.9484)	Prec@1 68.000 (66.774)
 * Training Prec@1 66.832
Test: [0/50]	Time 0.153 (0.153)	Loss 1.1641 (1.1641)	Prec@1 62.500 (62.500)
 * Testing Prec@1 60.320
Epoch: [22/80][0/250]	LR: 0.1	Time 0.169 (0.169)	Data 0.116 (0.116)	Loss 0.9679 (0.9679)	Prec@1 67.000 (67.000)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.9144 (0.9195)	Prec@1 69.500 (68.282)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 1.0192 (0.9193)	Prec@1 64.500 (68.147)
 * Training Prec@1 68.296
Test: [0/50]	Time 0.118 (0.118)	Loss 1.0958 (1.0958)	Prec@1 65.000 (65.000)
 * Testing Prec@1 63.580
Epoch: [23/80][0/250]	LR: 0.1	Time 0.149 (0.149)	Data 0.106 (0.106)	Loss 0.8354 (0.8354)	Prec@1 67.000 (67.000)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.061 (0.059)	Data 0.001 (0.003)	Loss 0.8508 (0.8784)	Prec@1 71.500 (69.579)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.059 (0.059)	Data 0.003 (0.003)	Loss 0.8097 (0.8856)	Prec@1 72.000 (69.221)
 * Training Prec@1 69.088
Test: [0/50]	Time 0.135 (0.135)	Loss 0.9528 (0.9528)	Prec@1 69.500 (69.500)
 * Testing Prec@1 67.490
Epoch: [24/80][0/250]	LR: 0.1	Time 0.154 (0.154)	Data 0.110 (0.110)	Loss 0.8893 (0.8893)	Prec@1 69.000 (69.000)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.059 (0.059)	Data 0.001 (0.003)	Loss 0.8723 (0.8716)	Prec@1 69.000 (69.792)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.059 (0.059)	Data 0.002 (0.002)	Loss 1.0472 (0.8720)	Prec@1 62.000 (69.826)
 * Training Prec@1 70.180
Test: [0/50]	Time 0.159 (0.159)	Loss 0.8851 (0.8851)	Prec@1 68.000 (68.000)
 * Testing Prec@1 67.840
Epoch: [25/80][0/250]	LR: 0.1	Time 0.154 (0.154)	Data 0.103 (0.103)	Loss 0.8742 (0.8742)	Prec@1 75.000 (75.000)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.8410 (0.8357)	Prec@1 71.000 (71.411)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.7465 (0.8373)	Prec@1 75.000 (71.007)
 * Training Prec@1 70.930
Test: [0/50]	Time 0.121 (0.121)	Loss 0.9800 (0.9800)	Prec@1 67.500 (67.500)
 * Testing Prec@1 66.630
Epoch: [26/80][0/250]	LR: 0.1	Time 0.157 (0.157)	Data 0.098 (0.098)	Loss 0.8661 (0.8661)	Prec@1 69.000 (69.000)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.7626 (0.8174)	Prec@1 74.500 (71.446)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.006 (0.002)	Loss 0.6686 (0.8118)	Prec@1 78.000 (71.731)
 * Training Prec@1 71.702
Test: [0/50]	Time 0.124 (0.124)	Loss 1.2329 (1.2329)	Prec@1 57.500 (57.500)
 * Testing Prec@1 59.810
Epoch: [27/80][0/250]	LR: 0.1	Time 0.162 (0.162)	Data 0.100 (0.100)	Loss 0.7197 (0.7197)	Prec@1 74.500 (74.500)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.059 (0.059)	Data 0.001 (0.003)	Loss 0.7532 (0.7903)	Prec@1 73.500 (72.797)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.8307 (0.7965)	Prec@1 72.500 (72.540)
 * Training Prec@1 72.516
Test: [0/50]	Time 0.146 (0.146)	Loss 0.7823 (0.7823)	Prec@1 70.000 (70.000)
 * Testing Prec@1 68.460
Epoch: [28/80][0/250]	LR: 0.1	Time 0.138 (0.138)	Data 0.084 (0.084)	Loss 0.7077 (0.7077)	Prec@1 73.000 (73.000)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.8269 (0.7732)	Prec@1 74.500 (73.653)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.059 (0.058)	Data 0.001 (0.002)	Loss 0.8572 (0.7776)	Prec@1 72.500 (73.527)
 * Training Prec@1 73.464
Test: [0/50]	Time 0.118 (0.118)	Loss 0.9627 (0.9627)	Prec@1 68.000 (68.000)
 * Testing Prec@1 64.400
Epoch: [29/80][0/250]	LR: 0.1	Time 0.128 (0.128)	Data 0.079 (0.079)	Loss 0.8343 (0.8343)	Prec@1 72.000 (72.000)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.8090 (0.7659)	Prec@1 72.500 (73.634)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.059 (0.058)	Data 0.002 (0.002)	Loss 0.6694 (0.7585)	Prec@1 77.000 (74.070)
 * Training Prec@1 73.952
Test: [0/50]	Time 0.152 (0.152)	Loss 0.7198 (0.7198)	Prec@1 78.500 (78.500)
 * Testing Prec@1 69.740
Epoch: [30/80][0/250]	LR: 0.1	Time 0.145 (0.145)	Data 0.110 (0.110)	Loss 0.7940 (0.7940)	Prec@1 73.500 (73.500)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.9278 (0.7440)	Prec@1 66.000 (74.228)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 0.6273 (0.7381)	Prec@1 79.000 (74.331)
 * Training Prec@1 74.380
Test: [0/50]	Time 0.167 (0.167)	Loss 0.8978 (0.8978)	Prec@1 70.500 (70.500)
 * Testing Prec@1 69.000
Epoch: [31/80][0/250]	LR: 0.1	Time 0.152 (0.152)	Data 0.101 (0.101)	Loss 0.8578 (0.8578)	Prec@1 73.000 (73.000)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.002 (0.003)	Loss 0.9152 (0.7187)	Prec@1 69.000 (75.327)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 0.6739 (0.7284)	Prec@1 75.500 (74.818)
 * Training Prec@1 74.776
Test: [0/50]	Time 0.137 (0.137)	Loss 0.9050 (0.9050)	Prec@1 67.500 (67.500)
 * Testing Prec@1 68.540
Epoch: [32/80][0/250]	LR: 0.1	Time 0.182 (0.182)	Data 0.127 (0.127)	Loss 0.7058 (0.7058)	Prec@1 73.500 (73.500)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.6742 (0.7046)	Prec@1 75.000 (75.797)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.6946 (0.7121)	Prec@1 76.500 (75.562)
 * Training Prec@1 75.612
Test: [0/50]	Time 0.117 (0.117)	Loss 0.9666 (0.9666)	Prec@1 69.000 (69.000)
 * Testing Prec@1 67.980
Epoch: [33/80][0/250]	LR: 0.1	Time 0.162 (0.162)	Data 0.112 (0.112)	Loss 0.6002 (0.6002)	Prec@1 81.000 (81.000)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.059 (0.059)	Data 0.001 (0.003)	Loss 0.7726 (0.6886)	Prec@1 73.500 (76.139)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.7576 (0.6945)	Prec@1 75.500 (76.030)
 * Training Prec@1 75.920
Test: [0/50]	Time 0.159 (0.159)	Loss 0.7454 (0.7454)	Prec@1 75.000 (75.000)
 * Testing Prec@1 73.030
Epoch: [34/80][0/250]	LR: 0.1	Time 0.155 (0.155)	Data 0.109 (0.109)	Loss 0.6182 (0.6182)	Prec@1 79.000 (79.000)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.002 (0.003)	Loss 0.6725 (0.6752)	Prec@1 79.000 (76.579)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.6852 (0.6850)	Prec@1 81.000 (76.276)
 * Training Prec@1 76.358
Test: [0/50]	Time 0.144 (0.144)	Loss 0.9244 (0.9244)	Prec@1 70.500 (70.500)
 * Testing Prec@1 65.330
Epoch: [35/80][0/250]	LR: 0.1	Time 0.143 (0.143)	Data 0.099 (0.099)	Loss 0.7433 (0.7433)	Prec@1 76.000 (76.000)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.002 (0.003)	Loss 0.7937 (0.6814)	Prec@1 73.000 (76.257)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.060 (0.058)	Data 0.001 (0.002)	Loss 0.7665 (0.6789)	Prec@1 74.500 (76.634)
 * Training Prec@1 76.734
Test: [0/50]	Time 0.120 (0.120)	Loss 0.9779 (0.9779)	Prec@1 67.000 (67.000)
 * Testing Prec@1 67.350
Epoch: [36/80][0/250]	LR: 0.1	Time 0.155 (0.155)	Data 0.105 (0.105)	Loss 0.5479 (0.5479)	Prec@1 82.000 (82.000)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.057 (0.059)	Data 0.002 (0.003)	Loss 0.6832 (0.6632)	Prec@1 77.000 (77.252)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.6710 (0.6631)	Prec@1 78.500 (77.276)
 * Training Prec@1 77.146
Test: [0/50]	Time 0.155 (0.155)	Loss 0.6785 (0.6785)	Prec@1 73.500 (73.500)
 * Testing Prec@1 73.240
Epoch: [37/80][0/250]	LR: 0.1	Time 0.162 (0.162)	Data 0.114 (0.114)	Loss 0.6489 (0.6489)	Prec@1 79.500 (79.500)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.002 (0.003)	Loss 0.6434 (0.6421)	Prec@1 76.000 (77.871)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.6723 (0.6491)	Prec@1 77.500 (77.726)
 * Training Prec@1 77.596
Test: [0/50]	Time 0.096 (0.096)	Loss 0.6876 (0.6876)	Prec@1 78.500 (78.500)
 * Testing Prec@1 72.290
Epoch: [38/80][0/250]	LR: 0.1	Time 0.144 (0.144)	Data 0.095 (0.095)	Loss 0.7676 (0.7676)	Prec@1 70.500 (70.500)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.5924 (0.6392)	Prec@1 79.000 (78.381)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.064 (0.058)	Data 0.002 (0.002)	Loss 0.7078 (0.6487)	Prec@1 75.500 (77.868)
 * Training Prec@1 77.896
Test: [0/50]	Time 0.110 (0.110)	Loss 0.6872 (0.6872)	Prec@1 76.500 (76.500)
 * Testing Prec@1 74.010
Epoch: [39/80][0/250]	LR: 0.1	Time 0.135 (0.135)	Data 0.084 (0.084)	Loss 0.4731 (0.4731)	Prec@1 84.000 (84.000)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.5606 (0.6193)	Prec@1 80.500 (79.035)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.058 (0.058)	Data 0.002 (0.002)	Loss 0.6410 (0.6333)	Prec@1 74.500 (78.510)
 * Training Prec@1 78.320
Test: [0/50]	Time 0.103 (0.103)	Loss 0.6527 (0.6527)	Prec@1 73.500 (73.500)
 * Testing Prec@1 75.730
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.174 (0.174)	Data 0.117 (0.117)	Loss 0.5208 (0.5208)	Prec@1 81.000 (81.000)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.003 (0.003)	Loss 0.5499 (0.5244)	Prec@1 80.000 (81.985)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.056 (0.059)	Data 0.002 (0.002)	Loss 0.4856 (0.5111)	Prec@1 85.000 (82.445)
 * Training Prec@1 82.606
Test: [0/50]	Time 0.151 (0.151)	Loss 0.4592 (0.4592)	Prec@1 83.000 (83.000)
 * Testing Prec@1 81.270
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.163 (0.163)	Data 0.103 (0.103)	Loss 0.3897 (0.3897)	Prec@1 86.500 (86.500)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.3824 (0.4621)	Prec@1 84.500 (84.035)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.4456 (0.4674)	Prec@1 84.000 (83.786)
 * Training Prec@1 83.816
Test: [0/50]	Time 0.100 (0.100)	Loss 0.4347 (0.4347)	Prec@1 84.500 (84.500)
 * Testing Prec@1 81.960
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.151 (0.151)	Data 0.095 (0.095)	Loss 0.4262 (0.4262)	Prec@1 83.000 (83.000)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.003)	Loss 0.4893 (0.4491)	Prec@1 82.500 (84.460)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.4065 (0.4533)	Prec@1 87.000 (84.405)
 * Training Prec@1 84.476
Test: [0/50]	Time 0.162 (0.162)	Loss 0.4260 (0.4260)	Prec@1 85.000 (85.000)
 * Testing Prec@1 82.140
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.143 (0.143)	Data 0.099 (0.099)	Loss 0.5011 (0.5011)	Prec@1 82.500 (82.500)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.3889 (0.4439)	Prec@1 84.500 (84.762)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.4708 (0.4417)	Prec@1 83.000 (84.933)
 * Training Prec@1 84.882
Test: [0/50]	Time 0.155 (0.155)	Loss 0.4228 (0.4228)	Prec@1 86.000 (86.000)
 * Testing Prec@1 82.220
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.173 (0.173)	Data 0.118 (0.118)	Loss 0.4008 (0.4008)	Prec@1 87.500 (87.500)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.5342 (0.4352)	Prec@1 83.000 (85.198)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.4611 (0.4340)	Prec@1 82.000 (85.189)
 * Training Prec@1 85.258
Test: [0/50]	Time 0.129 (0.129)	Loss 0.4033 (0.4033)	Prec@1 87.000 (87.000)
 * Testing Prec@1 82.480
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.174 (0.174)	Data 0.115 (0.115)	Loss 0.4505 (0.4505)	Prec@1 87.500 (87.500)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.3484 (0.4334)	Prec@1 89.000 (84.901)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.057 (0.059)	Data 0.002 (0.002)	Loss 0.4720 (0.4280)	Prec@1 86.000 (85.085)
 * Training Prec@1 85.070
Test: [0/50]	Time 0.162 (0.162)	Loss 0.4215 (0.4215)	Prec@1 84.500 (84.500)
 * Testing Prec@1 82.560
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.136 (0.136)	Data 0.090 (0.090)	Loss 0.6454 (0.6454)	Prec@1 77.500 (77.500)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.3930 (0.4179)	Prec@1 85.500 (85.396)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.059 (0.058)	Data 0.001 (0.002)	Loss 0.3528 (0.4221)	Prec@1 88.000 (85.256)
 * Training Prec@1 85.364
Test: [0/50]	Time 0.137 (0.137)	Loss 0.3977 (0.3977)	Prec@1 86.000 (86.000)
 * Testing Prec@1 82.580
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 0.173 (0.173)	Data 0.126 (0.126)	Loss 0.4225 (0.4225)	Prec@1 85.000 (85.000)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.3949 (0.4154)	Prec@1 86.000 (85.530)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.3523 (0.4170)	Prec@1 88.000 (85.515)
 * Training Prec@1 85.550
Test: [0/50]	Time 0.088 (0.088)	Loss 0.4112 (0.4112)	Prec@1 84.000 (84.000)
 * Testing Prec@1 82.800
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.139 (0.139)	Data 0.106 (0.106)	Loss 0.3611 (0.3611)	Prec@1 88.000 (88.000)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.3038 (0.4091)	Prec@1 90.000 (85.698)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.4893 (0.4082)	Prec@1 81.500 (85.903)
 * Training Prec@1 85.866
Test: [0/50]	Time 0.111 (0.111)	Loss 0.4515 (0.4515)	Prec@1 83.500 (83.500)
 * Testing Prec@1 82.700
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.172 (0.172)	Data 0.125 (0.125)	Loss 0.3867 (0.3867)	Prec@1 88.500 (88.500)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.4178 (0.4023)	Prec@1 86.500 (86.178)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.4126 (0.4052)	Prec@1 84.500 (85.945)
 * Training Prec@1 86.090
Test: [0/50]	Time 0.110 (0.110)	Loss 0.4049 (0.4049)	Prec@1 86.500 (86.500)
 * Testing Prec@1 82.820
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.171 (0.171)	Data 0.121 (0.121)	Loss 0.4201 (0.4201)	Prec@1 85.000 (85.000)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.003)	Loss 0.3897 (0.3860)	Prec@1 86.500 (86.609)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.5666 (0.3981)	Prec@1 79.000 (86.346)
 * Training Prec@1 86.282
Test: [0/50]	Time 0.108 (0.108)	Loss 0.3989 (0.3989)	Prec@1 87.500 (87.500)
 * Testing Prec@1 82.760
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 0.145 (0.145)	Data 0.096 (0.096)	Loss 0.4352 (0.4352)	Prec@1 84.000 (84.000)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.003)	Loss 0.3978 (0.4014)	Prec@1 87.000 (86.213)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.059 (0.059)	Data 0.001 (0.002)	Loss 0.3779 (0.3980)	Prec@1 87.000 (86.291)
 * Training Prec@1 86.382
Test: [0/50]	Time 0.145 (0.145)	Loss 0.4499 (0.4499)	Prec@1 84.000 (84.000)
 * Testing Prec@1 82.810
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.162 (0.162)	Data 0.115 (0.115)	Loss 0.3145 (0.3145)	Prec@1 89.000 (89.000)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.059 (0.059)	Data 0.001 (0.003)	Loss 0.4869 (0.3932)	Prec@1 84.500 (86.178)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.059 (0.059)	Data 0.002 (0.002)	Loss 0.4521 (0.3931)	Prec@1 84.500 (86.338)
 * Training Prec@1 86.446
Test: [0/50]	Time 0.117 (0.117)	Loss 0.4460 (0.4460)	Prec@1 84.000 (84.000)
 * Testing Prec@1 82.840
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 0.129 (0.129)	Data 0.090 (0.090)	Loss 0.3631 (0.3631)	Prec@1 87.000 (87.000)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.060 (0.059)	Data 0.002 (0.002)	Loss 0.3121 (0.3822)	Prec@1 89.000 (86.658)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.059 (0.059)	Data 0.002 (0.002)	Loss 0.2865 (0.3844)	Prec@1 89.000 (86.692)
 * Training Prec@1 86.732
Test: [0/50]	Time 0.089 (0.089)	Loss 0.4218 (0.4218)	Prec@1 84.000 (84.000)
 * Testing Prec@1 82.760
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.130 (0.130)	Data 0.083 (0.083)	Loss 0.4225 (0.4225)	Prec@1 84.000 (84.000)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.3305 (0.3754)	Prec@1 88.500 (86.970)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 0.2991 (0.3776)	Prec@1 87.500 (86.756)
 * Training Prec@1 86.710
Test: [0/50]	Time 0.138 (0.138)	Loss 0.4057 (0.4057)	Prec@1 84.500 (84.500)
 * Testing Prec@1 82.950
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.139 (0.139)	Data 0.088 (0.088)	Loss 0.4127 (0.4127)	Prec@1 86.000 (86.000)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.059 (0.059)	Data 0.002 (0.003)	Loss 0.4451 (0.3749)	Prec@1 84.000 (87.035)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.059 (0.059)	Data 0.002 (0.002)	Loss 0.3568 (0.3802)	Prec@1 84.500 (86.811)
 * Training Prec@1 86.972
Test: [0/50]	Time 0.095 (0.095)	Loss 0.3948 (0.3948)	Prec@1 86.500 (86.500)
 * Testing Prec@1 83.050
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.165 (0.165)	Data 0.102 (0.102)	Loss 0.3186 (0.3186)	Prec@1 89.500 (89.500)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.3654 (0.3652)	Prec@1 86.000 (87.292)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.3698 (0.3715)	Prec@1 88.500 (87.162)
 * Training Prec@1 87.220
Test: [0/50]	Time 0.139 (0.139)	Loss 0.4015 (0.4015)	Prec@1 85.500 (85.500)
 * Testing Prec@1 82.830
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.152 (0.152)	Data 0.102 (0.102)	Loss 0.3867 (0.3867)	Prec@1 84.500 (84.500)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.3628 (0.3704)	Prec@1 89.000 (87.035)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.3629 (0.3640)	Prec@1 88.500 (87.346)
 * Training Prec@1 87.312
Test: [0/50]	Time 0.147 (0.147)	Loss 0.4224 (0.4224)	Prec@1 85.500 (85.500)
 * Testing Prec@1 82.830
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.131 (0.131)	Data 0.081 (0.081)	Loss 0.3570 (0.3570)	Prec@1 88.000 (88.000)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.3640 (0.3544)	Prec@1 86.000 (87.455)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.2818 (0.3651)	Prec@1 90.500 (87.264)
 * Training Prec@1 87.246
Test: [0/50]	Time 0.091 (0.091)	Loss 0.3925 (0.3925)	Prec@1 84.500 (84.500)
 * Testing Prec@1 82.510
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.170 (0.170)	Data 0.115 (0.115)	Loss 0.3972 (0.3972)	Prec@1 84.500 (84.500)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.4186 (0.3612)	Prec@1 84.000 (87.446)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.059 (0.059)	Data 0.001 (0.002)	Loss 0.3431 (0.3691)	Prec@1 86.500 (87.311)
 * Training Prec@1 87.312
Test: [0/50]	Time 0.154 (0.154)	Loss 0.4057 (0.4057)	Prec@1 85.000 (85.000)
 * Testing Prec@1 83.420
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.165 (0.165)	Data 0.111 (0.111)	Loss 0.3946 (0.3946)	Prec@1 88.500 (88.500)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.4406 (0.3370)	Prec@1 84.000 (88.257)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.3779 (0.3375)	Prec@1 86.000 (88.231)
 * Training Prec@1 88.238
Test: [0/50]	Time 0.152 (0.152)	Loss 0.3950 (0.3950)	Prec@1 86.000 (86.000)
 * Testing Prec@1 83.630
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.181 (0.181)	Data 0.131 (0.131)	Loss 0.3327 (0.3327)	Prec@1 87.500 (87.500)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.059 (0.059)	Data 0.001 (0.003)	Loss 0.2778 (0.3376)	Prec@1 89.500 (88.297)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.3418 (0.3378)	Prec@1 90.000 (88.408)
 * Training Prec@1 88.432
Test: [0/50]	Time 0.111 (0.111)	Loss 0.3909 (0.3909)	Prec@1 86.000 (86.000)
 * Testing Prec@1 83.480
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.163 (0.163)	Data 0.119 (0.119)	Loss 0.4184 (0.4184)	Prec@1 87.000 (87.000)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.3497 (0.3394)	Prec@1 87.000 (88.332)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.2892 (0.3314)	Prec@1 90.500 (88.512)
 * Training Prec@1 88.472
Test: [0/50]	Time 0.112 (0.112)	Loss 0.3955 (0.3955)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.460
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 0.129 (0.129)	Data 0.089 (0.089)	Loss 0.3079 (0.3079)	Prec@1 90.500 (90.500)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.003)	Loss 0.2560 (0.3321)	Prec@1 92.000 (88.337)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.059 (0.058)	Data 0.001 (0.002)	Loss 0.2950 (0.3285)	Prec@1 87.000 (88.520)
 * Training Prec@1 88.494
Test: [0/50]	Time 0.100 (0.100)	Loss 0.3919 (0.3919)	Prec@1 85.000 (85.000)
 * Testing Prec@1 83.570
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 0.134 (0.134)	Data 0.092 (0.092)	Loss 0.2230 (0.2230)	Prec@1 94.000 (94.000)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.3386 (0.3253)	Prec@1 88.500 (88.738)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 0.3531 (0.3263)	Prec@1 87.500 (88.629)
 * Training Prec@1 88.558
Test: [0/50]	Time 0.094 (0.094)	Loss 0.3868 (0.3868)	Prec@1 86.000 (86.000)
 * Testing Prec@1 83.650
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.138 (0.138)	Data 0.083 (0.083)	Loss 0.2973 (0.2973)	Prec@1 91.500 (91.500)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.4043 (0.3278)	Prec@1 85.500 (88.663)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.058)	Data 0.001 (0.002)	Loss 0.3348 (0.3256)	Prec@1 87.000 (88.667)
 * Training Prec@1 88.550
Test: [0/50]	Time 0.161 (0.161)	Loss 0.3802 (0.3802)	Prec@1 86.500 (86.500)
 * Testing Prec@1 83.800
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 0.169 (0.169)	Data 0.119 (0.119)	Loss 0.3077 (0.3077)	Prec@1 90.000 (90.000)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.056 (0.059)	Data 0.002 (0.003)	Loss 0.2723 (0.3236)	Prec@1 91.000 (88.896)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.3582 (0.3243)	Prec@1 88.000 (88.759)
 * Training Prec@1 88.636
Test: [0/50]	Time 0.114 (0.114)	Loss 0.3833 (0.3833)	Prec@1 85.500 (85.500)
 * Testing Prec@1 83.780
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.178 (0.178)	Data 0.120 (0.120)	Loss 0.3087 (0.3087)	Prec@1 88.500 (88.500)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.3598 (0.3302)	Prec@1 88.000 (88.653)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.059 (0.059)	Data 0.001 (0.002)	Loss 0.3734 (0.3300)	Prec@1 89.500 (88.567)
 * Training Prec@1 88.644
Test: [0/50]	Time 0.150 (0.150)	Loss 0.3800 (0.3800)	Prec@1 85.500 (85.500)
 * Testing Prec@1 83.770
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.176 (0.176)	Data 0.121 (0.121)	Loss 0.2763 (0.2763)	Prec@1 91.000 (91.000)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.003)	Loss 0.3868 (0.3285)	Prec@1 86.000 (88.347)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.3801 (0.3229)	Prec@1 88.000 (88.764)
 * Training Prec@1 88.752
Test: [0/50]	Time 0.135 (0.135)	Loss 0.3707 (0.3707)	Prec@1 87.000 (87.000)
 * Testing Prec@1 83.790
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 0.156 (0.156)	Data 0.106 (0.106)	Loss 0.3494 (0.3494)	Prec@1 86.500 (86.500)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.3286 (0.3273)	Prec@1 88.000 (88.599)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.3557 (0.3261)	Prec@1 87.500 (88.649)
 * Training Prec@1 88.714
Test: [0/50]	Time 0.142 (0.142)	Loss 0.3661 (0.3661)	Prec@1 86.500 (86.500)
 * Testing Prec@1 83.640
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.138 (0.138)	Data 0.083 (0.083)	Loss 0.4744 (0.4744)	Prec@1 86.000 (86.000)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.2813 (0.3245)	Prec@1 91.000 (88.748)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.3037 (0.3251)	Prec@1 88.500 (88.769)
 * Training Prec@1 88.698
Test: [0/50]	Time 0.101 (0.101)	Loss 0.3654 (0.3654)	Prec@1 87.000 (87.000)
 * Testing Prec@1 83.830
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.145 (0.145)	Data 0.098 (0.098)	Loss 0.3607 (0.3607)	Prec@1 88.000 (88.000)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.004 (0.003)	Loss 0.2327 (0.3247)	Prec@1 92.000 (88.713)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.059 (0.059)	Data 0.002 (0.002)	Loss 0.3311 (0.3245)	Prec@1 88.000 (88.716)
 * Training Prec@1 88.728
Test: [0/50]	Time 0.113 (0.113)	Loss 0.3677 (0.3677)	Prec@1 87.500 (87.500)
 * Testing Prec@1 83.680
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.129 (0.129)	Data 0.079 (0.079)	Loss 0.2538 (0.2538)	Prec@1 92.000 (92.000)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.3378 (0.3234)	Prec@1 88.000 (88.668)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.3043 (0.3215)	Prec@1 89.000 (88.776)
 * Training Prec@1 88.786
Test: [0/50]	Time 0.152 (0.152)	Loss 0.3743 (0.3743)	Prec@1 87.000 (87.000)
 * Testing Prec@1 83.700
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 0.152 (0.152)	Data 0.102 (0.102)	Loss 0.3141 (0.3141)	Prec@1 89.000 (89.000)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.003)	Loss 0.3783 (0.3227)	Prec@1 85.500 (88.703)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.059 (0.059)	Data 0.001 (0.002)	Loss 0.4235 (0.3239)	Prec@1 85.000 (88.719)
 * Training Prec@1 88.680
Test: [0/50]	Time 0.149 (0.149)	Loss 0.3777 (0.3777)	Prec@1 85.500 (85.500)
 * Testing Prec@1 83.560
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.151 (0.151)	Data 0.096 (0.096)	Loss 0.2941 (0.2941)	Prec@1 89.500 (89.500)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.3545 (0.3214)	Prec@1 87.500 (88.926)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.059 (0.059)	Data 0.002 (0.002)	Loss 0.2899 (0.3229)	Prec@1 87.500 (88.900)
 * Training Prec@1 88.946
Test: [0/50]	Time 0.149 (0.149)	Loss 0.3732 (0.3732)	Prec@1 86.000 (86.000)
 * Testing Prec@1 83.680
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.186 (0.186)	Data 0.128 (0.128)	Loss 0.4078 (0.4078)	Prec@1 85.000 (85.000)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.003)	Loss 0.3337 (0.3202)	Prec@1 90.000 (88.896)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.3194 (0.3214)	Prec@1 90.500 (88.871)
 * Training Prec@1 88.924
Test: [0/50]	Time 0.155 (0.155)	Loss 0.3809 (0.3809)	Prec@1 85.500 (85.500)
 * Testing Prec@1 83.820
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.148 (0.148)	Data 0.109 (0.109)	Loss 0.3423 (0.3423)	Prec@1 86.000 (86.000)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.059 (0.059)	Data 0.001 (0.003)	Loss 0.3457 (0.3127)	Prec@1 88.000 (89.124)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.3316 (0.3190)	Prec@1 87.500 (88.925)
 * Training Prec@1 88.936
Test: [0/50]	Time 0.150 (0.150)	Loss 0.3822 (0.3822)	Prec@1 85.500 (85.500)
 * Testing Prec@1 83.840
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 0.120 (0.120)	Data 0.079 (0.079)	Loss 0.4001 (0.4001)	Prec@1 86.500 (86.500)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.3130 (0.3239)	Prec@1 88.000 (88.837)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.059 (0.059)	Data 0.002 (0.002)	Loss 0.3690 (0.3226)	Prec@1 87.500 (88.838)
 * Training Prec@1 88.930
Test: [0/50]	Time 0.152 (0.152)	Loss 0.3779 (0.3779)	Prec@1 86.000 (86.000)
 * Testing Prec@1 83.690
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.161 (0.161)	Data 0.117 (0.117)	Loss 0.2558 (0.2558)	Prec@1 91.500 (91.500)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.059 (0.059)	Data 0.001 (0.003)	Loss 0.2690 (0.3186)	Prec@1 91.000 (88.881)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.059 (0.059)	Data 0.001 (0.002)	Loss 0.2782 (0.3180)	Prec@1 90.000 (88.990)
 * Training Prec@1 89.014
Test: [0/50]	Time 0.128 (0.128)	Loss 0.3660 (0.3660)	Prec@1 87.000 (87.000)
 * Testing Prec@1 83.690
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.135 (0.135)	Data 0.088 (0.088)	Loss 0.2821 (0.2821)	Prec@1 92.500 (92.500)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.001 (0.002)	Loss 0.2533 (0.3139)	Prec@1 92.000 (89.173)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.059)	Data 0.002 (0.002)	Loss 0.2509 (0.3157)	Prec@1 91.000 (89.090)
 * Training Prec@1 89.110
Test: [0/50]	Time 0.099 (0.099)	Loss 0.3678 (0.3678)	Prec@1 86.500 (86.500)
 * Testing Prec@1 83.750
