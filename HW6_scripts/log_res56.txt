Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'resnet56'
Epoch: [0/80][0/250]	LR: 0.1	Time 0.659 (0.659)	Data 0.104 (0.104)	Loss 2.5292 (2.5292)	Prec@1 10.500 (10.500)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.063 (0.070)	Data 0.001 (0.003)	Loss 2.2735 (2.4858)	Prec@1 12.500 (11.243)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.063 (0.066)	Data 0.001 (0.002)	Loss 2.1807 (2.3728)	Prec@1 12.000 (12.405)
 * Training Prec@1 13.970
main.py:153: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.138 (0.138)	Loss 2.1172 (2.1172)	Prec@1 27.000 (27.000)
 * Testing Prec@1 22.320
main.py:190: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:191: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:199: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 0.179 (0.179)	Data 0.127 (0.127)	Loss 2.0451 (2.0451)	Prec@1 23.500 (23.500)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.063 (0.064)	Data 0.002 (0.003)	Loss 1.9533 (1.9237)	Prec@1 28.000 (26.153)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 1.7399 (1.8429)	Prec@1 35.000 (29.896)
 * Training Prec@1 31.472
Test: [0/50]	Time 0.155 (0.155)	Loss 1.6882 (1.6882)	Prec@1 38.500 (38.500)
 * Testing Prec@1 39.560
Epoch: [2/80][0/250]	LR: 0.1	Time 0.168 (0.168)	Data 0.122 (0.122)	Loss 1.6134 (1.6134)	Prec@1 38.000 (38.000)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.063 (0.065)	Data 0.002 (0.003)	Loss 1.4149 (1.5642)	Prec@1 44.000 (41.723)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.063 (0.064)	Data 0.002 (0.002)	Loss 1.2950 (1.5044)	Prec@1 50.500 (44.264)
 * Training Prec@1 45.240
Test: [0/50]	Time 0.107 (0.107)	Loss 1.3673 (1.3673)	Prec@1 52.000 (52.000)
 * Testing Prec@1 49.940
Epoch: [3/80][0/250]	LR: 0.1	Time 0.180 (0.180)	Data 0.126 (0.126)	Loss 1.3835 (1.3835)	Prec@1 52.000 (52.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 1.3416 (1.2962)	Prec@1 50.000 (53.173)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.9976 (1.2512)	Prec@1 63.500 (54.838)
 * Training Prec@1 55.538
Test: [0/50]	Time 0.189 (0.189)	Loss 1.3374 (1.3374)	Prec@1 52.500 (52.500)
 * Testing Prec@1 55.700
Epoch: [4/80][0/250]	LR: 0.1	Time 0.188 (0.188)	Data 0.116 (0.116)	Loss 0.9830 (0.9830)	Prec@1 63.000 (63.000)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.063 (0.065)	Data 0.002 (0.003)	Loss 1.0867 (1.0765)	Prec@1 60.500 (60.906)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 1.0066 (1.0488)	Prec@1 62.000 (62.167)
 * Training Prec@1 63.050
Test: [0/50]	Time 0.111 (0.111)	Loss 1.0078 (1.0078)	Prec@1 63.000 (63.000)
 * Testing Prec@1 63.140
Epoch: [5/80][0/250]	LR: 0.1	Time 0.159 (0.159)	Data 0.103 (0.103)	Loss 0.7873 (0.7873)	Prec@1 71.500 (71.500)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.002 (0.003)	Loss 0.8822 (0.9001)	Prec@1 70.000 (68.079)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.064 (0.064)	Data 0.002 (0.002)	Loss 0.8261 (0.8807)	Prec@1 73.500 (68.679)
 * Training Prec@1 69.000
Test: [0/50]	Time 0.141 (0.141)	Loss 0.8038 (0.8038)	Prec@1 72.500 (72.500)
 * Testing Prec@1 66.390
Epoch: [6/80][0/250]	LR: 0.1	Time 0.159 (0.159)	Data 0.117 (0.117)	Loss 0.8167 (0.8167)	Prec@1 69.500 (69.500)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.7094 (0.7815)	Prec@1 76.500 (72.347)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.6531 (0.7729)	Prec@1 78.500 (72.876)
 * Training Prec@1 73.124
Test: [0/50]	Time 0.113 (0.113)	Loss 0.7915 (0.7915)	Prec@1 69.500 (69.500)
 * Testing Prec@1 70.310
Epoch: [7/80][0/250]	LR: 0.1	Time 0.164 (0.164)	Data 0.119 (0.119)	Loss 0.6374 (0.6374)	Prec@1 74.500 (74.500)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.7080 (0.7037)	Prec@1 76.000 (75.396)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.065 (0.064)	Data 0.001 (0.002)	Loss 0.6450 (0.6944)	Prec@1 76.500 (75.736)
 * Training Prec@1 76.034
Test: [0/50]	Time 0.111 (0.111)	Loss 0.8262 (0.8262)	Prec@1 71.000 (71.000)
 * Testing Prec@1 71.360
Epoch: [8/80][0/250]	LR: 0.1	Time 0.168 (0.168)	Data 0.103 (0.103)	Loss 0.6040 (0.6040)	Prec@1 77.500 (77.500)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.5560 (0.6315)	Prec@1 81.000 (78.050)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.6349 (0.6271)	Prec@1 77.000 (78.072)
 * Training Prec@1 78.340
Test: [0/50]	Time 0.107 (0.107)	Loss 0.7454 (0.7454)	Prec@1 73.000 (73.000)
 * Testing Prec@1 73.860
Epoch: [9/80][0/250]	LR: 0.1	Time 0.120 (0.120)	Data 0.078 (0.078)	Loss 0.5802 (0.5802)	Prec@1 78.000 (78.000)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.064 (0.064)	Data 0.002 (0.002)	Loss 0.4740 (0.5590)	Prec@1 83.500 (80.876)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.5615 (0.5660)	Prec@1 81.000 (80.495)
 * Training Prec@1 80.528
Test: [0/50]	Time 0.143 (0.143)	Loss 0.5831 (0.5831)	Prec@1 81.000 (81.000)
 * Testing Prec@1 77.190
Epoch: [10/80][0/250]	LR: 0.1	Time 0.158 (0.158)	Data 0.108 (0.108)	Loss 0.4619 (0.4619)	Prec@1 86.500 (86.500)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.4032 (0.5296)	Prec@1 86.000 (81.520)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.5534 (0.5322)	Prec@1 78.500 (81.517)
 * Training Prec@1 81.558
Test: [0/50]	Time 0.144 (0.144)	Loss 0.5736 (0.5736)	Prec@1 79.000 (79.000)
 * Testing Prec@1 79.950
Epoch: [11/80][0/250]	LR: 0.1	Time 0.161 (0.161)	Data 0.112 (0.112)	Loss 0.4806 (0.4806)	Prec@1 81.500 (81.500)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.003)	Loss 0.5261 (0.5024)	Prec@1 81.000 (82.446)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.002 (0.002)	Loss 0.4682 (0.4982)	Prec@1 85.000 (82.791)
 * Training Prec@1 82.858
Test: [0/50]	Time 0.152 (0.152)	Loss 0.7423 (0.7423)	Prec@1 77.000 (77.000)
 * Testing Prec@1 77.340
Epoch: [12/80][0/250]	LR: 0.1	Time 0.124 (0.124)	Data 0.074 (0.074)	Loss 0.5026 (0.5026)	Prec@1 81.000 (81.000)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.4904 (0.4648)	Prec@1 85.500 (83.921)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.4682 (0.4667)	Prec@1 81.000 (83.806)
 * Training Prec@1 83.690
Test: [0/50]	Time 0.130 (0.130)	Loss 0.5791 (0.5791)	Prec@1 77.500 (77.500)
 * Testing Prec@1 79.090
Epoch: [13/80][0/250]	LR: 0.1	Time 0.196 (0.196)	Data 0.137 (0.137)	Loss 0.4542 (0.4542)	Prec@1 85.500 (85.500)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.064 (0.066)	Data 0.001 (0.003)	Loss 0.4070 (0.4501)	Prec@1 87.500 (84.401)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.4121 (0.4408)	Prec@1 86.000 (84.731)
 * Training Prec@1 84.704
Test: [0/50]	Time 0.130 (0.130)	Loss 0.6065 (0.6065)	Prec@1 80.500 (80.500)
 * Testing Prec@1 80.500
Epoch: [14/80][0/250]	LR: 0.1	Time 0.156 (0.156)	Data 0.101 (0.101)	Loss 0.4487 (0.4487)	Prec@1 85.000 (85.000)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.065 (0.066)	Data 0.002 (0.003)	Loss 0.3414 (0.4266)	Prec@1 89.000 (85.332)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.4115 (0.4235)	Prec@1 86.500 (85.443)
 * Training Prec@1 85.386
Test: [0/50]	Time 0.131 (0.131)	Loss 0.4671 (0.4671)	Prec@1 83.000 (83.000)
 * Testing Prec@1 82.670
Epoch: [15/80][0/250]	LR: 0.1	Time 0.144 (0.144)	Data 0.097 (0.097)	Loss 0.4319 (0.4319)	Prec@1 87.000 (87.000)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.5139 (0.4026)	Prec@1 81.000 (86.084)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.3750 (0.4034)	Prec@1 86.000 (85.983)
 * Training Prec@1 85.880
Test: [0/50]	Time 0.138 (0.138)	Loss 0.7224 (0.7224)	Prec@1 78.000 (78.000)
 * Testing Prec@1 80.830
Epoch: [16/80][0/250]	LR: 0.1	Time 0.165 (0.165)	Data 0.111 (0.111)	Loss 0.3694 (0.3694)	Prec@1 88.500 (88.500)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.3102 (0.3829)	Prec@1 90.000 (86.797)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.4059 (0.3871)	Prec@1 85.000 (86.644)
 * Training Prec@1 86.688
Test: [0/50]	Time 0.125 (0.125)	Loss 0.6543 (0.6543)	Prec@1 77.000 (77.000)
 * Testing Prec@1 81.040
Epoch: [17/80][0/250]	LR: 0.1	Time 0.180 (0.180)	Data 0.124 (0.124)	Loss 0.3485 (0.3485)	Prec@1 87.000 (87.000)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.003)	Loss 0.4264 (0.3772)	Prec@1 84.500 (86.782)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.3071 (0.3708)	Prec@1 88.000 (87.015)
 * Training Prec@1 87.034
Test: [0/50]	Time 0.142 (0.142)	Loss 0.4689 (0.4689)	Prec@1 83.000 (83.000)
 * Testing Prec@1 83.570
Epoch: [18/80][0/250]	LR: 0.1	Time 0.178 (0.178)	Data 0.125 (0.125)	Loss 0.3456 (0.3456)	Prec@1 87.500 (87.500)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.065 (0.066)	Data 0.001 (0.003)	Loss 0.3702 (0.3423)	Prec@1 88.500 (88.168)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.4461 (0.3529)	Prec@1 85.000 (87.731)
 * Training Prec@1 87.670
Test: [0/50]	Time 0.151 (0.151)	Loss 0.4161 (0.4161)	Prec@1 87.000 (87.000)
 * Testing Prec@1 84.890
Epoch: [19/80][0/250]	LR: 0.1	Time 0.170 (0.170)	Data 0.112 (0.112)	Loss 0.3138 (0.3138)	Prec@1 90.000 (90.000)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.3564 (0.3453)	Prec@1 92.500 (87.861)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.3143 (0.3412)	Prec@1 86.500 (88.055)
 * Training Prec@1 88.020
Test: [0/50]	Time 0.154 (0.154)	Loss 0.4632 (0.4632)	Prec@1 83.500 (83.500)
 * Testing Prec@1 83.560
Epoch: [20/80][0/250]	LR: 0.1	Time 0.121 (0.121)	Data 0.078 (0.078)	Loss 0.3632 (0.3632)	Prec@1 87.500 (87.500)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.002 (0.002)	Loss 0.4588 (0.3191)	Prec@1 85.000 (88.901)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.3761 (0.3266)	Prec@1 84.000 (88.582)
 * Training Prec@1 88.542
Test: [0/50]	Time 0.156 (0.156)	Loss 0.6814 (0.6814)	Prec@1 80.500 (80.500)
 * Testing Prec@1 80.040
Epoch: [21/80][0/250]	LR: 0.1	Time 0.170 (0.170)	Data 0.118 (0.118)	Loss 0.2833 (0.2833)	Prec@1 88.500 (88.500)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.2421 (0.3081)	Prec@1 93.000 (89.198)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.002 (0.002)	Loss 0.3465 (0.3176)	Prec@1 87.500 (88.963)
 * Training Prec@1 88.964
Test: [0/50]	Time 0.118 (0.118)	Loss 0.4271 (0.4271)	Prec@1 85.500 (85.500)
 * Testing Prec@1 85.040
Epoch: [22/80][0/250]	LR: 0.1	Time 0.146 (0.146)	Data 0.099 (0.099)	Loss 0.2500 (0.2500)	Prec@1 92.000 (92.000)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.2454 (0.2883)	Prec@1 92.500 (89.881)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.066 (0.065)	Data 0.001 (0.002)	Loss 0.3186 (0.3016)	Prec@1 87.500 (89.475)
 * Training Prec@1 89.376
Test: [0/50]	Time 0.119 (0.119)	Loss 0.4896 (0.4896)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.230
Epoch: [23/80][0/250]	LR: 0.1	Time 0.141 (0.141)	Data 0.085 (0.085)	Loss 0.2308 (0.2308)	Prec@1 93.000 (93.000)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.3068 (0.2964)	Prec@1 89.000 (89.530)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.002 (0.002)	Loss 0.3698 (0.2999)	Prec@1 88.500 (89.587)
 * Training Prec@1 89.524
Test: [0/50]	Time 0.121 (0.121)	Loss 0.4817 (0.4817)	Prec@1 85.000 (85.000)
 * Testing Prec@1 84.500
Epoch: [24/80][0/250]	LR: 0.1	Time 0.161 (0.161)	Data 0.121 (0.121)	Loss 0.2812 (0.2812)	Prec@1 90.500 (90.500)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.002 (0.003)	Loss 0.3066 (0.2838)	Prec@1 90.000 (90.233)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.2823 (0.2907)	Prec@1 90.500 (89.903)
 * Training Prec@1 89.832
Test: [0/50]	Time 0.120 (0.120)	Loss 0.6393 (0.6393)	Prec@1 84.500 (84.500)
 * Testing Prec@1 81.910
Epoch: [25/80][0/250]	LR: 0.1	Time 0.145 (0.145)	Data 0.104 (0.104)	Loss 0.2765 (0.2765)	Prec@1 90.500 (90.500)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.2666 (0.2757)	Prec@1 91.500 (90.455)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.2549 (0.2795)	Prec@1 90.000 (90.201)
 * Training Prec@1 90.096
Test: [0/50]	Time 0.140 (0.140)	Loss 0.4860 (0.4860)	Prec@1 83.000 (83.000)
 * Testing Prec@1 82.600
Epoch: [26/80][0/250]	LR: 0.1	Time 0.158 (0.158)	Data 0.105 (0.105)	Loss 0.2647 (0.2647)	Prec@1 90.000 (90.000)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.002 (0.002)	Loss 0.3808 (0.2806)	Prec@1 87.000 (90.064)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.2530 (0.2768)	Prec@1 90.500 (90.251)
 * Training Prec@1 90.106
Test: [0/50]	Time 0.137 (0.137)	Loss 0.5325 (0.5325)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.260
Epoch: [27/80][0/250]	LR: 0.1	Time 0.143 (0.143)	Data 0.088 (0.088)	Loss 0.1972 (0.1972)	Prec@1 92.500 (92.500)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.2155 (0.2562)	Prec@1 93.000 (90.817)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.2778 (0.2612)	Prec@1 89.500 (90.761)
 * Training Prec@1 90.678
Test: [0/50]	Time 0.168 (0.168)	Loss 0.4223 (0.4223)	Prec@1 86.000 (86.000)
 * Testing Prec@1 85.720
Epoch: [28/80][0/250]	LR: 0.1	Time 0.163 (0.163)	Data 0.109 (0.109)	Loss 0.2542 (0.2542)	Prec@1 92.500 (92.500)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.003)	Loss 0.2491 (0.2468)	Prec@1 92.500 (91.327)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.3738 (0.2534)	Prec@1 89.500 (91.216)
 * Training Prec@1 91.052
Test: [0/50]	Time 0.142 (0.142)	Loss 0.5074 (0.5074)	Prec@1 83.000 (83.000)
 * Testing Prec@1 84.330
Epoch: [29/80][0/250]	LR: 0.1	Time 0.160 (0.160)	Data 0.108 (0.108)	Loss 0.1940 (0.1940)	Prec@1 93.000 (93.000)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.1587 (0.2447)	Prec@1 94.000 (91.366)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.3108 (0.2520)	Prec@1 88.000 (91.090)
 * Training Prec@1 91.078
Test: [0/50]	Time 0.132 (0.132)	Loss 0.5481 (0.5481)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.260
Epoch: [30/80][0/250]	LR: 0.1	Time 0.134 (0.134)	Data 0.078 (0.078)	Loss 0.1786 (0.1786)	Prec@1 92.500 (92.500)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.002 (0.002)	Loss 0.2689 (0.2420)	Prec@1 90.000 (91.500)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.1663 (0.2426)	Prec@1 94.000 (91.493)
 * Training Prec@1 91.446
Test: [0/50]	Time 0.154 (0.154)	Loss 0.4433 (0.4433)	Prec@1 86.500 (86.500)
 * Testing Prec@1 86.650
Epoch: [31/80][0/250]	LR: 0.1	Time 0.154 (0.154)	Data 0.109 (0.109)	Loss 0.1882 (0.1882)	Prec@1 93.500 (93.500)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.002 (0.003)	Loss 0.2529 (0.2328)	Prec@1 91.500 (91.856)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.2912 (0.2420)	Prec@1 87.500 (91.545)
 * Training Prec@1 91.432
Test: [0/50]	Time 0.160 (0.160)	Loss 0.4632 (0.4632)	Prec@1 85.500 (85.500)
 * Testing Prec@1 86.280
Epoch: [32/80][0/250]	LR: 0.1	Time 0.172 (0.172)	Data 0.117 (0.117)	Loss 0.2308 (0.2308)	Prec@1 91.500 (91.500)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.2190 (0.2380)	Prec@1 92.500 (91.649)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.3368 (0.2431)	Prec@1 88.500 (91.465)
 * Training Prec@1 91.564
Test: [0/50]	Time 0.146 (0.146)	Loss 0.4823 (0.4823)	Prec@1 85.500 (85.500)
 * Testing Prec@1 86.200
Epoch: [33/80][0/250]	LR: 0.1	Time 0.174 (0.174)	Data 0.119 (0.119)	Loss 0.1811 (0.1811)	Prec@1 93.000 (93.000)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.2405 (0.2194)	Prec@1 91.500 (92.376)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.1761 (0.2294)	Prec@1 93.000 (92.090)
 * Training Prec@1 91.968
Test: [0/50]	Time 0.143 (0.143)	Loss 0.4068 (0.4068)	Prec@1 87.000 (87.000)
 * Testing Prec@1 86.580
Epoch: [34/80][0/250]	LR: 0.1	Time 0.146 (0.146)	Data 0.097 (0.097)	Loss 0.2578 (0.2578)	Prec@1 91.000 (91.000)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.2229 (0.2269)	Prec@1 94.000 (92.327)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.1723 (0.2258)	Prec@1 93.000 (92.236)
 * Training Prec@1 92.074
Test: [0/50]	Time 0.143 (0.143)	Loss 0.4042 (0.4042)	Prec@1 84.500 (84.500)
 * Testing Prec@1 86.900
Epoch: [35/80][0/250]	LR: 0.1	Time 0.162 (0.162)	Data 0.109 (0.109)	Loss 0.1795 (0.1795)	Prec@1 94.500 (94.500)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.2787 (0.2076)	Prec@1 90.500 (92.837)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.1627 (0.2160)	Prec@1 93.000 (92.473)
 * Training Prec@1 92.300
Test: [0/50]	Time 0.142 (0.142)	Loss 0.4179 (0.4179)	Prec@1 87.500 (87.500)
 * Testing Prec@1 83.900
Epoch: [36/80][0/250]	LR: 0.1	Time 0.163 (0.163)	Data 0.107 (0.107)	Loss 0.1926 (0.1926)	Prec@1 93.000 (93.000)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.2454 (0.2120)	Prec@1 91.000 (92.579)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.2228 (0.2173)	Prec@1 95.000 (92.433)
 * Training Prec@1 92.336
Test: [0/50]	Time 0.162 (0.162)	Loss 0.5660 (0.5660)	Prec@1 87.000 (87.000)
 * Testing Prec@1 83.190
Epoch: [37/80][0/250]	LR: 0.1	Time 0.166 (0.166)	Data 0.118 (0.118)	Loss 0.2382 (0.2382)	Prec@1 92.500 (92.500)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.2364 (0.2027)	Prec@1 92.000 (92.921)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.2339 (0.2092)	Prec@1 92.500 (92.736)
 * Training Prec@1 92.670
Test: [0/50]	Time 0.157 (0.157)	Loss 0.5981 (0.5981)	Prec@1 85.000 (85.000)
 * Testing Prec@1 83.340
Epoch: [38/80][0/250]	LR: 0.1	Time 0.157 (0.157)	Data 0.110 (0.110)	Loss 0.1880 (0.1880)	Prec@1 93.000 (93.000)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.003)	Loss 0.1817 (0.1964)	Prec@1 93.000 (92.990)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.1918 (0.2012)	Prec@1 92.000 (92.828)
 * Training Prec@1 92.618
Test: [0/50]	Time 0.105 (0.105)	Loss 0.4964 (0.4964)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.950
Epoch: [39/80][0/250]	LR: 0.1	Time 0.168 (0.168)	Data 0.113 (0.113)	Loss 0.1571 (0.1571)	Prec@1 93.500 (93.500)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.064 (0.066)	Data 0.001 (0.002)	Loss 0.2533 (0.2005)	Prec@1 92.500 (93.025)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.1923 (0.2035)	Prec@1 93.000 (92.963)
 * Training Prec@1 92.724
Test: [0/50]	Time 0.134 (0.134)	Loss 0.3843 (0.3843)	Prec@1 87.000 (87.000)
 * Testing Prec@1 86.120
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.162 (0.162)	Data 0.109 (0.109)	Loss 0.1487 (0.1487)	Prec@1 95.500 (95.500)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0910 (0.1488)	Prec@1 97.000 (95.020)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.1376 (0.1357)	Prec@1 95.500 (95.483)
 * Training Prec@1 95.574
Test: [0/50]	Time 0.170 (0.170)	Loss 0.2675 (0.2675)	Prec@1 93.000 (93.000)
 * Testing Prec@1 91.060
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.133 (0.133)	Data 0.080 (0.080)	Loss 0.0446 (0.0446)	Prec@1 98.500 (98.500)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0699 (0.0993)	Prec@1 98.500 (96.832)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0737 (0.1000)	Prec@1 98.500 (96.751)
 * Training Prec@1 96.706
Test: [0/50]	Time 0.149 (0.149)	Loss 0.2660 (0.2660)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.360
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.147 (0.147)	Data 0.092 (0.092)	Loss 0.1180 (0.1180)	Prec@1 96.000 (96.000)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.1266 (0.0913)	Prec@1 96.000 (97.010)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0588 (0.0905)	Prec@1 98.500 (97.050)
 * Training Prec@1 97.040
Test: [0/50]	Time 0.147 (0.147)	Loss 0.2818 (0.2818)	Prec@1 92.000 (92.000)
 * Testing Prec@1 91.260
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.171 (0.171)	Data 0.114 (0.114)	Loss 0.0728 (0.0728)	Prec@1 96.000 (96.000)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0491 (0.0830)	Prec@1 99.500 (97.287)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0832 (0.0812)	Prec@1 97.500 (97.408)
 * Training Prec@1 97.402
Test: [0/50]	Time 0.136 (0.136)	Loss 0.2601 (0.2601)	Prec@1 93.000 (93.000)
 * Testing Prec@1 91.430
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.145 (0.145)	Data 0.088 (0.088)	Loss 0.1173 (0.1173)	Prec@1 97.000 (97.000)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0645 (0.0756)	Prec@1 99.000 (97.599)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.1270 (0.0764)	Prec@1 96.500 (97.522)
 * Training Prec@1 97.568
Test: [0/50]	Time 0.107 (0.107)	Loss 0.2719 (0.2719)	Prec@1 92.000 (92.000)
 * Testing Prec@1 91.140
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.177 (0.177)	Data 0.116 (0.116)	Loss 0.0468 (0.0468)	Prec@1 99.500 (99.500)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0365 (0.0679)	Prec@1 99.500 (97.797)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0658 (0.0692)	Prec@1 98.000 (97.711)
 * Training Prec@1 97.718
Test: [0/50]	Time 0.148 (0.148)	Loss 0.2900 (0.2900)	Prec@1 91.500 (91.500)
 * Testing Prec@1 91.210
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.130 (0.130)	Data 0.077 (0.077)	Loss 0.0327 (0.0327)	Prec@1 99.000 (99.000)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0341 (0.0650)	Prec@1 99.500 (97.906)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0833 (0.0652)	Prec@1 97.000 (97.828)
 * Training Prec@1 97.862
Test: [0/50]	Time 0.133 (0.133)	Loss 0.3045 (0.3045)	Prec@1 91.500 (91.500)
 * Testing Prec@1 91.180
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 0.159 (0.159)	Data 0.103 (0.103)	Loss 0.0969 (0.0969)	Prec@1 96.500 (96.500)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.1299 (0.0621)	Prec@1 97.000 (97.931)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0693 (0.0628)	Prec@1 97.500 (97.935)
 * Training Prec@1 97.920
Test: [0/50]	Time 0.140 (0.140)	Loss 0.2931 (0.2931)	Prec@1 92.000 (92.000)
 * Testing Prec@1 91.440
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.133 (0.133)	Data 0.079 (0.079)	Loss 0.0279 (0.0279)	Prec@1 99.500 (99.500)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0489 (0.0534)	Prec@1 97.500 (98.322)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0531 (0.0571)	Prec@1 98.000 (98.177)
 * Training Prec@1 98.142
Test: [0/50]	Time 0.131 (0.131)	Loss 0.3022 (0.3022)	Prec@1 91.500 (91.500)
 * Testing Prec@1 91.510
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.164 (0.164)	Data 0.112 (0.112)	Loss 0.0513 (0.0513)	Prec@1 97.500 (97.500)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0403 (0.0559)	Prec@1 99.000 (98.168)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0423 (0.0574)	Prec@1 98.500 (98.117)
 * Training Prec@1 98.138
Test: [0/50]	Time 0.103 (0.103)	Loss 0.3116 (0.3116)	Prec@1 91.500 (91.500)
 * Testing Prec@1 91.350
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.175 (0.175)	Data 0.118 (0.118)	Loss 0.0233 (0.0233)	Prec@1 100.000 (100.000)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.066)	Data 0.001 (0.003)	Loss 0.0505 (0.0510)	Prec@1 99.000 (98.475)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0482 (0.0523)	Prec@1 97.500 (98.378)
 * Training Prec@1 98.340
Test: [0/50]	Time 0.156 (0.156)	Loss 0.3172 (0.3172)	Prec@1 91.000 (91.000)
 * Testing Prec@1 91.280
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 0.157 (0.157)	Data 0.103 (0.103)	Loss 0.0389 (0.0389)	Prec@1 98.000 (98.000)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0365 (0.0502)	Prec@1 99.000 (98.347)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.002 (0.002)	Loss 0.0937 (0.0500)	Prec@1 97.000 (98.316)
 * Training Prec@1 98.270
Test: [0/50]	Time 0.161 (0.161)	Loss 0.3321 (0.3321)	Prec@1 92.000 (92.000)
 * Testing Prec@1 91.400
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.181 (0.181)	Data 0.123 (0.123)	Loss 0.0422 (0.0422)	Prec@1 98.500 (98.500)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.066)	Data 0.001 (0.003)	Loss 0.0266 (0.0459)	Prec@1 99.000 (98.540)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0661 (0.0472)	Prec@1 98.000 (98.500)
 * Training Prec@1 98.486
Test: [0/50]	Time 0.151 (0.151)	Loss 0.3023 (0.3023)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.230
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 0.172 (0.172)	Data 0.116 (0.116)	Loss 0.0471 (0.0471)	Prec@1 98.000 (98.000)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.002 (0.003)	Loss 0.0627 (0.0441)	Prec@1 97.000 (98.520)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0358 (0.0460)	Prec@1 99.000 (98.460)
 * Training Prec@1 98.404
Test: [0/50]	Time 0.143 (0.143)	Loss 0.3350 (0.3350)	Prec@1 91.500 (91.500)
 * Testing Prec@1 91.120
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.133 (0.133)	Data 0.076 (0.076)	Loss 0.0313 (0.0313)	Prec@1 99.000 (99.000)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0264 (0.0443)	Prec@1 99.500 (98.594)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0368 (0.0433)	Prec@1 98.500 (98.619)
 * Training Prec@1 98.574
Test: [0/50]	Time 0.157 (0.157)	Loss 0.3007 (0.3007)	Prec@1 93.000 (93.000)
 * Testing Prec@1 91.290
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.170 (0.170)	Data 0.119 (0.119)	Loss 0.0488 (0.0488)	Prec@1 97.000 (97.000)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0638 (0.0412)	Prec@1 98.000 (98.762)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0406 (0.0408)	Prec@1 99.000 (98.756)
 * Training Prec@1 98.730
Test: [0/50]	Time 0.125 (0.125)	Loss 0.3454 (0.3454)	Prec@1 92.000 (92.000)
 * Testing Prec@1 91.170
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.175 (0.175)	Data 0.118 (0.118)	Loss 0.0516 (0.0516)	Prec@1 98.500 (98.500)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.066)	Data 0.001 (0.003)	Loss 0.0295 (0.0405)	Prec@1 99.000 (98.668)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0481 (0.0407)	Prec@1 98.000 (98.684)
 * Training Prec@1 98.676
Test: [0/50]	Time 0.152 (0.152)	Loss 0.3190 (0.3190)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.290
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.175 (0.175)	Data 0.120 (0.120)	Loss 0.0164 (0.0164)	Prec@1 100.000 (100.000)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.066)	Data 0.001 (0.003)	Loss 0.0223 (0.0383)	Prec@1 99.500 (98.896)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.066 (0.065)	Data 0.002 (0.002)	Loss 0.0373 (0.0379)	Prec@1 99.000 (98.848)
 * Training Prec@1 98.842
Test: [0/50]	Time 0.146 (0.146)	Loss 0.3537 (0.3537)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.250
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.158 (0.158)	Data 0.103 (0.103)	Loss 0.0357 (0.0357)	Prec@1 99.500 (99.500)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0807 (0.0350)	Prec@1 98.500 (98.955)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0492 (0.0353)	Prec@1 99.500 (98.923)
 * Training Prec@1 98.862
Test: [0/50]	Time 0.159 (0.159)	Loss 0.3627 (0.3627)	Prec@1 91.000 (91.000)
 * Testing Prec@1 91.210
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.118 (0.118)	Data 0.074 (0.074)	Loss 0.0391 (0.0391)	Prec@1 98.500 (98.500)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0239 (0.0340)	Prec@1 99.500 (98.960)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0267 (0.0355)	Prec@1 99.500 (98.858)
 * Training Prec@1 98.846
Test: [0/50]	Time 0.147 (0.147)	Loss 0.3605 (0.3605)	Prec@1 92.000 (92.000)
 * Testing Prec@1 91.060
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.131 (0.131)	Data 0.074 (0.074)	Loss 0.0401 (0.0401)	Prec@1 99.000 (99.000)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0293 (0.0300)	Prec@1 99.000 (99.094)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0308 (0.0316)	Prec@1 99.000 (99.015)
 * Training Prec@1 98.990
Test: [0/50]	Time 0.157 (0.157)	Loss 0.3544 (0.3544)	Prec@1 92.000 (92.000)
 * Testing Prec@1 91.240
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.167 (0.167)	Data 0.115 (0.115)	Loss 0.0226 (0.0226)	Prec@1 99.000 (99.000)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.003)	Loss 0.0494 (0.0293)	Prec@1 97.500 (99.158)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0501 (0.0299)	Prec@1 98.500 (99.117)
 * Training Prec@1 99.108
Test: [0/50]	Time 0.108 (0.108)	Loss 0.3516 (0.3516)	Prec@1 92.000 (92.000)
 * Testing Prec@1 91.300
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.178 (0.178)	Data 0.127 (0.127)	Loss 0.0341 (0.0341)	Prec@1 99.000 (99.000)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.066)	Data 0.002 (0.003)	Loss 0.0431 (0.0281)	Prec@1 98.500 (99.168)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0157 (0.0281)	Prec@1 99.500 (99.149)
 * Training Prec@1 99.142
Test: [0/50]	Time 0.163 (0.163)	Loss 0.3443 (0.3443)	Prec@1 93.000 (93.000)
 * Testing Prec@1 91.290
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 0.159 (0.159)	Data 0.107 (0.107)	Loss 0.0165 (0.0165)	Prec@1 99.500 (99.500)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.003)	Loss 0.0162 (0.0278)	Prec@1 99.500 (99.149)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0234 (0.0289)	Prec@1 99.500 (99.149)
 * Training Prec@1 99.120
Test: [0/50]	Time 0.099 (0.099)	Loss 0.3561 (0.3561)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.220
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 0.154 (0.154)	Data 0.100 (0.100)	Loss 0.0378 (0.0378)	Prec@1 98.000 (98.000)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0343 (0.0286)	Prec@1 98.500 (99.134)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0362 (0.0281)	Prec@1 98.500 (99.137)
 * Training Prec@1 99.148
Test: [0/50]	Time 0.153 (0.153)	Loss 0.3399 (0.3399)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.260
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.181 (0.181)	Data 0.126 (0.126)	Loss 0.0358 (0.0358)	Prec@1 98.500 (98.500)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.066)	Data 0.001 (0.003)	Loss 0.0520 (0.0269)	Prec@1 98.000 (99.238)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0198 (0.0281)	Prec@1 100.000 (99.137)
 * Training Prec@1 99.162
Test: [0/50]	Time 0.118 (0.118)	Loss 0.3412 (0.3412)	Prec@1 93.000 (93.000)
 * Testing Prec@1 91.340
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 0.131 (0.131)	Data 0.074 (0.074)	Loss 0.0204 (0.0204)	Prec@1 99.000 (99.000)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0417 (0.0277)	Prec@1 99.000 (99.188)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0242 (0.0274)	Prec@1 99.000 (99.211)
 * Training Prec@1 99.210
Test: [0/50]	Time 0.148 (0.148)	Loss 0.3443 (0.3443)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.270
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.167 (0.167)	Data 0.122 (0.122)	Loss 0.0292 (0.0292)	Prec@1 99.000 (99.000)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.003)	Loss 0.0194 (0.0283)	Prec@1 99.500 (99.178)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0264 (0.0277)	Prec@1 99.500 (99.201)
 * Training Prec@1 99.202
Test: [0/50]	Time 0.138 (0.138)	Loss 0.3442 (0.3442)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.350
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.132 (0.132)	Data 0.083 (0.083)	Loss 0.0710 (0.0710)	Prec@1 97.500 (97.500)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.003)	Loss 0.0303 (0.0282)	Prec@1 98.500 (99.173)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0407 (0.0270)	Prec@1 99.500 (99.219)
 * Training Prec@1 99.214
Test: [0/50]	Time 0.156 (0.156)	Loss 0.3376 (0.3376)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.290
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 0.121 (0.121)	Data 0.074 (0.074)	Loss 0.0234 (0.0234)	Prec@1 99.500 (99.500)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0237 (0.0257)	Prec@1 99.500 (99.307)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0198 (0.0261)	Prec@1 99.500 (99.276)
 * Training Prec@1 99.274
Test: [0/50]	Time 0.142 (0.142)	Loss 0.3390 (0.3390)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.340
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.141 (0.141)	Data 0.076 (0.076)	Loss 0.0165 (0.0165)	Prec@1 100.000 (100.000)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.002 (0.002)	Loss 0.0228 (0.0262)	Prec@1 99.000 (99.238)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0077 (0.0251)	Prec@1 100.000 (99.296)
 * Training Prec@1 99.252
Test: [0/50]	Time 0.154 (0.154)	Loss 0.3374 (0.3374)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.360
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.183 (0.183)	Data 0.129 (0.129)	Loss 0.0425 (0.0425)	Prec@1 98.000 (98.000)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.066)	Data 0.001 (0.003)	Loss 0.0351 (0.0231)	Prec@1 99.000 (99.371)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0438 (0.0242)	Prec@1 99.500 (99.343)
 * Training Prec@1 99.322
Test: [0/50]	Time 0.149 (0.149)	Loss 0.3511 (0.3511)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.170
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.165 (0.165)	Data 0.103 (0.103)	Loss 0.0358 (0.0358)	Prec@1 98.500 (98.500)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0155 (0.0253)	Prec@1 99.500 (99.267)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0331 (0.0255)	Prec@1 99.500 (99.259)
 * Training Prec@1 99.242
Test: [0/50]	Time 0.149 (0.149)	Loss 0.3316 (0.3316)	Prec@1 93.000 (93.000)
 * Testing Prec@1 91.330
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 0.111 (0.111)	Data 0.073 (0.073)	Loss 0.0330 (0.0330)	Prec@1 99.500 (99.500)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0160 (0.0250)	Prec@1 99.500 (99.267)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0155 (0.0248)	Prec@1 100.000 (99.291)
 * Training Prec@1 99.262
Test: [0/50]	Time 0.166 (0.166)	Loss 0.3417 (0.3417)	Prec@1 93.000 (93.000)
 * Testing Prec@1 91.530
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.168 (0.168)	Data 0.113 (0.113)	Loss 0.0294 (0.0294)	Prec@1 99.500 (99.500)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.066)	Data 0.001 (0.003)	Loss 0.0175 (0.0235)	Prec@1 99.500 (99.361)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0094 (0.0250)	Prec@1 100.000 (99.291)
 * Training Prec@1 99.290
Test: [0/50]	Time 0.161 (0.161)	Loss 0.3429 (0.3429)	Prec@1 93.000 (93.000)
 * Testing Prec@1 91.340
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.150 (0.150)	Data 0.095 (0.095)	Loss 0.0159 (0.0159)	Prec@1 100.000 (100.000)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0170 (0.0240)	Prec@1 100.000 (99.297)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0215 (0.0240)	Prec@1 99.500 (99.284)
 * Training Prec@1 99.288
Test: [0/50]	Time 0.157 (0.157)	Loss 0.3466 (0.3466)	Prec@1 93.500 (93.500)
 * Testing Prec@1 91.330
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.179 (0.179)	Data 0.130 (0.130)	Loss 0.0178 (0.0178)	Prec@1 99.500 (99.500)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.066)	Data 0.001 (0.003)	Loss 0.0235 (0.0249)	Prec@1 99.500 (99.272)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0405 (0.0252)	Prec@1 99.000 (99.276)
 * Training Prec@1 99.260
Test: [0/50]	Time 0.151 (0.151)	Loss 0.3574 (0.3574)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.270
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 0.169 (0.169)	Data 0.116 (0.116)	Loss 0.0217 (0.0217)	Prec@1 99.500 (99.500)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.003)	Loss 0.0403 (0.0261)	Prec@1 99.000 (99.233)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0409 (0.0255)	Prec@1 98.500 (99.244)
 * Training Prec@1 99.270
Test: [0/50]	Time 0.150 (0.150)	Loss 0.3433 (0.3433)	Prec@1 92.500 (92.500)
 * Testing Prec@1 91.360
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.128 (0.128)	Data 0.073 (0.073)	Loss 0.0242 (0.0242)	Prec@1 100.000 (100.000)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.062 (0.065)	Data 0.002 (0.002)	Loss 0.0057 (0.0240)	Prec@1 100.000 (99.307)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.002 (0.002)	Loss 0.0368 (0.0243)	Prec@1 99.000 (99.276)
 * Training Prec@1 99.262
Test: [0/50]	Time 0.122 (0.122)	Loss 0.3474 (0.3474)	Prec@1 92.000 (92.000)
 * Testing Prec@1 91.390
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.136 (0.136)	Data 0.083 (0.083)	Loss 0.0108 (0.0108)	Prec@1 99.500 (99.500)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0296 (0.0275)	Prec@1 99.000 (99.218)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0071 (0.0266)	Prec@1 100.000 (99.244)
 * Training Prec@1 99.282
Test: [0/50]	Time 0.149 (0.149)	Loss 0.3446 (0.3446)	Prec@1 93.000 (93.000)
 * Testing Prec@1 91.340
