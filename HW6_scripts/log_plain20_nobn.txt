Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'plainnet20'
Epoch: [0/80][0/250]	LR: 0.1	Time 0.432 (0.432)	Data 0.087 (0.087)	Loss 2.3114 (2.3114)	Prec@1 4.000 (4.000)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.028 (0.028)	Data 0.019 (0.015)	Loss 2.2491 (2.2960)	Prec@1 15.000 (11.762)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.026 (0.027)	Data 0.017 (0.016)	Loss 2.3076 (2.2997)	Prec@1 8.500 (11.055)
 * Training Prec@1 10.840
main.py:198: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.142 (0.142)	Loss 2.3040 (2.3040)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
main.py:235: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:236: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:244: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 0.115 (0.115)	Data 0.098 (0.098)	Loss 2.3025 (2.3025)	Prec@1 13.000 (13.000)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.025 (0.025)	Data 0.016 (0.015)	Loss 2.3114 (2.3038)	Prec@1 11.000 (9.985)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.026 (0.025)	Data 0.017 (0.016)	Loss 2.3017 (2.3041)	Prec@1 14.500 (9.861)
 * Training Prec@1 9.778
Test: [0/50]	Time 0.110 (0.110)	Loss 2.3029 (2.3029)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [2/80][0/250]	LR: 0.1	Time 0.131 (0.131)	Data 0.113 (0.113)	Loss 2.3101 (2.3101)	Prec@1 9.000 (9.000)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.022 (0.026)	Data 0.010 (0.016)	Loss 2.3035 (2.3038)	Prec@1 9.000 (9.970)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.026 (0.025)	Data 0.017 (0.016)	Loss 2.3015 (2.3038)	Prec@1 11.000 (9.913)
 * Training Prec@1 9.952
Test: [0/50]	Time 0.094 (0.094)	Loss 2.3029 (2.3029)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [3/80][0/250]	LR: 0.1	Time 0.118 (0.118)	Data 0.102 (0.102)	Loss 2.3036 (2.3036)	Prec@1 8.000 (8.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.027 (0.026)	Data 0.017 (0.016)	Loss 2.3017 (2.3035)	Prec@1 10.000 (9.767)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.026 (0.025)	Data 0.017 (0.015)	Loss 2.3022 (2.3038)	Prec@1 10.000 (9.682)
 * Training Prec@1 9.688
Test: [0/50]	Time 0.093 (0.093)	Loss 2.3055 (2.3055)	Prec@1 7.000 (7.000)
 * Testing Prec@1 10.000
Epoch: [4/80][0/250]	LR: 0.1	Time 0.110 (0.110)	Data 0.095 (0.095)	Loss 2.3077 (2.3077)	Prec@1 8.500 (8.500)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.024 (0.025)	Data 0.016 (0.016)	Loss 2.3060 (2.3042)	Prec@1 11.500 (10.089)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.014 (0.016)	Loss 2.2516 (2.3022)	Prec@1 17.000 (10.197)
 * Training Prec@1 10.266
Test: [0/50]	Time 0.155 (0.155)	Loss 2.3048 (2.3048)	Prec@1 7.000 (7.000)
 * Testing Prec@1 10.000
Epoch: [5/80][0/250]	LR: 0.1	Time 0.115 (0.115)	Data 0.098 (0.098)	Loss 2.2994 (2.2994)	Prec@1 11.000 (11.000)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.013 (0.015)	Loss 2.3046 (2.3004)	Prec@1 11.000 (10.762)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.024 (0.024)	Data 0.015 (0.015)	Loss 2.3037 (2.3023)	Prec@1 12.000 (10.080)
 * Training Prec@1 10.118
Test: [0/50]	Time 0.184 (0.184)	Loss 2.3019 (2.3019)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [6/80][0/250]	LR: 0.1	Time 0.107 (0.107)	Data 0.093 (0.093)	Loss 2.3049 (2.3049)	Prec@1 9.000 (9.000)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.033 (0.026)	Data 0.024 (0.016)	Loss 2.3040 (2.3036)	Prec@1 10.500 (9.772)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.024 (0.026)	Data 0.016 (0.017)	Loss 2.3085 (2.3037)	Prec@1 6.000 (9.930)
 * Training Prec@1 9.890
Test: [0/50]	Time 0.090 (0.090)	Loss 2.3031 (2.3031)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [7/80][0/250]	LR: 0.1	Time 0.182 (0.182)	Data 0.165 (0.165)	Loss 2.3039 (2.3039)	Prec@1 10.000 (10.000)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.024 (0.027)	Data 0.015 (0.017)	Loss 2.3042 (2.3035)	Prec@1 9.000 (9.941)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.023 (0.026)	Data 0.014 (0.017)	Loss 2.3080 (2.3035)	Prec@1 10.500 (10.045)
 * Training Prec@1 10.070
Test: [0/50]	Time 0.105 (0.105)	Loss 2.3046 (2.3046)	Prec@1 7.500 (7.500)
 * Testing Prec@1 10.000
Epoch: [8/80][0/250]	LR: 0.1	Time 0.179 (0.179)	Data 0.162 (0.162)	Loss 2.3040 (2.3040)	Prec@1 9.000 (9.000)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.023 (0.026)	Data 0.013 (0.017)	Loss 2.3051 (2.3039)	Prec@1 11.000 (9.931)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.024 (0.026)	Data 0.014 (0.017)	Loss 2.3076 (2.3039)	Prec@1 6.500 (9.918)
 * Training Prec@1 9.924
Test: [0/50]	Time 0.154 (0.154)	Loss 2.3020 (2.3020)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [9/80][0/250]	LR: 0.1	Time 0.117 (0.117)	Data 0.102 (0.102)	Loss 2.3041 (2.3041)	Prec@1 10.500 (10.500)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.021 (0.026)	Data 0.011 (0.016)	Loss 2.2973 (2.3035)	Prec@1 13.500 (10.149)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.024 (0.025)	Data 0.015 (0.016)	Loss 2.3099 (2.3035)	Prec@1 8.500 (10.085)
 * Training Prec@1 10.068
Test: [0/50]	Time 0.145 (0.145)	Loss 2.2974 (2.2974)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [10/80][0/250]	LR: 0.1	Time 0.110 (0.110)	Data 0.093 (0.093)	Loss 2.2993 (2.2993)	Prec@1 12.000 (12.000)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.027 (0.027)	Data 0.017 (0.017)	Loss 2.3003 (2.3038)	Prec@1 12.000 (10.089)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.036 (0.026)	Data 0.027 (0.017)	Loss 2.3071 (2.3037)	Prec@1 8.500 (10.172)
 * Training Prec@1 10.168
Test: [0/50]	Time 0.094 (0.094)	Loss 2.3013 (2.3013)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [11/80][0/250]	LR: 0.1	Time 0.121 (0.121)	Data 0.106 (0.106)	Loss 2.3061 (2.3061)	Prec@1 12.000 (12.000)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.026 (0.025)	Data 0.015 (0.015)	Loss 2.3002 (2.3042)	Prec@1 9.500 (9.634)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.024 (0.025)	Data 0.015 (0.015)	Loss 2.3045 (2.3041)	Prec@1 11.500 (9.736)
 * Training Prec@1 9.784
Test: [0/50]	Time 0.151 (0.151)	Loss 2.3058 (2.3058)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [12/80][0/250]	LR: 0.1	Time 0.140 (0.140)	Data 0.124 (0.124)	Loss 2.3011 (2.3011)	Prec@1 15.000 (15.000)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.023 (0.026)	Data 0.014 (0.016)	Loss 2.3051 (2.3040)	Prec@1 9.500 (10.129)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.026 (0.025)	Data 0.017 (0.016)	Loss 2.3057 (2.3038)	Prec@1 8.500 (10.169)
 * Training Prec@1 10.140
Test: [0/50]	Time 0.154 (0.154)	Loss 2.3059 (2.3059)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [13/80][0/250]	LR: 0.1	Time 0.172 (0.172)	Data 0.157 (0.157)	Loss 2.3022 (2.3022)	Prec@1 10.500 (10.500)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.029 (0.027)	Data 0.020 (0.017)	Loss 2.3043 (2.3038)	Prec@1 9.500 (10.000)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.023 (0.026)	Data 0.014 (0.017)	Loss 2.3025 (2.3039)	Prec@1 12.500 (9.938)
 * Training Prec@1 10.068
Test: [0/50]	Time 0.156 (0.156)	Loss 2.3086 (2.3086)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [14/80][0/250]	LR: 0.1	Time 0.114 (0.114)	Data 0.099 (0.099)	Loss 2.3044 (2.3044)	Prec@1 10.000 (10.000)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.024 (0.026)	Data 0.014 (0.016)	Loss 2.3064 (2.3037)	Prec@1 13.000 (9.861)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.035 (0.026)	Data 0.025 (0.016)	Loss 2.3089 (2.3036)	Prec@1 9.000 (9.823)
 * Training Prec@1 9.778
Test: [0/50]	Time 0.188 (0.188)	Loss 2.3002 (2.3002)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [15/80][0/250]	LR: 0.1	Time 0.109 (0.109)	Data 0.091 (0.091)	Loss 2.3041 (2.3041)	Prec@1 10.000 (10.000)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.025 (0.024)	Data 0.013 (0.015)	Loss 2.3035 (2.3035)	Prec@1 11.500 (10.302)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.027 (0.025)	Data 0.018 (0.015)	Loss 2.3053 (2.3037)	Prec@1 10.000 (9.960)
 * Training Prec@1 9.888
Test: [0/50]	Time 0.104 (0.104)	Loss 2.3051 (2.3051)	Prec@1 7.000 (7.000)
 * Testing Prec@1 10.000
Epoch: [16/80][0/250]	LR: 0.1	Time 0.139 (0.139)	Data 0.121 (0.121)	Loss 2.3041 (2.3041)	Prec@1 9.000 (9.000)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.021 (0.025)	Data 0.012 (0.016)	Loss 2.3035 (2.3036)	Prec@1 10.000 (9.757)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.025 (0.025)	Data 0.016 (0.016)	Loss 2.3030 (2.3035)	Prec@1 12.500 (9.925)
 * Training Prec@1 9.926
Test: [0/50]	Time 0.174 (0.174)	Loss 2.3043 (2.3043)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [17/80][0/250]	LR: 0.1	Time 0.103 (0.103)	Data 0.089 (0.089)	Loss 2.3065 (2.3065)	Prec@1 7.500 (7.500)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.027 (0.025)	Data 0.018 (0.016)	Loss 2.3049 (2.3039)	Prec@1 9.500 (10.193)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.025 (0.025)	Data 0.016 (0.016)	Loss 2.3031 (2.3037)	Prec@1 9.500 (10.154)
 * Training Prec@1 10.168
Test: [0/50]	Time 0.147 (0.147)	Loss 2.3056 (2.3056)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [18/80][0/250]	LR: 0.1	Time 0.102 (0.102)	Data 0.087 (0.087)	Loss 2.3030 (2.3030)	Prec@1 12.000 (12.000)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.026 (0.024)	Data 0.018 (0.015)	Loss 2.3022 (2.3041)	Prec@1 11.000 (9.891)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.014 (0.015)	Loss 2.2974 (2.3038)	Prec@1 15.000 (9.910)
 * Training Prec@1 9.898
Test: [0/50]	Time 0.114 (0.114)	Loss 2.3103 (2.3103)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [19/80][0/250]	LR: 0.1	Time 0.108 (0.108)	Data 0.093 (0.093)	Loss 2.3042 (2.3042)	Prec@1 10.500 (10.500)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.025 (0.025)	Data 0.016 (0.016)	Loss 2.3047 (2.3037)	Prec@1 11.500 (10.233)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.015 (0.016)	Loss 2.3013 (2.3039)	Prec@1 9.000 (9.853)
 * Training Prec@1 9.792
Test: [0/50]	Time 0.098 (0.098)	Loss 2.3020 (2.3020)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [20/80][0/250]	LR: 0.1	Time 0.102 (0.102)	Data 0.087 (0.087)	Loss 2.3034 (2.3034)	Prec@1 10.000 (10.000)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.028 (0.026)	Data 0.019 (0.017)	Loss 2.3052 (2.3037)	Prec@1 8.000 (10.213)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.026 (0.026)	Data 0.017 (0.017)	Loss 2.3012 (2.3038)	Prec@1 7.000 (10.087)
 * Training Prec@1 10.042
Test: [0/50]	Time 0.092 (0.092)	Loss 2.3027 (2.3027)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [21/80][0/250]	LR: 0.1	Time 0.107 (0.107)	Data 0.090 (0.090)	Loss 2.3012 (2.3012)	Prec@1 10.000 (10.000)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.014 (0.016)	Loss 2.2984 (2.3032)	Prec@1 12.500 (9.733)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.025 (0.025)	Data 0.017 (0.016)	Loss 2.3020 (2.3037)	Prec@1 9.500 (9.853)
 * Training Prec@1 9.814
Test: [0/50]	Time 0.161 (0.161)	Loss 2.3002 (2.3002)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [22/80][0/250]	LR: 0.1	Time 0.120 (0.120)	Data 0.105 (0.105)	Loss 2.3076 (2.3076)	Prec@1 6.000 (6.000)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.015 (0.016)	Loss 2.3042 (2.3041)	Prec@1 9.000 (9.668)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.024 (0.026)	Data 0.014 (0.017)	Loss 2.3061 (2.3038)	Prec@1 10.500 (9.749)
 * Training Prec@1 9.734
Test: [0/50]	Time 0.084 (0.084)	Loss 2.3047 (2.3047)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [23/80][0/250]	LR: 0.1	Time 0.107 (0.107)	Data 0.092 (0.092)	Loss 2.3047 (2.3047)	Prec@1 7.500 (7.500)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.022 (0.025)	Data 0.012 (0.016)	Loss 2.3016 (2.3039)	Prec@1 10.000 (10.193)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.026 (0.025)	Data 0.017 (0.016)	Loss 2.3024 (2.3036)	Prec@1 9.000 (10.142)
 * Training Prec@1 10.220
Test: [0/50]	Time 0.162 (0.162)	Loss 2.3054 (2.3054)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [24/80][0/250]	LR: 0.1	Time 0.110 (0.110)	Data 0.094 (0.094)	Loss 2.3028 (2.3028)	Prec@1 8.500 (8.500)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.021 (0.025)	Data 0.014 (0.016)	Loss 2.3060 (2.3034)	Prec@1 6.500 (10.248)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.014 (0.016)	Loss 2.3053 (2.3036)	Prec@1 8.500 (10.154)
 * Training Prec@1 10.128
Test: [0/50]	Time 0.115 (0.115)	Loss 2.3080 (2.3080)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [25/80][0/250]	LR: 0.1	Time 0.113 (0.113)	Data 0.096 (0.096)	Loss 2.2995 (2.2995)	Prec@1 11.500 (11.500)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.022 (0.024)	Data 0.013 (0.015)	Loss 2.3046 (2.3034)	Prec@1 11.000 (10.188)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.022 (0.024)	Data 0.012 (0.015)	Loss 2.3121 (2.3036)	Prec@1 10.000 (10.010)
 * Training Prec@1 10.062
Test: [0/50]	Time 0.097 (0.097)	Loss 2.2986 (2.2986)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [26/80][0/250]	LR: 0.1	Time 0.103 (0.103)	Data 0.088 (0.088)	Loss 2.3067 (2.3067)	Prec@1 9.500 (9.500)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.025 (0.025)	Data 0.016 (0.015)	Loss 2.3036 (2.3039)	Prec@1 12.500 (9.807)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.025 (0.025)	Data 0.017 (0.015)	Loss 2.2979 (2.3040)	Prec@1 15.000 (9.985)
 * Training Prec@1 9.906
Test: [0/50]	Time 0.092 (0.092)	Loss 2.3039 (2.3039)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [27/80][0/250]	LR: 0.1	Time 0.157 (0.157)	Data 0.142 (0.142)	Loss 2.3082 (2.3082)	Prec@1 8.500 (8.500)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.030 (0.025)	Data 0.021 (0.015)	Loss 2.3086 (2.3039)	Prec@1 6.500 (9.876)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.022 (0.025)	Data 0.013 (0.015)	Loss 2.3083 (2.3037)	Prec@1 8.000 (9.873)
 * Training Prec@1 9.982
Test: [0/50]	Time 0.097 (0.097)	Loss 2.3037 (2.3037)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [28/80][0/250]	LR: 0.1	Time 0.169 (0.169)	Data 0.154 (0.154)	Loss 2.3048 (2.3048)	Prec@1 8.000 (8.000)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.023 (0.026)	Data 0.014 (0.017)	Loss 2.3073 (2.3041)	Prec@1 4.500 (9.782)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.026 (0.026)	Data 0.016 (0.016)	Loss 2.3076 (2.3038)	Prec@1 7.500 (9.808)
 * Training Prec@1 9.860
Test: [0/50]	Time 0.107 (0.107)	Loss 2.3107 (2.3107)	Prec@1 7.000 (7.000)
 * Testing Prec@1 10.000
Epoch: [29/80][0/250]	LR: 0.1	Time 0.111 (0.111)	Data 0.097 (0.097)	Loss 2.3034 (2.3034)	Prec@1 10.500 (10.500)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.031 (0.028)	Data 0.019 (0.018)	Loss 2.3037 (2.3036)	Prec@1 10.500 (9.762)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.022 (0.026)	Data 0.013 (0.017)	Loss 2.3048 (2.3037)	Prec@1 7.500 (9.823)
 * Training Prec@1 9.914
Test: [0/50]	Time 0.123 (0.123)	Loss 2.2958 (2.2958)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [30/80][0/250]	LR: 0.1	Time 0.123 (0.123)	Data 0.106 (0.106)	Loss 2.3041 (2.3041)	Prec@1 10.000 (10.000)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.029 (0.026)	Data 0.021 (0.016)	Loss 2.3047 (2.3039)	Prec@1 11.000 (9.921)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.027 (0.027)	Data 0.018 (0.017)	Loss 2.3051 (2.3041)	Prec@1 11.000 (9.813)
 * Training Prec@1 9.786
Test: [0/50]	Time 0.163 (0.163)	Loss 2.3054 (2.3054)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [31/80][0/250]	LR: 0.1	Time 0.111 (0.111)	Data 0.096 (0.096)	Loss 2.3085 (2.3085)	Prec@1 10.000 (10.000)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.025 (0.026)	Data 0.016 (0.016)	Loss 2.3048 (2.3039)	Prec@1 10.500 (9.990)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.026 (0.025)	Data 0.018 (0.016)	Loss 2.3001 (2.3038)	Prec@1 8.500 (9.960)
 * Training Prec@1 10.002
Test: [0/50]	Time 0.109 (0.109)	Loss 2.3039 (2.3039)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [32/80][0/250]	LR: 0.1	Time 0.110 (0.110)	Data 0.094 (0.094)	Loss 2.3013 (2.3013)	Prec@1 8.000 (8.000)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.022 (0.026)	Data 0.013 (0.016)	Loss 2.3054 (2.3038)	Prec@1 7.000 (9.708)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.030 (0.025)	Data 0.021 (0.016)	Loss 2.3068 (2.3039)	Prec@1 7.000 (9.789)
 * Training Prec@1 9.826
Test: [0/50]	Time 0.110 (0.110)	Loss 2.2983 (2.2983)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [33/80][0/250]	LR: 0.1	Time 0.167 (0.167)	Data 0.152 (0.152)	Loss 2.3057 (2.3057)	Prec@1 11.000 (11.000)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.024 (0.026)	Data 0.016 (0.017)	Loss 2.3040 (2.3036)	Prec@1 7.000 (9.822)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.021 (0.026)	Data 0.012 (0.017)	Loss 2.3027 (2.3036)	Prec@1 14.500 (9.955)
 * Training Prec@1 9.934
Test: [0/50]	Time 0.156 (0.156)	Loss 2.3041 (2.3041)	Prec@1 7.000 (7.000)
 * Testing Prec@1 10.000
Epoch: [34/80][0/250]	LR: 0.1	Time 0.110 (0.110)	Data 0.096 (0.096)	Loss 2.3047 (2.3047)	Prec@1 8.500 (8.500)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.023 (0.027)	Data 0.014 (0.018)	Loss 2.3018 (2.3036)	Prec@1 14.500 (10.238)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.026 (0.026)	Data 0.016 (0.017)	Loss 2.3036 (2.3037)	Prec@1 9.500 (10.124)
 * Training Prec@1 10.104
Test: [0/50]	Time 0.161 (0.161)	Loss 2.3046 (2.3046)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [35/80][0/250]	LR: 0.1	Time 0.104 (0.104)	Data 0.089 (0.089)	Loss 2.3045 (2.3045)	Prec@1 10.000 (10.000)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.025 (0.025)	Data 0.015 (0.015)	Loss 2.3031 (2.3036)	Prec@1 11.000 (10.267)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.022 (0.025)	Data 0.013 (0.015)	Loss 2.3021 (2.3037)	Prec@1 10.000 (10.027)
 * Training Prec@1 9.936
Test: [0/50]	Time 0.107 (0.107)	Loss 2.3016 (2.3016)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [36/80][0/250]	LR: 0.1	Time 0.108 (0.108)	Data 0.092 (0.092)	Loss 2.2945 (2.2945)	Prec@1 13.000 (13.000)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.039 (0.026)	Data 0.030 (0.017)	Loss 2.3064 (2.3039)	Prec@1 6.500 (10.158)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.015 (0.016)	Loss 2.3012 (2.3038)	Prec@1 8.500 (10.060)
 * Training Prec@1 10.028
Test: [0/50]	Time 0.147 (0.147)	Loss 2.3066 (2.3066)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [37/80][0/250]	LR: 0.1	Time 0.109 (0.109)	Data 0.093 (0.093)	Loss 2.3046 (2.3046)	Prec@1 8.500 (8.500)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.025 (0.026)	Data 0.017 (0.016)	Loss 2.3009 (2.3038)	Prec@1 13.500 (10.193)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.020 (0.025)	Data 0.013 (0.016)	Loss 2.3002 (2.3039)	Prec@1 13.500 (10.122)
 * Training Prec@1 10.088
Test: [0/50]	Time 0.091 (0.091)	Loss 2.3068 (2.3068)	Prec@1 7.000 (7.000)
 * Testing Prec@1 10.000
Epoch: [38/80][0/250]	LR: 0.1	Time 0.108 (0.108)	Data 0.093 (0.093)	Loss 2.3024 (2.3024)	Prec@1 9.500 (9.500)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.037 (0.026)	Data 0.027 (0.017)	Loss 2.3072 (2.3042)	Prec@1 7.000 (9.965)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.027 (0.026)	Data 0.014 (0.017)	Loss 2.3024 (2.3039)	Prec@1 12.500 (9.945)
 * Training Prec@1 9.934
Test: [0/50]	Time 0.145 (0.145)	Loss 2.3040 (2.3040)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [39/80][0/250]	LR: 0.1	Time 0.108 (0.108)	Data 0.093 (0.093)	Loss 2.3028 (2.3028)	Prec@1 11.000 (11.000)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.023 (0.026)	Data 0.014 (0.016)	Loss 2.3002 (2.3035)	Prec@1 10.500 (9.678)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.026 (0.026)	Data 0.015 (0.016)	Loss 2.3023 (2.3036)	Prec@1 8.500 (9.925)
 * Training Prec@1 9.988
Test: [0/50]	Time 0.103 (0.103)	Loss 2.3024 (2.3024)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.121 (0.121)	Data 0.104 (0.104)	Loss 2.3071 (2.3071)	Prec@1 9.500 (9.500)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.022 (0.026)	Data 0.013 (0.016)	Loss 2.3023 (2.3032)	Prec@1 9.000 (9.743)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.025 (0.026)	Data 0.015 (0.016)	Loss 2.3021 (2.3030)	Prec@1 14.500 (9.746)
 * Training Prec@1 9.844
Test: [0/50]	Time 0.105 (0.105)	Loss 2.3030 (2.3030)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.112 (0.112)	Data 0.098 (0.098)	Loss 2.3037 (2.3037)	Prec@1 9.000 (9.000)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.026 (0.026)	Data 0.017 (0.016)	Loss 2.3024 (2.3027)	Prec@1 7.000 (10.203)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.025 (0.026)	Data 0.014 (0.016)	Loss 2.3028 (2.3028)	Prec@1 6.500 (9.853)
 * Training Prec@1 9.824
Test: [0/50]	Time 0.149 (0.149)	Loss 2.3034 (2.3034)	Prec@1 7.500 (7.500)
 * Testing Prec@1 10.000
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.136 (0.136)	Data 0.117 (0.117)	Loss 2.3029 (2.3029)	Prec@1 9.500 (9.500)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.017 (0.018)	Loss 2.3028 (2.3027)	Prec@1 12.500 (9.990)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.024 (0.026)	Data 0.015 (0.017)	Loss 2.3010 (2.3027)	Prec@1 14.500 (9.871)
 * Training Prec@1 9.750
Test: [0/50]	Time 0.153 (0.153)	Loss 2.3029 (2.3029)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.097 (0.097)	Data 0.081 (0.081)	Loss 2.3027 (2.3027)	Prec@1 9.500 (9.500)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.038 (0.025)	Data 0.027 (0.015)	Loss 2.3020 (2.3026)	Prec@1 8.500 (9.861)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.026 (0.025)	Data 0.018 (0.016)	Loss 2.3028 (2.3027)	Prec@1 7.500 (9.672)
 * Training Prec@1 9.734
Test: [0/50]	Time 0.158 (0.158)	Loss 2.3026 (2.3026)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.110 (0.110)	Data 0.094 (0.094)	Loss 2.3021 (2.3021)	Prec@1 10.500 (10.500)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.024 (0.026)	Data 0.015 (0.016)	Loss 2.3031 (2.3027)	Prec@1 9.000 (10.000)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.024 (0.026)	Data 0.015 (0.016)	Loss 2.3023 (2.3027)	Prec@1 12.000 (10.015)
 * Training Prec@1 9.958
Test: [0/50]	Time 0.092 (0.092)	Loss 2.3038 (2.3038)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.118 (0.118)	Data 0.104 (0.104)	Loss 2.3028 (2.3028)	Prec@1 9.000 (9.000)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.024 (0.025)	Data 0.014 (0.016)	Loss 2.3019 (2.3028)	Prec@1 9.500 (9.896)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.024 (0.025)	Data 0.017 (0.015)	Loss 2.3025 (2.3028)	Prec@1 8.500 (9.833)
 * Training Prec@1 9.842
Test: [0/50]	Time 0.155 (0.155)	Loss 2.3028 (2.3028)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.106 (0.106)	Data 0.090 (0.090)	Loss 2.3031 (2.3031)	Prec@1 9.000 (9.000)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.021 (0.026)	Data 0.011 (0.016)	Loss 2.3021 (2.3027)	Prec@1 9.000 (9.847)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.022 (0.025)	Data 0.013 (0.016)	Loss 2.3023 (2.3028)	Prec@1 12.000 (9.846)
 * Training Prec@1 9.768
Test: [0/50]	Time 0.088 (0.088)	Loss 2.3031 (2.3031)	Prec@1 7.500 (7.500)
 * Testing Prec@1 10.000
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 0.122 (0.122)	Data 0.105 (0.105)	Loss 2.3028 (2.3028)	Prec@1 6.500 (6.500)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.024 (0.025)	Data 0.016 (0.015)	Loss 2.3029 (2.3027)	Prec@1 9.000 (9.970)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.022 (0.024)	Data 0.014 (0.015)	Loss 2.3018 (2.3027)	Prec@1 10.000 (9.988)
 * Training Prec@1 9.894
Test: [0/50]	Time 0.176 (0.176)	Loss 2.3017 (2.3017)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.104 (0.104)	Data 0.087 (0.087)	Loss 2.3020 (2.3020)	Prec@1 13.000 (13.000)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.024 (0.025)	Data 0.015 (0.015)	Loss 2.3033 (2.3028)	Prec@1 3.500 (9.723)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.026 (0.024)	Data 0.018 (0.015)	Loss 2.3033 (2.3027)	Prec@1 10.000 (9.893)
 * Training Prec@1 9.830
Test: [0/50]	Time 0.141 (0.141)	Loss 2.3017 (2.3017)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.121 (0.121)	Data 0.105 (0.105)	Loss 2.3027 (2.3027)	Prec@1 7.000 (7.000)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.026 (0.025)	Data 0.017 (0.016)	Loss 2.3032 (2.3027)	Prec@1 10.000 (9.644)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.025 (0.025)	Data 0.017 (0.016)	Loss 2.3034 (2.3027)	Prec@1 10.500 (9.597)
 * Training Prec@1 9.650
Test: [0/50]	Time 0.117 (0.117)	Loss 2.3017 (2.3017)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.103 (0.103)	Data 0.087 (0.087)	Loss 2.3033 (2.3033)	Prec@1 9.500 (9.500)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.033 (0.025)	Data 0.024 (0.015)	Loss 2.3027 (2.3027)	Prec@1 10.500 (9.658)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.023 (0.025)	Data 0.014 (0.015)	Loss 2.3026 (2.3028)	Prec@1 6.500 (9.525)
 * Training Prec@1 9.480
Test: [0/50]	Time 0.168 (0.168)	Loss 2.3017 (2.3017)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 0.154 (0.154)	Data 0.137 (0.137)	Loss 2.3022 (2.3022)	Prec@1 13.000 (13.000)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.025 (0.026)	Data 0.016 (0.017)	Loss 2.3007 (2.3026)	Prec@1 11.000 (10.297)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.022 (0.025)	Data 0.013 (0.016)	Loss 2.3032 (2.3027)	Prec@1 7.000 (10.082)
 * Training Prec@1 10.108
Test: [0/50]	Time 0.083 (0.083)	Loss 2.3032 (2.3032)	Prec@1 7.500 (7.500)
 * Testing Prec@1 10.000
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.125 (0.125)	Data 0.110 (0.110)	Loss 2.3035 (2.3035)	Prec@1 12.000 (12.000)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.023 (0.027)	Data 0.014 (0.017)	Loss 2.3016 (2.3028)	Prec@1 14.000 (10.144)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.023 (0.026)	Data 0.014 (0.017)	Loss 2.3031 (2.3028)	Prec@1 8.000 (10.035)
 * Training Prec@1 9.940
Test: [0/50]	Time 0.105 (0.105)	Loss 2.3033 (2.3033)	Prec@1 7.000 (7.000)
 * Testing Prec@1 10.000
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 0.119 (0.119)	Data 0.102 (0.102)	Loss 2.3020 (2.3020)	Prec@1 12.000 (12.000)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.024 (0.026)	Data 0.016 (0.017)	Loss 2.3030 (2.3027)	Prec@1 7.000 (9.876)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.024 (0.025)	Data 0.014 (0.016)	Loss 2.3024 (2.3027)	Prec@1 13.500 (10.000)
 * Training Prec@1 9.834
Test: [0/50]	Time 0.112 (0.112)	Loss 2.3022 (2.3022)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.170 (0.170)	Data 0.154 (0.154)	Loss 2.3017 (2.3017)	Prec@1 15.500 (15.500)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.023 (0.026)	Data 0.013 (0.016)	Loss 2.3027 (2.3027)	Prec@1 14.000 (10.005)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.025)	Data 0.018 (0.016)	Loss 2.3019 (2.3027)	Prec@1 11.500 (9.985)
 * Training Prec@1 9.888
Test: [0/50]	Time 0.105 (0.105)	Loss 2.3023 (2.3023)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.155 (0.155)	Data 0.140 (0.140)	Loss 2.3025 (2.3025)	Prec@1 11.000 (11.000)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.024 (0.026)	Data 0.015 (0.017)	Loss 2.3022 (2.3027)	Prec@1 11.000 (9.728)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.023 (0.026)	Data 0.014 (0.017)	Loss 2.3023 (2.3027)	Prec@1 12.000 (9.858)
 * Training Prec@1 9.784
Test: [0/50]	Time 0.151 (0.151)	Loss 2.3027 (2.3027)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.104 (0.104)	Data 0.089 (0.089)	Loss 2.3028 (2.3028)	Prec@1 8.000 (8.000)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.027 (0.025)	Data 0.018 (0.016)	Loss 2.3026 (2.3027)	Prec@1 11.000 (9.866)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.026 (0.025)	Data 0.017 (0.016)	Loss 2.3013 (2.3027)	Prec@1 15.000 (9.831)
 * Training Prec@1 9.822
Test: [0/50]	Time 0.143 (0.143)	Loss 2.3022 (2.3022)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.103 (0.103)	Data 0.086 (0.086)	Loss 2.3020 (2.3020)	Prec@1 13.000 (13.000)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.022 (0.024)	Data 0.014 (0.015)	Loss 2.3049 (2.3026)	Prec@1 6.000 (9.807)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.021 (0.024)	Data 0.012 (0.015)	Loss 2.3034 (2.3027)	Prec@1 6.500 (9.801)
 * Training Prec@1 9.794
Test: [0/50]	Time 0.091 (0.091)	Loss 2.3027 (2.3027)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.185 (0.185)	Data 0.168 (0.168)	Loss 2.3026 (2.3026)	Prec@1 11.000 (11.000)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.025 (0.025)	Data 0.015 (0.016)	Loss 2.3025 (2.3027)	Prec@1 7.500 (10.064)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.034 (0.025)	Data 0.024 (0.016)	Loss 2.3034 (2.3027)	Prec@1 9.000 (10.087)
 * Training Prec@1 9.918
Test: [0/50]	Time 0.152 (0.152)	Loss 2.3028 (2.3028)	Prec@1 7.500 (7.500)
 * Testing Prec@1 10.000
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.117 (0.117)	Data 0.102 (0.102)	Loss 2.3033 (2.3033)	Prec@1 9.500 (9.500)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.023 (0.026)	Data 0.013 (0.016)	Loss 2.3021 (2.3027)	Prec@1 12.000 (10.099)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.026)	Data 0.018 (0.016)	Loss 2.3035 (2.3027)	Prec@1 8.500 (9.920)
 * Training Prec@1 9.848
Test: [0/50]	Time 0.114 (0.114)	Loss 2.3025 (2.3025)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.103 (0.103)	Data 0.087 (0.087)	Loss 2.3031 (2.3031)	Prec@1 9.500 (9.500)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.025 (0.026)	Data 0.015 (0.016)	Loss 2.3028 (2.3026)	Prec@1 10.000 (10.094)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.023 (0.026)	Data 0.014 (0.016)	Loss 2.3035 (2.3026)	Prec@1 9.500 (10.035)
 * Training Prec@1 9.970
Test: [0/50]	Time 0.154 (0.154)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.116 (0.116)	Data 0.099 (0.099)	Loss 2.3027 (2.3027)	Prec@1 12.500 (12.500)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.045 (0.026)	Data 0.036 (0.017)	Loss 2.3029 (2.3026)	Prec@1 8.500 (9.708)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.025 (0.026)	Data 0.016 (0.016)	Loss 2.3027 (2.3026)	Prec@1 10.500 (9.679)
 * Training Prec@1 9.620
Test: [0/50]	Time 0.142 (0.142)	Loss 2.3025 (2.3025)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.103 (0.103)	Data 0.088 (0.088)	Loss 2.3026 (2.3026)	Prec@1 7.500 (7.500)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.024 (0.026)	Data 0.015 (0.017)	Loss 2.3030 (2.3026)	Prec@1 8.500 (10.054)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.024 (0.026)	Data 0.013 (0.016)	Loss 2.3029 (2.3026)	Prec@1 5.500 (9.886)
 * Training Prec@1 9.870
Test: [0/50]	Time 0.154 (0.154)	Loss 2.3025 (2.3025)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 0.121 (0.121)	Data 0.105 (0.105)	Loss 2.3022 (2.3022)	Prec@1 6.500 (6.500)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.031 (0.026)	Data 0.022 (0.016)	Loss 2.3024 (2.3026)	Prec@1 12.500 (9.861)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.025 (0.025)	Data 0.016 (0.016)	Loss 2.3029 (2.3026)	Prec@1 5.500 (9.816)
 * Training Prec@1 9.752
Test: [0/50]	Time 0.165 (0.165)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 0.122 (0.122)	Data 0.107 (0.107)	Loss 2.3027 (2.3027)	Prec@1 8.000 (8.000)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.023 (0.026)	Data 0.014 (0.017)	Loss 2.3026 (2.3026)	Prec@1 10.500 (9.896)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.024 (0.027)	Data 0.015 (0.017)	Loss 2.3025 (2.3026)	Prec@1 12.000 (9.878)
 * Training Prec@1 9.846
Test: [0/50]	Time 0.149 (0.149)	Loss 2.3025 (2.3025)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.161 (0.161)	Data 0.145 (0.145)	Loss 2.3027 (2.3027)	Prec@1 11.500 (11.500)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.021 (0.026)	Data 0.013 (0.017)	Loss 2.3024 (2.3026)	Prec@1 9.000 (9.619)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.023 (0.026)	Data 0.014 (0.016)	Loss 2.3028 (2.3026)	Prec@1 9.500 (9.724)
 * Training Prec@1 9.684
Test: [0/50]	Time 0.147 (0.147)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 0.154 (0.154)	Data 0.137 (0.137)	Loss 2.3026 (2.3026)	Prec@1 8.500 (8.500)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.026 (0.027)	Data 0.017 (0.018)	Loss 2.3025 (2.3026)	Prec@1 8.500 (9.822)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.023 (0.026)	Data 0.013 (0.017)	Loss 2.3023 (2.3026)	Prec@1 13.500 (9.948)
 * Training Prec@1 9.804
Test: [0/50]	Time 0.172 (0.172)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.119 (0.119)	Data 0.103 (0.103)	Loss 2.3026 (2.3026)	Prec@1 8.000 (8.000)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.026)	Data 0.018 (0.016)	Loss 2.3025 (2.3026)	Prec@1 11.500 (10.064)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.025 (0.025)	Data 0.015 (0.016)	Loss 2.3027 (2.3026)	Prec@1 7.000 (10.080)
 * Training Prec@1 9.930
Test: [0/50]	Time 0.143 (0.143)	Loss 2.3026 (2.3026)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.106 (0.106)	Data 0.091 (0.091)	Loss 2.3026 (2.3026)	Prec@1 11.500 (11.500)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.025 (0.025)	Data 0.016 (0.016)	Loss 2.3028 (2.3026)	Prec@1 5.500 (10.287)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.026 (0.025)	Data 0.016 (0.016)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.007)
 * Training Prec@1 9.900
Test: [0/50]	Time 0.154 (0.154)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 0.146 (0.146)	Data 0.130 (0.130)	Loss 2.3026 (2.3026)	Prec@1 11.500 (11.500)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.024 (0.026)	Data 0.013 (0.017)	Loss 2.3028 (2.3026)	Prec@1 9.000 (9.817)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.028 (0.026)	Data 0.019 (0.016)	Loss 2.3025 (2.3026)	Prec@1 13.000 (9.881)
 * Training Prec@1 9.702
Test: [0/50]	Time 0.092 (0.092)	Loss 2.3025 (2.3025)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.112 (0.112)	Data 0.094 (0.094)	Loss 2.3026 (2.3026)	Prec@1 5.000 (5.000)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.025)	Data 0.024 (0.015)	Loss 2.3026 (2.3026)	Prec@1 12.500 (9.827)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.026 (0.025)	Data 0.014 (0.015)	Loss 2.3027 (2.3026)	Prec@1 8.000 (9.764)
 * Training Prec@1 9.752
Test: [0/50]	Time 0.105 (0.105)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.158 (0.158)	Data 0.141 (0.141)	Loss 2.3025 (2.3025)	Prec@1 10.500 (10.500)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.021 (0.026)	Data 0.013 (0.017)	Loss 2.3027 (2.3026)	Prec@1 8.000 (10.079)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.026 (0.026)	Data 0.014 (0.016)	Loss 2.3025 (2.3026)	Prec@1 9.500 (9.779)
 * Training Prec@1 9.778
Test: [0/50]	Time 0.098 (0.098)	Loss 2.3025 (2.3025)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.118 (0.118)	Data 0.103 (0.103)	Loss 2.3025 (2.3025)	Prec@1 13.000 (13.000)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.026 (0.027)	Data 0.017 (0.017)	Loss 2.3028 (2.3026)	Prec@1 10.500 (9.792)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.022 (0.026)	Data 0.013 (0.017)	Loss 2.3026 (2.3026)	Prec@1 11.000 (9.649)
 * Training Prec@1 9.560
Test: [0/50]	Time 0.154 (0.154)	Loss 2.3026 (2.3026)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 0.158 (0.158)	Data 0.141 (0.141)	Loss 2.3026 (2.3026)	Prec@1 8.500 (8.500)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.023 (0.027)	Data 0.015 (0.018)	Loss 2.3026 (2.3026)	Prec@1 8.500 (9.856)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.029 (0.027)	Data 0.020 (0.017)	Loss 2.3025 (2.3026)	Prec@1 12.500 (9.953)
 * Training Prec@1 9.782
Test: [0/50]	Time 0.092 (0.092)	Loss 2.3027 (2.3027)	Prec@1 7.500 (7.500)
 * Testing Prec@1 10.000
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.133 (0.133)	Data 0.116 (0.116)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.500)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.042 (0.027)	Data 0.027 (0.017)	Loss 2.3027 (2.3026)	Prec@1 9.500 (10.173)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.025 (0.027)	Data 0.016 (0.017)	Loss 2.3026 (2.3026)	Prec@1 11.000 (9.945)
 * Training Prec@1 9.796
Test: [0/50]	Time 0.162 (0.162)	Loss 2.3026 (2.3026)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.115 (0.115)	Data 0.099 (0.099)	Loss 2.3026 (2.3026)	Prec@1 11.000 (11.000)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.025 (0.027)	Data 0.015 (0.017)	Loss 2.3026 (2.3026)	Prec@1 7.500 (9.792)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.028 (0.026)	Data 0.019 (0.017)	Loss 2.3026 (2.3026)	Prec@1 8.500 (9.841)
 * Training Prec@1 9.816
Test: [0/50]	Time 0.092 (0.092)	Loss 2.3027 (2.3027)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.104 (0.104)	Data 0.087 (0.087)	Loss 2.3026 (2.3026)	Prec@1 5.500 (5.500)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.025 (0.025)	Data 0.015 (0.016)	Loss 2.3027 (2.3026)	Prec@1 13.500 (10.020)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.024 (0.025)	Data 0.014 (0.015)	Loss 2.3026 (2.3026)	Prec@1 10.000 (9.908)
 * Training Prec@1 9.882
Test: [0/50]	Time 0.110 (0.110)	Loss 2.3026 (2.3026)	Prec@1 7.500 (7.500)
 * Testing Prec@1 10.000
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 0.106 (0.106)	Data 0.089 (0.089)	Loss 2.3027 (2.3027)	Prec@1 11.000 (11.000)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.022 (0.026)	Data 0.013 (0.016)	Loss 2.3026 (2.3026)	Prec@1 11.500 (9.975)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.024 (0.026)	Data 0.015 (0.016)	Loss 2.3028 (2.3026)	Prec@1 6.000 (9.811)
 * Training Prec@1 9.758
Test: [0/50]	Time 0.152 (0.152)	Loss 2.3027 (2.3027)	Prec@1 7.500 (7.500)
 * Testing Prec@1 10.000
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.144 (0.144)	Data 0.127 (0.127)	Loss 2.3026 (2.3026)	Prec@1 10.000 (10.000)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.027 (0.026)	Data 0.018 (0.017)	Loss 2.3026 (2.3026)	Prec@1 11.000 (9.921)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.025 (0.025)	Data 0.014 (0.016)	Loss 2.3027 (2.3026)	Prec@1 8.000 (9.784)
 * Training Prec@1 9.718
Test: [0/50]	Time 0.103 (0.103)	Loss 2.3026 (2.3026)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.103 (0.103)	Data 0.087 (0.087)	Loss 2.3026 (2.3026)	Prec@1 9.500 (9.500)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.024 (0.026)	Data 0.015 (0.016)	Loss 2.3026 (2.3026)	Prec@1 9.500 (9.866)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.030 (0.025)	Data 0.018 (0.016)	Loss 2.3027 (2.3026)	Prec@1 10.000 (9.791)
 * Training Prec@1 9.636
Test: [0/50]	Time 0.102 (0.102)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
