Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'plainnet20'
Epoch: [0/80][0/250]	LR: 0.1	Time 0.433 (0.433)	Data 0.115 (0.115)	Loss 2.3008 (2.3008)	Prec@1 9.000 (9.000)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.031 (0.034)	Data 0.022 (0.022)	Loss 2.3106 (2.3042)	Prec@1 6.500 (9.995)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.032 (0.033)	Data 0.023 (0.022)	Loss 2.3053 (2.3041)	Prec@1 10.000 (9.930)
 * Training Prec@1 9.882
main.py:207: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.150 (0.150)	Loss 2.3038 (2.3038)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
main.py:244: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:245: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:253: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 0.117 (0.117)	Data 0.101 (0.101)	Loss 2.3042 (2.3042)	Prec@1 10.000 (10.000)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.032 (0.032)	Data 0.022 (0.023)	Loss 2.2776 (2.3025)	Prec@1 13.500 (9.936)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.028 (0.032)	Data 0.019 (0.023)	Loss 2.3028 (2.3028)	Prec@1 10.500 (10.286)
 * Training Prec@1 10.220
Test: [0/50]	Time 0.157 (0.157)	Loss 2.3054 (2.3054)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [2/80][0/250]	LR: 0.1	Time 0.167 (0.167)	Data 0.151 (0.151)	Loss 2.3026 (2.3026)	Prec@1 10.000 (10.000)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.031 (0.032)	Data 0.020 (0.022)	Loss 2.3062 (2.3037)	Prec@1 8.000 (9.842)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.030 (0.032)	Data 0.021 (0.022)	Loss 2.3063 (2.3036)	Prec@1 6.500 (9.806)
 * Training Prec@1 9.818
Test: [0/50]	Time 0.156 (0.156)	Loss 2.3079 (2.3079)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [3/80][0/250]	LR: 0.1	Time 0.174 (0.174)	Data 0.156 (0.156)	Loss 2.3033 (2.3033)	Prec@1 10.500 (10.500)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.030 (0.032)	Data 0.020 (0.023)	Loss 2.3035 (2.3036)	Prec@1 10.500 (9.950)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.042 (0.032)	Data 0.033 (0.022)	Loss 2.3097 (2.3037)	Prec@1 9.500 (10.022)
 * Training Prec@1 9.938
Test: [0/50]	Time 0.096 (0.096)	Loss 2.3022 (2.3022)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [4/80][0/250]	LR: 0.1	Time 0.196 (0.196)	Data 0.179 (0.179)	Loss 2.3057 (2.3057)	Prec@1 7.500 (7.500)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.031 (0.032)	Data 0.022 (0.022)	Loss 2.3006 (2.3039)	Prec@1 10.500 (9.257)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.034 (0.032)	Data 0.024 (0.023)	Loss 2.2998 (2.3037)	Prec@1 12.000 (9.537)
 * Training Prec@1 9.632
Test: [0/50]	Time 0.136 (0.136)	Loss 2.3057 (2.3057)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [5/80][0/250]	LR: 0.1	Time 0.200 (0.200)	Data 0.184 (0.184)	Loss 2.3044 (2.3044)	Prec@1 10.000 (10.000)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.030 (0.033)	Data 0.021 (0.023)	Loss 2.3054 (2.3041)	Prec@1 9.000 (9.639)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.030 (0.032)	Data 0.019 (0.022)	Loss 2.3038 (2.3039)	Prec@1 10.500 (9.799)
 * Training Prec@1 9.848
Test: [0/50]	Time 0.091 (0.091)	Loss 2.3021 (2.3021)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [6/80][0/250]	LR: 0.1	Time 0.172 (0.172)	Data 0.156 (0.156)	Loss 2.3049 (2.3049)	Prec@1 7.500 (7.500)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.029 (0.033)	Data 0.019 (0.023)	Loss 2.3050 (2.3038)	Prec@1 11.500 (9.960)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.029 (0.033)	Data 0.020 (0.023)	Loss 2.3078 (2.3036)	Prec@1 8.500 (9.948)
 * Training Prec@1 9.880
Test: [0/50]	Time 0.166 (0.166)	Loss 2.2998 (2.2998)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [7/80][0/250]	LR: 0.1	Time 0.169 (0.169)	Data 0.152 (0.152)	Loss 2.3027 (2.3027)	Prec@1 9.500 (9.500)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.031 (0.032)	Data 0.020 (0.022)	Loss 2.3073 (2.3037)	Prec@1 9.500 (9.970)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.041 (0.032)	Data 0.031 (0.023)	Loss 2.3024 (2.3038)	Prec@1 7.500 (9.915)
 * Training Prec@1 9.954
Test: [0/50]	Time 0.105 (0.105)	Loss 2.3050 (2.3050)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [8/80][0/250]	LR: 0.1	Time 0.192 (0.192)	Data 0.173 (0.173)	Loss 2.3055 (2.3055)	Prec@1 7.500 (7.500)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.033 (0.034)	Data 0.023 (0.024)	Loss 2.3042 (2.3039)	Prec@1 10.500 (10.000)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.030 (0.032)	Data 0.021 (0.023)	Loss 2.3008 (2.3038)	Prec@1 9.000 (9.841)
 * Training Prec@1 9.792
Test: [0/50]	Time 0.144 (0.144)	Loss 2.3043 (2.3043)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [9/80][0/250]	LR: 0.1	Time 0.177 (0.177)	Data 0.162 (0.162)	Loss 2.3045 (2.3045)	Prec@1 9.000 (9.000)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.033 (0.032)	Data 0.024 (0.023)	Loss 2.3045 (2.3037)	Prec@1 11.000 (9.718)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.033 (0.032)	Data 0.024 (0.023)	Loss 2.3012 (2.3038)	Prec@1 10.500 (9.769)
 * Training Prec@1 9.844
Test: [0/50]	Time 0.161 (0.161)	Loss 2.2969 (2.2969)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [10/80][0/250]	LR: 0.1	Time 0.116 (0.116)	Data 0.101 (0.101)	Loss 2.3004 (2.3004)	Prec@1 8.500 (8.500)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.026 (0.031)	Data 0.018 (0.022)	Loss 2.3045 (2.3039)	Prec@1 9.000 (9.604)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.033 (0.031)	Data 0.022 (0.022)	Loss 2.3036 (2.3037)	Prec@1 10.500 (9.764)
 * Training Prec@1 9.774
Test: [0/50]	Time 0.112 (0.112)	Loss 2.3017 (2.3017)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [11/80][0/250]	LR: 0.1	Time 0.182 (0.182)	Data 0.166 (0.166)	Loss 2.3054 (2.3054)	Prec@1 12.000 (12.000)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.033 (0.033)	Data 0.024 (0.023)	Loss 2.3021 (2.3036)	Prec@1 9.000 (10.149)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.035 (0.033)	Data 0.026 (0.023)	Loss 2.2984 (2.3036)	Prec@1 10.000 (9.918)
 * Training Prec@1 9.894
Test: [0/50]	Time 0.149 (0.149)	Loss 2.3031 (2.3031)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [12/80][0/250]	LR: 0.1	Time 0.193 (0.193)	Data 0.177 (0.177)	Loss 2.3086 (2.3086)	Prec@1 8.000 (8.000)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.030 (0.033)	Data 0.021 (0.024)	Loss 2.3056 (2.3038)	Prec@1 8.000 (9.921)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.031 (0.032)	Data 0.021 (0.023)	Loss 2.3026 (2.3036)	Prec@1 11.500 (10.249)
 * Training Prec@1 10.118
Test: [0/50]	Time 0.111 (0.111)	Loss 2.2986 (2.2986)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [13/80][0/250]	LR: 0.1	Time 0.178 (0.178)	Data 0.161 (0.161)	Loss 2.3014 (2.3014)	Prec@1 10.500 (10.500)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.032 (0.032)	Data 0.021 (0.023)	Loss 2.3033 (2.3042)	Prec@1 12.500 (9.876)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.034 (0.032)	Data 0.024 (0.023)	Loss 2.3033 (2.3040)	Prec@1 13.000 (9.910)
 * Training Prec@1 9.950
Test: [0/50]	Time 0.151 (0.151)	Loss 2.3015 (2.3015)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [14/80][0/250]	LR: 0.1	Time 0.185 (0.185)	Data 0.168 (0.168)	Loss 2.3005 (2.3005)	Prec@1 10.500 (10.500)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.033 (0.034)	Data 0.023 (0.023)	Loss 2.2994 (2.3039)	Prec@1 13.500 (9.762)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.034 (0.033)	Data 0.025 (0.023)	Loss 2.3030 (2.3039)	Prec@1 8.000 (9.642)
 * Training Prec@1 9.634
Test: [0/50]	Time 0.104 (0.104)	Loss 2.3111 (2.3111)	Prec@1 7.500 (7.500)
 * Testing Prec@1 10.000
Epoch: [15/80][0/250]	LR: 0.1	Time 0.188 (0.188)	Data 0.170 (0.170)	Loss 2.3005 (2.3005)	Prec@1 8.500 (8.500)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.030 (0.033)	Data 0.021 (0.023)	Loss 2.3082 (2.3039)	Prec@1 9.000 (9.851)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.027 (0.032)	Data 0.017 (0.022)	Loss 2.3060 (2.3042)	Prec@1 9.500 (9.893)
 * Training Prec@1 9.828
Test: [0/50]	Time 0.086 (0.086)	Loss 2.2987 (2.2987)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [16/80][0/250]	LR: 0.1	Time 0.176 (0.176)	Data 0.160 (0.160)	Loss 2.3088 (2.3088)	Prec@1 11.500 (11.500)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.030 (0.034)	Data 0.021 (0.025)	Loss 2.3051 (2.3037)	Prec@1 9.000 (9.639)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.032 (0.033)	Data 0.023 (0.024)	Loss 2.3043 (2.3037)	Prec@1 11.500 (9.851)
 * Training Prec@1 9.928
Test: [0/50]	Time 0.153 (0.153)	Loss 2.3071 (2.3071)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [17/80][0/250]	LR: 0.1	Time 0.180 (0.180)	Data 0.162 (0.162)	Loss 2.3042 (2.3042)	Prec@1 10.000 (10.000)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.030 (0.033)	Data 0.021 (0.023)	Loss 2.3041 (2.3037)	Prec@1 10.000 (9.757)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.034 (0.032)	Data 0.025 (0.023)	Loss 2.3089 (2.3038)	Prec@1 9.500 (9.779)
 * Training Prec@1 9.862
Test: [0/50]	Time 0.113 (0.113)	Loss 2.3137 (2.3137)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [18/80][0/250]	LR: 0.1	Time 0.180 (0.180)	Data 0.164 (0.164)	Loss 2.3108 (2.3108)	Prec@1 8.000 (8.000)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.031 (0.033)	Data 0.022 (0.023)	Loss 2.3105 (2.3033)	Prec@1 8.500 (9.985)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.031 (0.032)	Data 0.022 (0.023)	Loss 2.3127 (2.3037)	Prec@1 7.500 (9.876)
 * Training Prec@1 9.840
Test: [0/50]	Time 0.168 (0.168)	Loss 2.3003 (2.3003)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [19/80][0/250]	LR: 0.1	Time 0.174 (0.174)	Data 0.159 (0.159)	Loss 2.3042 (2.3042)	Prec@1 10.000 (10.000)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.029 (0.032)	Data 0.020 (0.022)	Loss 2.3054 (2.3036)	Prec@1 10.500 (9.975)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.036 (0.032)	Data 0.027 (0.022)	Loss 2.3038 (2.3038)	Prec@1 6.500 (9.808)
 * Training Prec@1 9.872
Test: [0/50]	Time 0.147 (0.147)	Loss 2.3069 (2.3069)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [20/80][0/250]	LR: 0.1	Time 0.175 (0.175)	Data 0.158 (0.158)	Loss 2.3038 (2.3038)	Prec@1 8.000 (8.000)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.031 (0.033)	Data 0.021 (0.022)	Loss 2.3039 (2.3036)	Prec@1 9.500 (10.089)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.031 (0.032)	Data 0.021 (0.022)	Loss 2.3012 (2.3036)	Prec@1 10.000 (10.005)
 * Training Prec@1 9.994
Test: [0/50]	Time 0.167 (0.167)	Loss 2.2989 (2.2989)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [21/80][0/250]	LR: 0.1	Time 0.164 (0.164)	Data 0.148 (0.148)	Loss 2.3049 (2.3049)	Prec@1 10.500 (10.500)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.031 (0.034)	Data 0.022 (0.025)	Loss 2.3040 (2.3041)	Prec@1 8.000 (10.361)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.031 (0.033)	Data 0.022 (0.024)	Loss 2.3015 (2.3040)	Prec@1 11.000 (10.087)
 * Training Prec@1 10.100
Test: [0/50]	Time 0.156 (0.156)	Loss 2.2993 (2.2993)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [22/80][0/250]	LR: 0.1	Time 0.165 (0.165)	Data 0.150 (0.150)	Loss 2.3004 (2.3004)	Prec@1 13.500 (13.500)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.033 (0.033)	Data 0.020 (0.023)	Loss 2.3013 (2.3041)	Prec@1 9.500 (10.000)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.029 (0.033)	Data 0.019 (0.023)	Loss 2.3040 (2.3039)	Prec@1 8.500 (9.915)
 * Training Prec@1 9.990
Test: [0/50]	Time 0.183 (0.183)	Loss 2.3000 (2.3000)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [23/80][0/250]	LR: 0.1	Time 0.194 (0.194)	Data 0.177 (0.177)	Loss 2.3038 (2.3038)	Prec@1 8.500 (8.500)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.031 (0.033)	Data 0.022 (0.023)	Loss 2.3061 (2.3035)	Prec@1 9.500 (9.901)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.032 (0.032)	Data 0.023 (0.023)	Loss 2.3109 (2.3035)	Prec@1 10.000 (9.920)
 * Training Prec@1 9.946
Test: [0/50]	Time 0.100 (0.100)	Loss 2.3074 (2.3074)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [24/80][0/250]	LR: 0.1	Time 0.193 (0.193)	Data 0.175 (0.175)	Loss 2.3024 (2.3024)	Prec@1 10.000 (10.000)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.032 (0.033)	Data 0.023 (0.024)	Loss 2.2972 (2.3039)	Prec@1 17.000 (9.896)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.032 (0.032)	Data 0.023 (0.023)	Loss 2.3006 (2.3040)	Prec@1 10.500 (10.047)
 * Training Prec@1 10.046
Test: [0/50]	Time 0.162 (0.162)	Loss 2.3099 (2.3099)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [25/80][0/250]	LR: 0.1	Time 0.175 (0.175)	Data 0.159 (0.159)	Loss 2.3139 (2.3139)	Prec@1 12.000 (12.000)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.033 (0.033)	Data 0.024 (0.023)	Loss 2.3150 (2.3038)	Prec@1 7.000 (10.139)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.030 (0.033)	Data 0.022 (0.023)	Loss 2.3036 (2.3041)	Prec@1 13.500 (10.179)
 * Training Prec@1 10.144
Test: [0/50]	Time 0.113 (0.113)	Loss 2.3052 (2.3052)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [26/80][0/250]	LR: 0.1	Time 0.130 (0.130)	Data 0.114 (0.114)	Loss 2.3017 (2.3017)	Prec@1 13.000 (13.000)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.033 (0.034)	Data 0.024 (0.024)	Loss 2.3001 (2.3038)	Prec@1 12.000 (10.005)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.031 (0.032)	Data 0.022 (0.023)	Loss 2.2994 (2.3038)	Prec@1 10.500 (9.896)
 * Training Prec@1 9.952
Test: [0/50]	Time 0.091 (0.091)	Loss 2.3006 (2.3006)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [27/80][0/250]	LR: 0.1	Time 0.176 (0.176)	Data 0.160 (0.160)	Loss 2.3055 (2.3055)	Prec@1 8.500 (8.500)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.035 (0.033)	Data 0.026 (0.024)	Loss 2.3041 (2.3045)	Prec@1 8.000 (9.629)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.020 (0.032)	Data 0.012 (0.023)	Loss 2.3046 (2.3041)	Prec@1 11.000 (9.672)
 * Training Prec@1 9.632
Test: [0/50]	Time 0.094 (0.094)	Loss 2.3075 (2.3075)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [28/80][0/250]	LR: 0.1	Time 0.175 (0.175)	Data 0.158 (0.158)	Loss 2.3101 (2.3101)	Prec@1 6.500 (6.500)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.030 (0.033)	Data 0.021 (0.024)	Loss 2.3066 (2.3044)	Prec@1 9.000 (9.545)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.029 (0.032)	Data 0.020 (0.023)	Loss 2.3038 (2.3041)	Prec@1 9.000 (9.617)
 * Training Prec@1 9.702
Test: [0/50]	Time 0.105 (0.105)	Loss 2.3080 (2.3080)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [29/80][0/250]	LR: 0.1	Time 0.172 (0.172)	Data 0.155 (0.155)	Loss 2.3036 (2.3036)	Prec@1 10.000 (10.000)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.033 (0.033)	Data 0.024 (0.023)	Loss 2.3038 (2.3044)	Prec@1 9.500 (10.050)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.032 (0.032)	Data 0.022 (0.022)	Loss 2.3048 (2.3040)	Prec@1 11.000 (9.993)
 * Training Prec@1 9.988
Test: [0/50]	Time 0.101 (0.101)	Loss 2.3025 (2.3025)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [30/80][0/250]	LR: 0.1	Time 0.178 (0.178)	Data 0.161 (0.161)	Loss 2.3051 (2.3051)	Prec@1 10.000 (10.000)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.032 (0.034)	Data 0.023 (0.025)	Loss 2.3057 (2.3039)	Prec@1 8.500 (10.015)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.029 (0.033)	Data 0.020 (0.023)	Loss 2.2996 (2.3037)	Prec@1 13.500 (10.147)
 * Training Prec@1 10.176
Test: [0/50]	Time 0.098 (0.098)	Loss 2.3035 (2.3035)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [31/80][0/250]	LR: 0.1	Time 0.182 (0.182)	Data 0.166 (0.166)	Loss 2.3097 (2.3097)	Prec@1 6.500 (6.500)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.044 (0.034)	Data 0.034 (0.023)	Loss 2.3037 (2.3040)	Prec@1 8.500 (9.886)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.030 (0.033)	Data 0.020 (0.022)	Loss 2.3046 (2.3039)	Prec@1 7.000 (9.794)
 * Training Prec@1 9.794
Test: [0/50]	Time 0.098 (0.098)	Loss 2.3057 (2.3057)	Prec@1 7.000 (7.000)
 * Testing Prec@1 10.000
Epoch: [32/80][0/250]	LR: 0.1	Time 0.177 (0.177)	Data 0.159 (0.159)	Loss 2.3033 (2.3033)	Prec@1 9.500 (9.500)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.030 (0.032)	Data 0.021 (0.022)	Loss 2.3022 (2.3038)	Prec@1 12.000 (10.119)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.039 (0.032)	Data 0.030 (0.022)	Loss 2.3053 (2.3038)	Prec@1 7.500 (10.226)
 * Training Prec@1 10.212
Test: [0/50]	Time 0.164 (0.164)	Loss 2.3030 (2.3030)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [33/80][0/250]	LR: 0.1	Time 0.170 (0.170)	Data 0.152 (0.152)	Loss 2.3111 (2.3111)	Prec@1 7.500 (7.500)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.032 (0.034)	Data 0.019 (0.023)	Loss 2.2987 (2.3041)	Prec@1 14.500 (9.713)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.032 (0.032)	Data 0.021 (0.022)	Loss 2.3052 (2.3041)	Prec@1 8.000 (9.709)
 * Training Prec@1 9.682
Test: [0/50]	Time 0.106 (0.106)	Loss 2.3043 (2.3043)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [34/80][0/250]	LR: 0.1	Time 0.192 (0.192)	Data 0.175 (0.175)	Loss 2.3064 (2.3064)	Prec@1 9.500 (9.500)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.028 (0.032)	Data 0.019 (0.022)	Loss 2.3078 (2.3037)	Prec@1 10.000 (10.129)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.033 (0.032)	Data 0.023 (0.022)	Loss 2.3035 (2.3039)	Prec@1 7.000 (9.930)
 * Training Prec@1 10.006
Test: [0/50]	Time 0.160 (0.160)	Loss 2.3075 (2.3075)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [35/80][0/250]	LR: 0.1	Time 0.165 (0.165)	Data 0.149 (0.149)	Loss 2.3077 (2.3077)	Prec@1 10.500 (10.500)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.032 (0.034)	Data 0.022 (0.024)	Loss 2.3028 (2.3037)	Prec@1 13.000 (10.168)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.033 (0.032)	Data 0.023 (0.023)	Loss 2.3027 (2.3037)	Prec@1 10.000 (10.040)
 * Training Prec@1 10.004
Test: [0/50]	Time 0.105 (0.105)	Loss 2.3071 (2.3071)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [36/80][0/250]	LR: 0.1	Time 0.183 (0.183)	Data 0.165 (0.165)	Loss 2.3073 (2.3073)	Prec@1 10.000 (10.000)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.031 (0.033)	Data 0.020 (0.023)	Loss 2.3037 (2.3037)	Prec@1 9.500 (9.703)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.034 (0.033)	Data 0.025 (0.023)	Loss 2.3055 (2.3039)	Prec@1 7.500 (9.826)
 * Training Prec@1 9.804
Test: [0/50]	Time 0.112 (0.112)	Loss 2.2990 (2.2990)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [37/80][0/250]	LR: 0.1	Time 0.182 (0.182)	Data 0.166 (0.166)	Loss 2.2995 (2.2995)	Prec@1 9.000 (9.000)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.030 (0.033)	Data 0.021 (0.024)	Loss 2.3047 (2.3035)	Prec@1 9.000 (10.411)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.028 (0.032)	Data 0.018 (0.023)	Loss 2.3029 (2.3037)	Prec@1 9.000 (10.104)
 * Training Prec@1 10.050
Test: [0/50]	Time 0.116 (0.116)	Loss 2.3008 (2.3008)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [38/80][0/250]	LR: 0.1	Time 0.189 (0.189)	Data 0.173 (0.173)	Loss 2.3088 (2.3088)	Prec@1 8.000 (8.000)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.032 (0.033)	Data 0.023 (0.024)	Loss 2.3014 (2.3035)	Prec@1 12.000 (9.916)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.034 (0.033)	Data 0.025 (0.024)	Loss 2.3025 (2.3037)	Prec@1 9.500 (9.920)
 * Training Prec@1 9.960
Test: [0/50]	Time 0.122 (0.122)	Loss 2.3046 (2.3046)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [39/80][0/250]	LR: 0.1	Time 0.194 (0.194)	Data 0.177 (0.177)	Loss 2.3089 (2.3089)	Prec@1 6.000 (6.000)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.031 (0.033)	Data 0.022 (0.024)	Loss 2.3039 (2.3043)	Prec@1 6.500 (9.673)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.043 (0.033)	Data 0.030 (0.023)	Loss 2.2994 (2.3040)	Prec@1 14.000 (9.876)
 * Training Prec@1 9.878
Test: [0/50]	Time 0.094 (0.094)	Loss 2.3044 (2.3044)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.188 (0.188)	Data 0.170 (0.170)	Loss 2.2987 (2.2987)	Prec@1 10.000 (10.000)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.033 (0.033)	Data 0.023 (0.024)	Loss 2.3019 (2.3033)	Prec@1 12.500 (9.564)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.030 (0.033)	Data 0.021 (0.023)	Loss 2.3024 (2.3030)	Prec@1 11.000 (9.801)
 * Training Prec@1 9.816
Test: [0/50]	Time 0.095 (0.095)	Loss 2.3032 (2.3032)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.188 (0.188)	Data 0.169 (0.169)	Loss 2.3030 (2.3030)	Prec@1 10.500 (10.500)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.048 (0.032)	Data 0.037 (0.022)	Loss 2.3030 (2.3028)	Prec@1 8.500 (9.718)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.029 (0.032)	Data 0.020 (0.022)	Loss 2.3029 (2.3028)	Prec@1 13.500 (9.667)
 * Training Prec@1 9.684
Test: [0/50]	Time 0.112 (0.112)	Loss 2.3022 (2.3022)	Prec@1 7.500 (7.500)
 * Testing Prec@1 10.000
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.197 (0.197)	Data 0.179 (0.179)	Loss 2.3030 (2.3030)	Prec@1 9.000 (9.000)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.030 (0.034)	Data 0.020 (0.024)	Loss 2.3024 (2.3027)	Prec@1 10.500 (9.743)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.030 (0.033)	Data 0.021 (0.023)	Loss 2.3038 (2.3027)	Prec@1 10.500 (9.903)
 * Training Prec@1 9.810
Test: [0/50]	Time 0.104 (0.104)	Loss 2.3026 (2.3026)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.195 (0.195)	Data 0.178 (0.178)	Loss 2.3016 (2.3016)	Prec@1 12.500 (12.500)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.029 (0.033)	Data 0.019 (0.023)	Loss 2.3026 (2.3027)	Prec@1 7.000 (9.777)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.032 (0.032)	Data 0.022 (0.023)	Loss 2.3037 (2.3027)	Prec@1 5.500 (9.828)
 * Training Prec@1 9.766
Test: [0/50]	Time 0.168 (0.168)	Loss 2.3032 (2.3032)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.190 (0.190)	Data 0.171 (0.171)	Loss 2.3023 (2.3023)	Prec@1 10.000 (10.000)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.029 (0.034)	Data 0.020 (0.024)	Loss 2.3020 (2.3028)	Prec@1 10.500 (9.837)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.032 (0.033)	Data 0.022 (0.023)	Loss 2.3023 (2.3028)	Prec@1 7.500 (9.644)
 * Training Prec@1 9.638
Test: [0/50]	Time 0.100 (0.100)	Loss 2.3015 (2.3015)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.183 (0.183)	Data 0.170 (0.170)	Loss 2.3028 (2.3028)	Prec@1 9.000 (9.000)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.030 (0.032)	Data 0.020 (0.023)	Loss 2.3010 (2.3027)	Prec@1 11.000 (10.163)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.030 (0.031)	Data 0.019 (0.022)	Loss 2.3032 (2.3027)	Prec@1 9.500 (9.883)
 * Training Prec@1 9.744
Test: [0/50]	Time 0.100 (0.100)	Loss 2.3028 (2.3028)	Prec@1 7.000 (7.000)
 * Testing Prec@1 10.000
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.187 (0.187)	Data 0.170 (0.170)	Loss 2.3020 (2.3020)	Prec@1 13.000 (13.000)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.032 (0.032)	Data 0.023 (0.023)	Loss 2.3023 (2.3027)	Prec@1 8.500 (9.926)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.030 (0.032)	Data 0.021 (0.022)	Loss 2.3027 (2.3027)	Prec@1 12.000 (9.779)
 * Training Prec@1 9.808
Test: [0/50]	Time 0.170 (0.170)	Loss 2.3032 (2.3032)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 0.183 (0.183)	Data 0.167 (0.167)	Loss 2.3012 (2.3012)	Prec@1 14.500 (14.500)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.033 (0.034)	Data 0.023 (0.024)	Loss 2.3034 (2.3027)	Prec@1 10.000 (9.941)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.030 (0.033)	Data 0.020 (0.023)	Loss 2.3038 (2.3027)	Prec@1 5.500 (9.831)
 * Training Prec@1 9.804
Test: [0/50]	Time 0.095 (0.095)	Loss 2.3026 (2.3026)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.199 (0.199)	Data 0.181 (0.181)	Loss 2.3030 (2.3030)	Prec@1 8.500 (8.500)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.032 (0.032)	Data 0.023 (0.023)	Loss 2.3034 (2.3027)	Prec@1 9.500 (9.876)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.030 (0.033)	Data 0.021 (0.023)	Loss 2.3033 (2.3027)	Prec@1 8.000 (9.843)
 * Training Prec@1 9.732
Test: [0/50]	Time 0.109 (0.109)	Loss 2.3027 (2.3027)	Prec@1 7.500 (7.500)
 * Testing Prec@1 10.000
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.178 (0.178)	Data 0.159 (0.159)	Loss 2.3028 (2.3028)	Prec@1 10.500 (10.500)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.030 (0.034)	Data 0.021 (0.024)	Loss 2.3022 (2.3027)	Prec@1 13.000 (10.109)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.032 (0.033)	Data 0.023 (0.023)	Loss 2.3027 (2.3027)	Prec@1 10.500 (9.955)
 * Training Prec@1 9.880
Test: [0/50]	Time 0.173 (0.173)	Loss 2.3024 (2.3024)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.184 (0.184)	Data 0.167 (0.167)	Loss 2.3029 (2.3029)	Prec@1 7.000 (7.000)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.032 (0.033)	Data 0.023 (0.024)	Loss 2.3022 (2.3027)	Prec@1 10.500 (9.787)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.031 (0.033)	Data 0.021 (0.023)	Loss 2.3027 (2.3027)	Prec@1 12.500 (9.771)
 * Training Prec@1 9.792
Test: [0/50]	Time 0.152 (0.152)	Loss 2.3032 (2.3032)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 0.184 (0.184)	Data 0.168 (0.168)	Loss 2.3027 (2.3027)	Prec@1 8.000 (8.000)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.031 (0.033)	Data 0.021 (0.024)	Loss 2.3017 (2.3027)	Prec@1 11.000 (9.748)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.034 (0.032)	Data 0.025 (0.023)	Loss 2.3032 (2.3027)	Prec@1 9.000 (9.731)
 * Training Prec@1 9.654
Test: [0/50]	Time 0.155 (0.155)	Loss 2.3013 (2.3013)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.185 (0.185)	Data 0.170 (0.170)	Loss 2.3022 (2.3022)	Prec@1 9.500 (9.500)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.032 (0.034)	Data 0.023 (0.024)	Loss 2.3040 (2.3027)	Prec@1 7.000 (9.990)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.031 (0.033)	Data 0.022 (0.024)	Loss 2.3023 (2.3027)	Prec@1 4.500 (9.774)
 * Training Prec@1 9.706
Test: [0/50]	Time 0.152 (0.152)	Loss 2.3027 (2.3027)	Prec@1 7.000 (7.000)
 * Testing Prec@1 10.000
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 0.178 (0.178)	Data 0.160 (0.160)	Loss 2.3027 (2.3027)	Prec@1 11.500 (11.500)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.031 (0.033)	Data 0.022 (0.023)	Loss 2.3031 (2.3027)	Prec@1 7.500 (9.980)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.032 (0.032)	Data 0.020 (0.023)	Loss 2.3024 (2.3028)	Prec@1 8.500 (9.831)
 * Training Prec@1 9.790
Test: [0/50]	Time 0.170 (0.170)	Loss 2.3022 (2.3022)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.183 (0.183)	Data 0.169 (0.169)	Loss 2.3027 (2.3027)	Prec@1 10.000 (10.000)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.030 (0.034)	Data 0.020 (0.024)	Loss 2.3017 (2.3027)	Prec@1 12.500 (9.990)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.030 (0.032)	Data 0.021 (0.023)	Loss 2.3027 (2.3027)	Prec@1 6.500 (9.831)
 * Training Prec@1 9.808
Test: [0/50]	Time 0.107 (0.107)	Loss 2.3019 (2.3019)	Prec@1 10.000 (10.000)
 * Testing Prec@1 10.000
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.171 (0.171)	Data 0.156 (0.156)	Loss 2.3025 (2.3025)	Prec@1 10.500 (10.500)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.030 (0.032)	Data 0.021 (0.023)	Loss 2.3034 (2.3027)	Prec@1 7.500 (10.104)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.032 (0.032)	Data 0.022 (0.023)	Loss 2.3036 (2.3027)	Prec@1 6.000 (10.012)
 * Training Prec@1 9.914
Test: [0/50]	Time 0.104 (0.104)	Loss 2.3031 (2.3031)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.175 (0.175)	Data 0.158 (0.158)	Loss 2.3027 (2.3027)	Prec@1 9.000 (9.000)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.030 (0.032)	Data 0.021 (0.022)	Loss 2.3034 (2.3027)	Prec@1 9.500 (9.683)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.031 (0.032)	Data 0.022 (0.023)	Loss 2.3029 (2.3028)	Prec@1 11.500 (9.833)
 * Training Prec@1 9.818
Test: [0/50]	Time 0.100 (0.100)	Loss 2.3031 (2.3031)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.206 (0.206)	Data 0.189 (0.189)	Loss 2.3023 (2.3023)	Prec@1 12.000 (12.000)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.030 (0.034)	Data 0.022 (0.024)	Loss 2.3019 (2.3026)	Prec@1 10.000 (9.752)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.031 (0.033)	Data 0.022 (0.023)	Loss 2.3044 (2.3027)	Prec@1 8.500 (9.998)
 * Training Prec@1 9.926
Test: [0/50]	Time 0.164 (0.164)	Loss 2.3016 (2.3016)	Prec@1 14.000 (14.000)
 * Testing Prec@1 10.000
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.183 (0.183)	Data 0.167 (0.167)	Loss 2.3029 (2.3029)	Prec@1 11.000 (11.000)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.031 (0.033)	Data 0.022 (0.023)	Loss 2.3032 (2.3027)	Prec@1 9.500 (9.946)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.033 (0.033)	Data 0.022 (0.023)	Loss 2.3029 (2.3028)	Prec@1 9.000 (9.851)
 * Training Prec@1 9.826
Test: [0/50]	Time 0.102 (0.102)	Loss 2.3016 (2.3016)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.175 (0.175)	Data 0.158 (0.158)	Loss 2.3031 (2.3031)	Prec@1 9.000 (9.000)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.029 (0.033)	Data 0.021 (0.022)	Loss 2.3032 (2.3028)	Prec@1 6.000 (9.748)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.031 (0.032)	Data 0.022 (0.022)	Loss 2.3020 (2.3028)	Prec@1 9.500 (9.823)
 * Training Prec@1 9.778
Test: [0/50]	Time 0.098 (0.098)	Loss 2.3022 (2.3022)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.196 (0.196)	Data 0.180 (0.180)	Loss 2.3028 (2.3028)	Prec@1 7.500 (7.500)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.030 (0.033)	Data 0.022 (0.023)	Loss 2.3024 (2.3026)	Prec@1 12.500 (9.936)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.031 (0.032)	Data 0.021 (0.023)	Loss 2.3023 (2.3026)	Prec@1 10.500 (10.052)
 * Training Prec@1 10.000
Test: [0/50]	Time 0.166 (0.166)	Loss 2.3023 (2.3023)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.181 (0.181)	Data 0.165 (0.165)	Loss 2.3024 (2.3024)	Prec@1 10.000 (10.000)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.027 (0.032)	Data 0.018 (0.023)	Loss 2.3023 (2.3026)	Prec@1 13.500 (9.876)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.031 (0.032)	Data 0.020 (0.022)	Loss 2.3024 (2.3026)	Prec@1 10.500 (9.983)
 * Training Prec@1 9.936
Test: [0/50]	Time 0.106 (0.106)	Loss 2.3024 (2.3024)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.184 (0.184)	Data 0.168 (0.168)	Loss 2.3026 (2.3026)	Prec@1 7.000 (7.000)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.032 (0.033)	Data 0.023 (0.024)	Loss 2.3026 (2.3026)	Prec@1 8.500 (10.050)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.031 (0.032)	Data 0.020 (0.023)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.075)
 * Training Prec@1 10.000
Test: [0/50]	Time 0.102 (0.102)	Loss 2.3024 (2.3024)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 0.188 (0.188)	Data 0.172 (0.172)	Loss 2.3025 (2.3025)	Prec@1 8.500 (8.500)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.033)	Data 0.026 (0.024)	Loss 2.3029 (2.3026)	Prec@1 7.000 (10.054)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.031 (0.033)	Data 0.022 (0.023)	Loss 2.3022 (2.3026)	Prec@1 11.000 (10.020)
 * Training Prec@1 9.806
Test: [0/50]	Time 0.159 (0.159)	Loss 2.3025 (2.3025)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 0.174 (0.174)	Data 0.158 (0.158)	Loss 2.3025 (2.3025)	Prec@1 7.500 (7.500)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.030)	Data 0.019 (0.021)	Loss 2.3026 (2.3026)	Prec@1 9.000 (9.960)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.034 (0.030)	Data 0.025 (0.021)	Loss 2.3027 (2.3026)	Prec@1 9.000 (9.848)
 * Training Prec@1 9.814
Test: [0/50]	Time 0.095 (0.095)	Loss 2.3025 (2.3025)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.189 (0.189)	Data 0.167 (0.167)	Loss 2.3026 (2.3026)	Prec@1 10.000 (10.000)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.030 (0.031)	Data 0.021 (0.021)	Loss 2.3027 (2.3026)	Prec@1 7.500 (10.168)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.030 (0.030)	Data 0.020 (0.021)	Loss 2.3025 (2.3026)	Prec@1 12.500 (9.975)
 * Training Prec@1 9.900
Test: [0/50]	Time 0.102 (0.102)	Loss 2.3025 (2.3025)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 0.159 (0.159)	Data 0.143 (0.143)	Loss 2.3026 (2.3026)	Prec@1 9.500 (9.500)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.030 (0.032)	Data 0.021 (0.022)	Loss 2.3026 (2.3026)	Prec@1 11.000 (9.881)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.028 (0.030)	Data 0.017 (0.021)	Loss 2.3027 (2.3026)	Prec@1 8.500 (9.794)
 * Training Prec@1 9.724
Test: [0/50]	Time 0.107 (0.107)	Loss 2.3025 (2.3025)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.165 (0.165)	Data 0.149 (0.149)	Loss 2.3027 (2.3027)	Prec@1 11.500 (11.500)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.036 (0.032)	Data 0.026 (0.022)	Loss 2.3027 (2.3026)	Prec@1 5.500 (9.936)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.031 (0.031)	Data 0.021 (0.021)	Loss 2.3026 (2.3026)	Prec@1 7.000 (9.614)
 * Training Prec@1 9.636
Test: [0/50]	Time 0.103 (0.103)	Loss 2.3025 (2.3025)	Prec@1 9.000 (9.000)
 * Testing Prec@1 10.000
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.176 (0.176)	Data 0.159 (0.159)	Loss 2.3025 (2.3025)	Prec@1 9.500 (9.500)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.031 (0.033)	Data 0.022 (0.024)	Loss 2.3025 (2.3026)	Prec@1 9.500 (9.866)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.032 (0.032)	Data 0.023 (0.022)	Loss 2.3025 (2.3026)	Prec@1 13.500 (9.607)
 * Training Prec@1 9.622
Test: [0/50]	Time 0.099 (0.099)	Loss 2.3025 (2.3025)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 0.202 (0.202)	Data 0.184 (0.184)	Loss 2.3026 (2.3026)	Prec@1 12.500 (12.500)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.025 (0.032)	Data 0.016 (0.022)	Loss 2.3026 (2.3026)	Prec@1 10.500 (9.807)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.031)	Data 0.018 (0.022)	Loss 2.3025 (2.3026)	Prec@1 13.000 (9.739)
 * Training Prec@1 9.720
Test: [0/50]	Time 0.101 (0.101)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.170 (0.170)	Data 0.152 (0.152)	Loss 2.3026 (2.3026)	Prec@1 6.000 (6.000)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.032 (0.032)	Data 0.022 (0.023)	Loss 2.3026 (2.3026)	Prec@1 8.000 (9.678)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.028 (0.031)	Data 0.020 (0.022)	Loss 2.3026 (2.3026)	Prec@1 9.500 (9.888)
 * Training Prec@1 9.760
Test: [0/50]	Time 0.095 (0.095)	Loss 2.3026 (2.3026)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.170 (0.170)	Data 0.154 (0.154)	Loss 2.3026 (2.3026)	Prec@1 6.000 (6.000)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.031)	Data 0.020 (0.022)	Loss 2.3026 (2.3026)	Prec@1 8.000 (9.842)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.032 (0.031)	Data 0.023 (0.022)	Loss 2.3025 (2.3026)	Prec@1 11.000 (9.881)
 * Training Prec@1 9.798
Test: [0/50]	Time 0.109 (0.109)	Loss 2.3026 (2.3026)	Prec@1 7.500 (7.500)
 * Testing Prec@1 10.000
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.177 (0.177)	Data 0.161 (0.161)	Loss 2.3026 (2.3026)	Prec@1 13.500 (13.500)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.031)	Data 0.020 (0.022)	Loss 2.3028 (2.3026)	Prec@1 8.500 (9.946)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.042 (0.031)	Data 0.032 (0.021)	Loss 2.3026 (2.3026)	Prec@1 10.000 (9.873)
 * Training Prec@1 9.776
Test: [0/50]	Time 0.093 (0.093)	Loss 2.3025 (2.3025)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 0.168 (0.168)	Data 0.149 (0.149)	Loss 2.3026 (2.3026)	Prec@1 12.000 (12.000)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.030)	Data 0.020 (0.021)	Loss 2.3027 (2.3026)	Prec@1 8.500 (9.792)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.042 (0.030)	Data 0.033 (0.021)	Loss 2.3026 (2.3026)	Prec@1 10.500 (9.818)
 * Training Prec@1 9.768
Test: [0/50]	Time 0.106 (0.106)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.167 (0.167)	Data 0.151 (0.151)	Loss 2.3026 (2.3026)	Prec@1 7.000 (7.000)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.030)	Data 0.019 (0.021)	Loss 2.3027 (2.3026)	Prec@1 10.000 (10.005)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.044 (0.030)	Data 0.034 (0.021)	Loss 2.3025 (2.3026)	Prec@1 10.500 (9.943)
 * Training Prec@1 9.762
Test: [0/50]	Time 0.115 (0.115)	Loss 2.3025 (2.3025)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.178 (0.178)	Data 0.162 (0.162)	Loss 2.3026 (2.3026)	Prec@1 10.000 (10.000)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.030 (0.031)	Data 0.020 (0.022)	Loss 2.3026 (2.3026)	Prec@1 8.500 (9.713)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.029 (0.031)	Data 0.021 (0.021)	Loss 2.3026 (2.3026)	Prec@1 7.500 (9.634)
 * Training Prec@1 9.622
Test: [0/50]	Time 0.098 (0.098)	Loss 2.3025 (2.3025)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.202 (0.202)	Data 0.185 (0.185)	Loss 2.3026 (2.3026)	Prec@1 8.000 (8.000)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.032 (0.031)	Data 0.023 (0.022)	Loss 2.3026 (2.3026)	Prec@1 9.000 (9.792)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.031)	Data 0.019 (0.021)	Loss 2.3027 (2.3026)	Prec@1 7.000 (9.704)
 * Training Prec@1 9.672
Test: [0/50]	Time 0.098 (0.098)	Loss 2.3025 (2.3025)	Prec@1 13.000 (13.000)
 * Testing Prec@1 10.000
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 0.170 (0.170)	Data 0.154 (0.154)	Loss 2.3026 (2.3026)	Prec@1 8.500 (8.500)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.044 (0.031)	Data 0.034 (0.022)	Loss 2.3024 (2.3026)	Prec@1 12.500 (10.020)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.028 (0.031)	Data 0.019 (0.022)	Loss 2.3026 (2.3026)	Prec@1 8.500 (9.781)
 * Training Prec@1 9.780
Test: [0/50]	Time 0.101 (0.101)	Loss 2.3025 (2.3025)	Prec@1 9.500 (9.500)
 * Testing Prec@1 10.000
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.171 (0.171)	Data 0.154 (0.154)	Loss 2.3026 (2.3026)	Prec@1 8.500 (8.500)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.032)	Data 0.019 (0.022)	Loss 2.3026 (2.3026)	Prec@1 14.500 (9.728)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.029 (0.031)	Data 0.020 (0.022)	Loss 2.3026 (2.3026)	Prec@1 7.500 (9.838)
 * Training Prec@1 9.766
Test: [0/50]	Time 0.096 (0.096)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.169 (0.169)	Data 0.152 (0.152)	Loss 2.3026 (2.3026)	Prec@1 6.500 (6.500)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.032)	Data 0.020 (0.023)	Loss 2.3026 (2.3026)	Prec@1 9.000 (9.733)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.030 (0.032)	Data 0.021 (0.023)	Loss 2.3025 (2.3026)	Prec@1 11.500 (9.799)
 * Training Prec@1 9.722
Test: [0/50]	Time 0.097 (0.097)	Loss 2.3026 (2.3026)	Prec@1 10.500 (10.500)
 * Testing Prec@1 10.000
