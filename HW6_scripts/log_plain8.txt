Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'plainnet8'
Epoch: [0/80][0/250]	LR: 0.1	Time 0.515 (0.515)	Data 0.122 (0.122)	Loss 2.3425 (2.3425)	Prec@1 10.000 (10.000)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.028 (0.040)	Data 0.020 (0.027)	Loss 1.4425 (1.7901)	Prec@1 44.000 (31.569)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.028 (0.035)	Data 0.019 (0.024)	Loss 1.1875 (1.6137)	Prec@1 58.000 (39.134)
 * Training Prec@1 41.926
main.py:198: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.108 (0.108)	Loss 1.2739 (1.2739)	Prec@1 51.500 (51.500)
 * Testing Prec@1 51.790
main.py:235: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:236: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:244: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 0.092 (0.092)	Data 0.074 (0.074)	Loss 1.2670 (1.2670)	Prec@1 51.500 (51.500)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.030 (0.028)	Data 0.023 (0.021)	Loss 1.0323 (1.1745)	Prec@1 64.000 (56.881)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.034 (0.028)	Data 0.027 (0.021)	Loss 1.0370 (1.1180)	Prec@1 63.500 (59.269)
 * Training Prec@1 60.094
Test: [0/50]	Time 0.121 (0.121)	Loss 1.1018 (1.1018)	Prec@1 61.000 (61.000)
 * Testing Prec@1 59.420
Epoch: [2/80][0/250]	LR: 0.1	Time 0.136 (0.136)	Data 0.115 (0.115)	Loss 0.8687 (0.8687)	Prec@1 67.500 (67.500)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.027 (0.031)	Data 0.020 (0.023)	Loss 1.0209 (0.9664)	Prec@1 62.000 (65.134)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.028 (0.029)	Data 0.022 (0.022)	Loss 0.9854 (0.9395)	Prec@1 64.000 (66.386)
 * Training Prec@1 66.718
Test: [0/50]	Time 0.105 (0.105)	Loss 0.8909 (0.8909)	Prec@1 69.500 (69.500)
 * Testing Prec@1 65.140
Epoch: [3/80][0/250]	LR: 0.1	Time 0.132 (0.132)	Data 0.117 (0.117)	Loss 0.7683 (0.7683)	Prec@1 72.000 (72.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.028 (0.028)	Data 0.022 (0.021)	Loss 0.9035 (0.8358)	Prec@1 66.500 (70.074)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.028 (0.028)	Data 0.018 (0.021)	Loss 0.7333 (0.8195)	Prec@1 77.500 (70.781)
 * Training Prec@1 70.788
Test: [0/50]	Time 0.077 (0.077)	Loss 0.8278 (0.8278)	Prec@1 69.500 (69.500)
 * Testing Prec@1 68.530
Epoch: [4/80][0/250]	LR: 0.1	Time 0.086 (0.086)	Data 0.072 (0.072)	Loss 0.6982 (0.6982)	Prec@1 74.000 (74.000)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.021 (0.020)	Loss 0.6466 (0.7438)	Prec@1 80.500 (73.713)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.027 (0.027)	Data 0.020 (0.020)	Loss 0.8201 (0.7440)	Prec@1 69.500 (73.667)
 * Training Prec@1 73.810
Test: [0/50]	Time 0.124 (0.124)	Loss 0.9513 (0.9513)	Prec@1 67.000 (67.000)
 * Testing Prec@1 65.910
Epoch: [5/80][0/250]	LR: 0.1	Time 0.129 (0.129)	Data 0.114 (0.114)	Loss 0.6748 (0.6748)	Prec@1 78.500 (78.500)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.022 (0.022)	Loss 0.6690 (0.6803)	Prec@1 71.500 (76.035)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.019 (0.021)	Loss 0.6944 (0.6806)	Prec@1 78.000 (76.124)
 * Training Prec@1 76.218
Test: [0/50]	Time 0.078 (0.078)	Loss 0.7647 (0.7647)	Prec@1 72.500 (72.500)
 * Testing Prec@1 71.660
Epoch: [6/80][0/250]	LR: 0.1	Time 0.124 (0.124)	Data 0.106 (0.106)	Loss 0.5451 (0.5451)	Prec@1 81.000 (81.000)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.026 (0.027)	Data 0.021 (0.022)	Loss 0.6277 (0.6281)	Prec@1 80.500 (78.134)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.033 (0.027)	Data 0.025 (0.021)	Loss 0.6482 (0.6282)	Prec@1 79.000 (77.943)
 * Training Prec@1 77.840
Test: [0/50]	Time 0.125 (0.125)	Loss 0.7866 (0.7866)	Prec@1 70.000 (70.000)
 * Testing Prec@1 71.680
Epoch: [7/80][0/250]	LR: 0.1	Time 0.131 (0.131)	Data 0.116 (0.116)	Loss 0.5616 (0.5616)	Prec@1 82.000 (82.000)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.026 (0.028)	Data 0.021 (0.021)	Loss 0.5751 (0.5939)	Prec@1 79.000 (79.233)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.028 (0.028)	Data 0.020 (0.021)	Loss 0.5104 (0.5919)	Prec@1 83.000 (79.254)
 * Training Prec@1 79.222
Test: [0/50]	Time 0.129 (0.129)	Loss 0.7306 (0.7306)	Prec@1 70.500 (70.500)
 * Testing Prec@1 70.810
Epoch: [8/80][0/250]	LR: 0.1	Time 0.154 (0.154)	Data 0.136 (0.136)	Loss 0.6246 (0.6246)	Prec@1 79.500 (79.500)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.019 (0.020)	Loss 0.5820 (0.5405)	Prec@1 80.500 (80.941)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.026 (0.028)	Data 0.019 (0.020)	Loss 0.4257 (0.5463)	Prec@1 87.000 (80.741)
 * Training Prec@1 80.746
Test: [0/50]	Time 0.124 (0.124)	Loss 0.9674 (0.9674)	Prec@1 71.000 (71.000)
 * Testing Prec@1 69.110
Epoch: [9/80][0/250]	LR: 0.1	Time 0.129 (0.129)	Data 0.114 (0.114)	Loss 0.4517 (0.4517)	Prec@1 83.500 (83.500)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.019 (0.021)	Loss 0.4273 (0.5071)	Prec@1 87.500 (82.371)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.020 (0.020)	Loss 0.5911 (0.5152)	Prec@1 81.500 (82.022)
 * Training Prec@1 81.884
Test: [0/50]	Time 0.076 (0.076)	Loss 0.8840 (0.8840)	Prec@1 69.500 (69.500)
 * Testing Prec@1 68.730
Epoch: [10/80][0/250]	LR: 0.1	Time 0.115 (0.115)	Data 0.101 (0.101)	Loss 0.4966 (0.4966)	Prec@1 85.000 (85.000)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.027 (0.027)	Data 0.021 (0.021)	Loss 0.5036 (0.4805)	Prec@1 85.000 (83.168)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.032 (0.028)	Data 0.024 (0.022)	Loss 0.5088 (0.4844)	Prec@1 79.500 (83.045)
 * Training Prec@1 82.926
Test: [0/50]	Time 0.157 (0.157)	Loss 0.9140 (0.9140)	Prec@1 69.500 (69.500)
 * Testing Prec@1 69.920
Epoch: [11/80][0/250]	LR: 0.1	Time 0.142 (0.142)	Data 0.124 (0.124)	Loss 0.4415 (0.4415)	Prec@1 87.500 (87.500)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.020 (0.021)	Loss 0.4513 (0.4413)	Prec@1 84.500 (84.411)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.019 (0.020)	Loss 0.5748 (0.4607)	Prec@1 83.000 (83.866)
 * Training Prec@1 83.682
Test: [0/50]	Time 0.126 (0.126)	Loss 1.0863 (1.0863)	Prec@1 63.000 (63.000)
 * Testing Prec@1 68.570
Epoch: [12/80][0/250]	LR: 0.1	Time 0.134 (0.134)	Data 0.120 (0.120)	Loss 0.4284 (0.4284)	Prec@1 84.000 (84.000)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.022 (0.022)	Loss 0.4986 (0.4291)	Prec@1 81.500 (85.045)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.020 (0.021)	Loss 0.3889 (0.4430)	Prec@1 87.500 (84.289)
 * Training Prec@1 84.274
Test: [0/50]	Time 0.074 (0.074)	Loss 0.9433 (0.9433)	Prec@1 67.500 (67.500)
 * Testing Prec@1 72.040
Epoch: [13/80][0/250]	LR: 0.1	Time 0.131 (0.131)	Data 0.113 (0.113)	Loss 0.4422 (0.4422)	Prec@1 85.000 (85.000)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.021 (0.022)	Loss 0.4358 (0.4075)	Prec@1 83.500 (85.505)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.021 (0.021)	Loss 0.3714 (0.4187)	Prec@1 89.000 (85.234)
 * Training Prec@1 85.138
Test: [0/50]	Time 0.073 (0.073)	Loss 0.6689 (0.6689)	Prec@1 80.500 (80.500)
 * Testing Prec@1 76.170
Epoch: [14/80][0/250]	LR: 0.1	Time 0.092 (0.092)	Data 0.074 (0.074)	Loss 0.3118 (0.3118)	Prec@1 91.000 (91.000)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.022 (0.021)	Loss 0.3513 (0.3876)	Prec@1 89.500 (86.554)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.026 (0.027)	Data 0.019 (0.021)	Loss 0.3855 (0.3995)	Prec@1 87.500 (86.112)
 * Training Prec@1 85.816
Test: [0/50]	Time 0.074 (0.074)	Loss 0.6309 (0.6309)	Prec@1 79.500 (79.500)
 * Testing Prec@1 74.600
Epoch: [15/80][0/250]	LR: 0.1	Time 0.136 (0.136)	Data 0.121 (0.121)	Loss 0.2952 (0.2952)	Prec@1 91.000 (91.000)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.028 (0.028)	Data 0.021 (0.022)	Loss 0.4224 (0.3654)	Prec@1 82.500 (87.564)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.029 (0.028)	Data 0.021 (0.021)	Loss 0.4932 (0.3800)	Prec@1 84.500 (86.806)
 * Training Prec@1 86.528
Test: [0/50]	Time 0.076 (0.076)	Loss 0.6517 (0.6517)	Prec@1 78.000 (78.000)
 * Testing Prec@1 75.660
Epoch: [16/80][0/250]	LR: 0.1	Time 0.145 (0.145)	Data 0.128 (0.128)	Loss 0.3928 (0.3928)	Prec@1 87.000 (87.000)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.026 (0.028)	Data 0.020 (0.021)	Loss 0.3144 (0.3467)	Prec@1 88.000 (88.054)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.034 (0.028)	Data 0.026 (0.021)	Loss 0.2815 (0.3623)	Prec@1 90.500 (87.398)
 * Training Prec@1 86.910
Test: [0/50]	Time 0.130 (0.130)	Loss 0.6438 (0.6438)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.590
Epoch: [17/80][0/250]	LR: 0.1	Time 0.131 (0.131)	Data 0.115 (0.115)	Loss 0.3596 (0.3596)	Prec@1 87.000 (87.000)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.020 (0.020)	Loss 0.3086 (0.3320)	Prec@1 89.000 (88.416)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.021 (0.020)	Loss 0.3719 (0.3483)	Prec@1 88.500 (87.784)
 * Training Prec@1 87.600
Test: [0/50]	Time 0.122 (0.122)	Loss 0.7829 (0.7829)	Prec@1 74.000 (74.000)
 * Testing Prec@1 74.200
Epoch: [18/80][0/250]	LR: 0.1	Time 0.131 (0.131)	Data 0.116 (0.116)	Loss 0.2663 (0.2663)	Prec@1 91.000 (91.000)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.029 (0.028)	Data 0.022 (0.021)	Loss 0.3261 (0.3157)	Prec@1 89.500 (88.965)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.034 (0.028)	Data 0.024 (0.020)	Loss 0.4290 (0.3276)	Prec@1 84.500 (88.480)
 * Training Prec@1 88.114
Test: [0/50]	Time 0.131 (0.131)	Loss 0.7319 (0.7319)	Prec@1 74.500 (74.500)
 * Testing Prec@1 73.510
Epoch: [19/80][0/250]	LR: 0.1	Time 0.122 (0.122)	Data 0.108 (0.108)	Loss 0.3660 (0.3660)	Prec@1 90.500 (90.500)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.026 (0.028)	Data 0.019 (0.021)	Loss 0.2804 (0.3101)	Prec@1 89.500 (89.074)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.020 (0.020)	Loss 0.3348 (0.3160)	Prec@1 87.500 (88.781)
 * Training Prec@1 88.616
Test: [0/50]	Time 0.124 (0.124)	Loss 0.6955 (0.6955)	Prec@1 75.500 (75.500)
 * Testing Prec@1 75.020
Epoch: [20/80][0/250]	LR: 0.1	Time 0.094 (0.094)	Data 0.077 (0.077)	Loss 0.2691 (0.2691)	Prec@1 91.500 (91.500)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.030 (0.028)	Data 0.020 (0.020)	Loss 0.3105 (0.2961)	Prec@1 90.500 (89.624)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.033 (0.029)	Data 0.024 (0.022)	Loss 0.3248 (0.3104)	Prec@1 87.500 (89.032)
 * Training Prec@1 88.770
Test: [0/50]	Time 0.107 (0.107)	Loss 0.7189 (0.7189)	Prec@1 77.000 (77.000)
 * Testing Prec@1 76.410
Epoch: [21/80][0/250]	LR: 0.1	Time 0.135 (0.135)	Data 0.120 (0.120)	Loss 0.3406 (0.3406)	Prec@1 89.000 (89.000)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.019 (0.021)	Loss 0.3157 (0.2935)	Prec@1 89.000 (89.624)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.020 (0.021)	Loss 0.2875 (0.3099)	Prec@1 90.000 (89.040)
 * Training Prec@1 88.866
Test: [0/50]	Time 0.126 (0.126)	Loss 0.6750 (0.6750)	Prec@1 78.000 (78.000)
 * Testing Prec@1 75.780
Epoch: [22/80][0/250]	LR: 0.1	Time 0.135 (0.135)	Data 0.116 (0.116)	Loss 0.2744 (0.2744)	Prec@1 91.500 (91.500)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.028 (0.028)	Data 0.020 (0.021)	Loss 0.2493 (0.2681)	Prec@1 88.500 (90.668)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.019 (0.021)	Loss 0.3492 (0.2846)	Prec@1 85.000 (89.881)
 * Training Prec@1 89.598
Test: [0/50]	Time 0.080 (0.080)	Loss 0.7320 (0.7320)	Prec@1 75.500 (75.500)
 * Testing Prec@1 75.010
Epoch: [23/80][0/250]	LR: 0.1	Time 0.135 (0.135)	Data 0.119 (0.119)	Loss 0.2830 (0.2830)	Prec@1 90.000 (90.000)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.020 (0.020)	Loss 0.3045 (0.2572)	Prec@1 88.000 (91.158)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.033 (0.028)	Data 0.024 (0.020)	Loss 0.4084 (0.2696)	Prec@1 84.500 (90.692)
 * Training Prec@1 90.496
Test: [0/50]	Time 0.105 (0.105)	Loss 0.8655 (0.8655)	Prec@1 74.500 (74.500)
 * Testing Prec@1 73.860
Epoch: [24/80][0/250]	LR: 0.1	Time 0.142 (0.142)	Data 0.124 (0.124)	Loss 0.1927 (0.1927)	Prec@1 95.000 (95.000)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.027 (0.029)	Data 0.020 (0.021)	Loss 0.2889 (0.2402)	Prec@1 92.000 (91.673)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.034 (0.028)	Data 0.025 (0.021)	Loss 0.3195 (0.2580)	Prec@1 89.000 (90.863)
 * Training Prec@1 90.688
Test: [0/50]	Time 0.146 (0.146)	Loss 0.6043 (0.6043)	Prec@1 79.500 (79.500)
 * Testing Prec@1 77.210
Epoch: [25/80][0/250]	LR: 0.1	Time 0.139 (0.139)	Data 0.120 (0.120)	Loss 0.2346 (0.2346)	Prec@1 93.000 (93.000)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.027 (0.029)	Data 0.020 (0.021)	Loss 0.2571 (0.2276)	Prec@1 90.500 (92.104)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.029 (0.028)	Data 0.022 (0.020)	Loss 0.3077 (0.2478)	Prec@1 89.500 (91.323)
 * Training Prec@1 90.862
Test: [0/50]	Time 0.075 (0.075)	Loss 0.7028 (0.7028)	Prec@1 76.000 (76.000)
 * Testing Prec@1 75.470
Epoch: [26/80][0/250]	LR: 0.1	Time 0.120 (0.120)	Data 0.104 (0.104)	Loss 0.2307 (0.2307)	Prec@1 92.500 (92.500)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.028 (0.028)	Data 0.021 (0.022)	Loss 0.1878 (0.2218)	Prec@1 93.000 (92.287)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.028 (0.028)	Data 0.021 (0.021)	Loss 0.2228 (0.2418)	Prec@1 91.000 (91.522)
 * Training Prec@1 91.098
Test: [0/50]	Time 0.070 (0.070)	Loss 0.7477 (0.7477)	Prec@1 74.500 (74.500)
 * Testing Prec@1 75.010
Epoch: [27/80][0/250]	LR: 0.1	Time 0.122 (0.122)	Data 0.102 (0.102)	Loss 0.2019 (0.2019)	Prec@1 93.000 (93.000)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.027 (0.029)	Data 0.021 (0.022)	Loss 0.2987 (0.2276)	Prec@1 89.500 (91.916)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.028 (0.029)	Data 0.020 (0.022)	Loss 0.2994 (0.2400)	Prec@1 91.000 (91.465)
 * Training Prec@1 91.226
Test: [0/50]	Time 0.104 (0.104)	Loss 0.8500 (0.8500)	Prec@1 75.000 (75.000)
 * Testing Prec@1 73.950
Epoch: [28/80][0/250]	LR: 0.1	Time 0.136 (0.136)	Data 0.116 (0.116)	Loss 0.2531 (0.2531)	Prec@1 90.500 (90.500)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.032 (0.030)	Data 0.025 (0.022)	Loss 0.1197 (0.2050)	Prec@1 96.000 (92.802)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.032 (0.031)	Data 0.023 (0.023)	Loss 0.2105 (0.2245)	Prec@1 93.000 (92.020)
 * Training Prec@1 91.878
Test: [0/50]	Time 0.108 (0.108)	Loss 0.7564 (0.7564)	Prec@1 74.500 (74.500)
 * Testing Prec@1 75.080
Epoch: [29/80][0/250]	LR: 0.1	Time 0.135 (0.135)	Data 0.116 (0.116)	Loss 0.2355 (0.2355)	Prec@1 93.500 (93.500)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.020 (0.021)	Loss 0.1794 (0.1924)	Prec@1 92.000 (93.683)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.019 (0.020)	Loss 0.2923 (0.2144)	Prec@1 88.000 (92.682)
 * Training Prec@1 92.400
Test: [0/50]	Time 0.126 (0.126)	Loss 0.7544 (0.7544)	Prec@1 76.000 (76.000)
 * Testing Prec@1 75.250
Epoch: [30/80][0/250]	LR: 0.1	Time 0.124 (0.124)	Data 0.110 (0.110)	Loss 0.1889 (0.1889)	Prec@1 94.000 (94.000)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.018 (0.021)	Loss 0.1705 (0.1994)	Prec@1 95.000 (93.257)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.019 (0.020)	Loss 0.3644 (0.2141)	Prec@1 86.500 (92.602)
 * Training Prec@1 92.322
Test: [0/50]	Time 0.075 (0.075)	Loss 0.8250 (0.8250)	Prec@1 76.500 (76.500)
 * Testing Prec@1 72.450
Epoch: [31/80][0/250]	LR: 0.1	Time 0.127 (0.127)	Data 0.112 (0.112)	Loss 0.2854 (0.2854)	Prec@1 91.000 (91.000)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.022 (0.022)	Loss 0.1917 (0.1881)	Prec@1 92.500 (93.653)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.020 (0.021)	Loss 0.2934 (0.2095)	Prec@1 89.500 (92.716)
 * Training Prec@1 92.338
Test: [0/50]	Time 0.123 (0.123)	Loss 0.6358 (0.6358)	Prec@1 82.000 (82.000)
 * Testing Prec@1 75.820
Epoch: [32/80][0/250]	LR: 0.1	Time 0.144 (0.144)	Data 0.124 (0.124)	Loss 0.1635 (0.1635)	Prec@1 95.500 (95.500)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.020 (0.021)	Loss 0.1935 (0.1848)	Prec@1 93.500 (93.658)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.031 (0.030)	Data 0.025 (0.022)	Loss 0.1994 (0.1972)	Prec@1 93.000 (93.052)
 * Training Prec@1 92.708
Test: [0/50]	Time 0.105 (0.105)	Loss 1.2530 (1.2530)	Prec@1 68.000 (68.000)
 * Testing Prec@1 67.170
Epoch: [33/80][0/250]	LR: 0.1	Time 0.143 (0.143)	Data 0.125 (0.125)	Loss 0.1991 (0.1991)	Prec@1 93.500 (93.500)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.019 (0.020)	Loss 0.1845 (0.1890)	Prec@1 94.000 (93.564)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.020 (0.020)	Loss 0.1737 (0.1976)	Prec@1 95.500 (93.102)
 * Training Prec@1 92.754
Test: [0/50]	Time 0.122 (0.122)	Loss 0.6610 (0.6610)	Prec@1 78.500 (78.500)
 * Testing Prec@1 77.940
Epoch: [34/80][0/250]	LR: 0.1	Time 0.119 (0.119)	Data 0.098 (0.098)	Loss 0.1544 (0.1544)	Prec@1 95.000 (95.000)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.030 (0.028)	Data 0.022 (0.021)	Loss 0.2314 (0.1686)	Prec@1 91.000 (94.391)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.019 (0.020)	Loss 0.2202 (0.1876)	Prec@1 91.000 (93.505)
 * Training Prec@1 93.142
Test: [0/50]	Time 0.075 (0.075)	Loss 0.7886 (0.7886)	Prec@1 79.500 (79.500)
 * Testing Prec@1 75.050
Epoch: [35/80][0/250]	LR: 0.1	Time 0.141 (0.141)	Data 0.122 (0.122)	Loss 0.1545 (0.1545)	Prec@1 96.000 (96.000)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.028 (0.028)	Data 0.021 (0.021)	Loss 0.1637 (0.1660)	Prec@1 92.500 (94.277)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.026 (0.028)	Data 0.019 (0.021)	Loss 0.1635 (0.1888)	Prec@1 95.000 (93.400)
 * Training Prec@1 93.022
Test: [0/50]	Time 0.074 (0.074)	Loss 0.6613 (0.6613)	Prec@1 80.000 (80.000)
 * Testing Prec@1 75.630
Epoch: [36/80][0/250]	LR: 0.1	Time 0.125 (0.125)	Data 0.112 (0.112)	Loss 0.2146 (0.2146)	Prec@1 92.500 (92.500)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.035 (0.033)	Data 0.028 (0.026)	Loss 0.1973 (0.1636)	Prec@1 92.500 (94.663)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.027 (0.032)	Data 0.020 (0.025)	Loss 0.1405 (0.1782)	Prec@1 96.000 (93.896)
 * Training Prec@1 93.632
Test: [0/50]	Time 0.107 (0.107)	Loss 0.8180 (0.8180)	Prec@1 77.000 (77.000)
 * Testing Prec@1 74.390
Epoch: [37/80][0/250]	LR: 0.1	Time 0.119 (0.119)	Data 0.106 (0.106)	Loss 0.1786 (0.1786)	Prec@1 94.000 (94.000)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.025 (0.028)	Data 0.017 (0.021)	Loss 0.1825 (0.1709)	Prec@1 92.000 (94.213)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.029 (0.027)	Data 0.021 (0.020)	Loss 0.1971 (0.1854)	Prec@1 92.000 (93.517)
 * Training Prec@1 93.366
Test: [0/50]	Time 0.076 (0.076)	Loss 0.7800 (0.7800)	Prec@1 74.500 (74.500)
 * Testing Prec@1 74.440
Epoch: [38/80][0/250]	LR: 0.1	Time 0.137 (0.137)	Data 0.118 (0.118)	Loss 0.2358 (0.2358)	Prec@1 92.500 (92.500)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.021 (0.021)	Loss 0.2392 (0.1623)	Prec@1 91.500 (94.446)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.027 (0.027)	Data 0.023 (0.022)	Loss 0.2147 (0.1764)	Prec@1 90.500 (93.861)
 * Training Prec@1 93.662
Test: [0/50]	Time 0.072 (0.072)	Loss 0.6690 (0.6690)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.880
Epoch: [39/80][0/250]	LR: 0.1	Time 0.130 (0.130)	Data 0.115 (0.115)	Loss 0.2230 (0.2230)	Prec@1 93.000 (93.000)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.026 (0.028)	Data 0.020 (0.022)	Loss 0.1337 (0.1504)	Prec@1 95.500 (94.906)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.028 (0.027)	Data 0.021 (0.021)	Loss 0.1993 (0.1696)	Prec@1 93.500 (94.092)
 * Training Prec@1 93.816
Test: [0/50]	Time 0.127 (0.127)	Loss 1.0776 (1.0776)	Prec@1 73.500 (73.500)
 * Testing Prec@1 71.400
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.137 (0.137)	Data 0.119 (0.119)	Loss 0.1305 (0.1305)	Prec@1 95.000 (95.000)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.030 (0.034)	Data 0.023 (0.026)	Loss 0.0737 (0.1132)	Prec@1 99.000 (96.733)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.034)	Data 0.027 (0.025)	Loss 0.0732 (0.0962)	Prec@1 98.000 (97.505)
 * Training Prec@1 97.674
Test: [0/50]	Time 0.086 (0.086)	Loss 0.5771 (0.5771)	Prec@1 82.500 (82.500)
 * Testing Prec@1 80.180
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.088 (0.088)	Data 0.070 (0.070)	Loss 0.0512 (0.0512)	Prec@1 99.000 (99.000)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.021 (0.021)	Loss 0.0683 (0.0638)	Prec@1 98.000 (98.921)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.026 (0.028)	Data 0.018 (0.020)	Loss 0.0636 (0.0621)	Prec@1 99.000 (98.978)
 * Training Prec@1 98.984
Test: [0/50]	Time 0.125 (0.125)	Loss 0.5722 (0.5722)	Prec@1 83.500 (83.500)
 * Testing Prec@1 80.240
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.136 (0.136)	Data 0.117 (0.117)	Loss 0.0866 (0.0866)	Prec@1 98.500 (98.500)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.022 (0.022)	Loss 0.0583 (0.0543)	Prec@1 99.500 (99.228)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.022 (0.022)	Loss 0.0688 (0.0548)	Prec@1 99.000 (99.221)
 * Training Prec@1 99.258
Test: [0/50]	Time 0.072 (0.072)	Loss 0.5798 (0.5798)	Prec@1 83.500 (83.500)
 * Testing Prec@1 80.280
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.127 (0.127)	Data 0.111 (0.111)	Loss 0.0443 (0.0443)	Prec@1 99.500 (99.500)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.029 (0.028)	Data 0.021 (0.022)	Loss 0.0363 (0.0471)	Prec@1 100.000 (99.500)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.026 (0.027)	Data 0.021 (0.022)	Loss 0.0368 (0.0491)	Prec@1 100.000 (99.433)
 * Training Prec@1 99.424
Test: [0/50]	Time 0.076 (0.076)	Loss 0.5912 (0.5912)	Prec@1 82.500 (82.500)
 * Testing Prec@1 80.190
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.137 (0.137)	Data 0.118 (0.118)	Loss 0.0414 (0.0414)	Prec@1 99.500 (99.500)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.019 (0.020)	Loss 0.0694 (0.0435)	Prec@1 98.000 (99.639)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.018 (0.020)	Loss 0.0472 (0.0442)	Prec@1 99.500 (99.570)
 * Training Prec@1 99.574
Test: [0/50]	Time 0.123 (0.123)	Loss 0.6005 (0.6005)	Prec@1 83.500 (83.500)
 * Testing Prec@1 80.170
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.139 (0.139)	Data 0.122 (0.122)	Loss 0.0407 (0.0407)	Prec@1 99.500 (99.500)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.026 (0.028)	Data 0.019 (0.020)	Loss 0.0413 (0.0412)	Prec@1 99.000 (99.589)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.020 (0.020)	Loss 0.0271 (0.0416)	Prec@1 100.000 (99.582)
 * Training Prec@1 99.574
Test: [0/50]	Time 0.128 (0.128)	Loss 0.6191 (0.6191)	Prec@1 83.000 (83.000)
 * Testing Prec@1 80.280
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.138 (0.138)	Data 0.120 (0.120)	Loss 0.0272 (0.0272)	Prec@1 100.000 (100.000)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.028 (0.028)	Data 0.021 (0.021)	Loss 0.0378 (0.0380)	Prec@1 99.500 (99.748)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.026 (0.028)	Data 0.019 (0.020)	Loss 0.0397 (0.0390)	Prec@1 99.500 (99.706)
 * Training Prec@1 99.692
Test: [0/50]	Time 0.124 (0.124)	Loss 0.6345 (0.6345)	Prec@1 82.500 (82.500)
 * Testing Prec@1 80.110
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 0.130 (0.130)	Data 0.113 (0.113)	Loss 0.0284 (0.0284)	Prec@1 100.000 (100.000)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.029 (0.030)	Data 0.022 (0.023)	Loss 0.0544 (0.0373)	Prec@1 99.000 (99.723)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.026 (0.030)	Data 0.020 (0.023)	Loss 0.0519 (0.0377)	Prec@1 99.500 (99.726)
 * Training Prec@1 99.712
Test: [0/50]	Time 0.104 (0.104)	Loss 0.6314 (0.6314)	Prec@1 83.500 (83.500)
 * Testing Prec@1 80.330
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.164 (0.164)	Data 0.146 (0.146)	Loss 0.0404 (0.0404)	Prec@1 99.500 (99.500)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.028 (0.032)	Data 0.022 (0.024)	Loss 0.0347 (0.0359)	Prec@1 100.000 (99.772)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.030)	Data 0.020 (0.022)	Loss 0.0269 (0.0357)	Prec@1 100.000 (99.771)
 * Training Prec@1 99.774
Test: [0/50]	Time 0.083 (0.083)	Loss 0.6493 (0.6493)	Prec@1 83.500 (83.500)
 * Testing Prec@1 80.070
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.126 (0.126)	Data 0.110 (0.110)	Loss 0.0243 (0.0243)	Prec@1 100.000 (100.000)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.028 (0.029)	Data 0.021 (0.021)	Loss 0.0316 (0.0348)	Prec@1 100.000 (99.827)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.032 (0.029)	Data 0.023 (0.021)	Loss 0.0344 (0.0341)	Prec@1 99.500 (99.813)
 * Training Prec@1 99.806
Test: [0/50]	Time 0.122 (0.122)	Loss 0.6436 (0.6436)	Prec@1 82.000 (82.000)
 * Testing Prec@1 80.230
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.143 (0.143)	Data 0.124 (0.124)	Loss 0.0307 (0.0307)	Prec@1 100.000 (100.000)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.028 (0.029)	Data 0.023 (0.022)	Loss 0.0330 (0.0308)	Prec@1 100.000 (99.891)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.020 (0.021)	Loss 0.0346 (0.0317)	Prec@1 100.000 (99.856)
 * Training Prec@1 99.838
Test: [0/50]	Time 0.127 (0.127)	Loss 0.6582 (0.6582)	Prec@1 83.000 (83.000)
 * Testing Prec@1 80.040
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 0.116 (0.116)	Data 0.102 (0.102)	Loss 0.0281 (0.0281)	Prec@1 99.500 (99.500)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.028 (0.028)	Data 0.022 (0.023)	Loss 0.0382 (0.0313)	Prec@1 99.500 (99.817)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.028 (0.028)	Data 0.022 (0.023)	Loss 0.0260 (0.0318)	Prec@1 100.000 (99.816)
 * Training Prec@1 99.824
Test: [0/50]	Time 0.073 (0.073)	Loss 0.6687 (0.6687)	Prec@1 84.500 (84.500)
 * Testing Prec@1 80.070
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.134 (0.134)	Data 0.116 (0.116)	Loss 0.0261 (0.0261)	Prec@1 100.000 (100.000)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.026 (0.028)	Data 0.020 (0.021)	Loss 0.0275 (0.0305)	Prec@1 100.000 (99.847)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.033 (0.028)	Data 0.026 (0.021)	Loss 0.0276 (0.0309)	Prec@1 100.000 (99.848)
 * Training Prec@1 99.840
Test: [0/50]	Time 0.123 (0.123)	Loss 0.6639 (0.6639)	Prec@1 84.000 (84.000)
 * Testing Prec@1 79.910
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 0.121 (0.121)	Data 0.105 (0.105)	Loss 0.0244 (0.0244)	Prec@1 100.000 (100.000)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.026 (0.028)	Data 0.020 (0.021)	Loss 0.0354 (0.0284)	Prec@1 100.000 (99.881)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.028 (0.027)	Data 0.022 (0.021)	Loss 0.0364 (0.0291)	Prec@1 100.000 (99.891)
 * Training Prec@1 99.872
Test: [0/50]	Time 0.130 (0.130)	Loss 0.6764 (0.6764)	Prec@1 83.000 (83.000)
 * Testing Prec@1 80.150
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.132 (0.132)	Data 0.116 (0.116)	Loss 0.0257 (0.0257)	Prec@1 100.000 (100.000)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.022 (0.022)	Loss 0.0221 (0.0284)	Prec@1 100.000 (99.901)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.021 (0.022)	Loss 0.0340 (0.0280)	Prec@1 99.000 (99.898)
 * Training Prec@1 99.878
Test: [0/50]	Time 0.070 (0.070)	Loss 0.6830 (0.6830)	Prec@1 81.500 (81.500)
 * Testing Prec@1 79.920
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.117 (0.117)	Data 0.103 (0.103)	Loss 0.0272 (0.0272)	Prec@1 100.000 (100.000)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.026 (0.028)	Data 0.019 (0.021)	Loss 0.0288 (0.0278)	Prec@1 100.000 (99.911)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.028 (0.028)	Data 0.019 (0.020)	Loss 0.0376 (0.0274)	Prec@1 99.500 (99.910)
 * Training Prec@1 99.912
Test: [0/50]	Time 0.127 (0.127)	Loss 0.6780 (0.6780)	Prec@1 84.000 (84.000)
 * Testing Prec@1 79.880
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.137 (0.137)	Data 0.116 (0.116)	Loss 0.0177 (0.0177)	Prec@1 100.000 (100.000)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.020 (0.020)	Loss 0.0339 (0.0269)	Prec@1 100.000 (99.891)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.031 (0.030)	Data 0.025 (0.022)	Loss 0.0222 (0.0272)	Prec@1 100.000 (99.888)
 * Training Prec@1 99.888
Test: [0/50]	Time 0.150 (0.150)	Loss 0.6941 (0.6941)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.810
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.143 (0.143)	Data 0.123 (0.123)	Loss 0.0243 (0.0243)	Prec@1 100.000 (100.000)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.029 (0.028)	Data 0.022 (0.020)	Loss 0.0249 (0.0257)	Prec@1 100.000 (99.921)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.020 (0.020)	Loss 0.0304 (0.0263)	Prec@1 99.500 (99.896)
 * Training Prec@1 99.904
Test: [0/50]	Time 0.075 (0.075)	Loss 0.7033 (0.7033)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.810
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.129 (0.129)	Data 0.115 (0.115)	Loss 0.0265 (0.0265)	Prec@1 100.000 (100.000)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.022 (0.022)	Loss 0.0250 (0.0250)	Prec@1 100.000 (99.946)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.022 (0.022)	Loss 0.0263 (0.0255)	Prec@1 100.000 (99.948)
 * Training Prec@1 99.936
Test: [0/50]	Time 0.128 (0.128)	Loss 0.7069 (0.7069)	Prec@1 82.500 (82.500)
 * Testing Prec@1 79.820
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.139 (0.139)	Data 0.121 (0.121)	Loss 0.0232 (0.0232)	Prec@1 99.500 (99.500)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.020 (0.020)	Loss 0.0266 (0.0244)	Prec@1 100.000 (99.906)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.028)	Data 0.019 (0.020)	Loss 0.0234 (0.0244)	Prec@1 100.000 (99.920)
 * Training Prec@1 99.914
Test: [0/50]	Time 0.122 (0.122)	Loss 0.7072 (0.7072)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.890
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.164 (0.164)	Data 0.146 (0.146)	Loss 0.0196 (0.0196)	Prec@1 100.000 (100.000)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.026 (0.030)	Data 0.019 (0.022)	Loss 0.0231 (0.0234)	Prec@1 100.000 (99.955)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.028)	Data 0.020 (0.021)	Loss 0.0229 (0.0229)	Prec@1 100.000 (99.955)
 * Training Prec@1 99.956
Test: [0/50]	Time 0.075 (0.075)	Loss 0.7124 (0.7124)	Prec@1 83.500 (83.500)
 * Testing Prec@1 79.950
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.137 (0.137)	Data 0.121 (0.121)	Loss 0.0174 (0.0174)	Prec@1 100.000 (100.000)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.029)	Data 0.020 (0.021)	Loss 0.0242 (0.0229)	Prec@1 100.000 (99.946)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.031 (0.028)	Data 0.022 (0.021)	Loss 0.0180 (0.0225)	Prec@1 100.000 (99.948)
 * Training Prec@1 99.944
Test: [0/50]	Time 0.078 (0.078)	Loss 0.7096 (0.7096)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.800
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.123 (0.123)	Data 0.106 (0.106)	Loss 0.0248 (0.0248)	Prec@1 100.000 (100.000)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.027 (0.028)	Data 0.022 (0.022)	Loss 0.0232 (0.0223)	Prec@1 99.500 (99.955)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.026 (0.028)	Data 0.017 (0.021)	Loss 0.0249 (0.0225)	Prec@1 100.000 (99.953)
 * Training Prec@1 99.950
Test: [0/50]	Time 0.124 (0.124)	Loss 0.7052 (0.7052)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.940
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 0.165 (0.165)	Data 0.146 (0.146)	Loss 0.0202 (0.0202)	Prec@1 100.000 (100.000)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.027 (0.030)	Data 0.019 (0.022)	Loss 0.0193 (0.0221)	Prec@1 100.000 (99.965)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.028 (0.029)	Data 0.023 (0.022)	Loss 0.0229 (0.0223)	Prec@1 100.000 (99.950)
 * Training Prec@1 99.952
Test: [0/50]	Time 0.071 (0.071)	Loss 0.6992 (0.6992)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.850
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 0.119 (0.119)	Data 0.104 (0.104)	Loss 0.0208 (0.0208)	Prec@1 100.000 (100.000)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.029)	Data 0.022 (0.022)	Loss 0.0156 (0.0220)	Prec@1 100.000 (99.955)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.031 (0.029)	Data 0.024 (0.022)	Loss 0.0212 (0.0222)	Prec@1 100.000 (99.950)
 * Training Prec@1 99.952
Test: [0/50]	Time 0.077 (0.077)	Loss 0.7047 (0.7047)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.860
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.124 (0.124)	Data 0.109 (0.109)	Loss 0.0281 (0.0281)	Prec@1 100.000 (100.000)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.030)	Data 0.020 (0.022)	Loss 0.0178 (0.0230)	Prec@1 100.000 (99.950)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.029)	Data 0.021 (0.021)	Loss 0.0172 (0.0226)	Prec@1 100.000 (99.958)
 * Training Prec@1 99.962
Test: [0/50]	Time 0.077 (0.077)	Loss 0.7115 (0.7115)	Prec@1 82.500 (82.500)
 * Testing Prec@1 79.720
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 0.146 (0.146)	Data 0.127 (0.127)	Loss 0.0261 (0.0261)	Prec@1 99.500 (99.500)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.027 (0.029)	Data 0.021 (0.022)	Loss 0.0370 (0.0226)	Prec@1 99.500 (99.960)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.030 (0.028)	Data 0.022 (0.022)	Loss 0.0243 (0.0223)	Prec@1 100.000 (99.960)
 * Training Prec@1 99.956
Test: [0/50]	Time 0.072 (0.072)	Loss 0.7118 (0.7118)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.900
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.124 (0.124)	Data 0.109 (0.109)	Loss 0.0202 (0.0202)	Prec@1 100.000 (100.000)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.027 (0.032)	Data 0.021 (0.025)	Loss 0.0209 (0.0224)	Prec@1 100.000 (99.941)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.028 (0.030)	Data 0.020 (0.023)	Loss 0.0245 (0.0225)	Prec@1 99.500 (99.930)
 * Training Prec@1 99.940
Test: [0/50]	Time 0.156 (0.156)	Loss 0.7123 (0.7123)	Prec@1 83.500 (83.500)
 * Testing Prec@1 79.870
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.135 (0.135)	Data 0.115 (0.115)	Loss 0.0173 (0.0173)	Prec@1 100.000 (100.000)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.029)	Data 0.021 (0.021)	Loss 0.0217 (0.0219)	Prec@1 99.500 (99.941)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.030 (0.029)	Data 0.022 (0.021)	Loss 0.0231 (0.0218)	Prec@1 100.000 (99.948)
 * Training Prec@1 99.954
Test: [0/50]	Time 0.128 (0.128)	Loss 0.7068 (0.7068)	Prec@1 84.000 (84.000)
 * Testing Prec@1 79.920
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 0.138 (0.138)	Data 0.118 (0.118)	Loss 0.0169 (0.0169)	Prec@1 100.000 (100.000)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.029)	Data 0.022 (0.022)	Loss 0.0182 (0.0219)	Prec@1 100.000 (99.980)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.029)	Data 0.021 (0.022)	Loss 0.0212 (0.0224)	Prec@1 100.000 (99.950)
 * Training Prec@1 99.960
Test: [0/50]	Time 0.128 (0.128)	Loss 0.7110 (0.7110)	Prec@1 83.500 (83.500)
 * Testing Prec@1 79.910
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.134 (0.134)	Data 0.119 (0.119)	Loss 0.0254 (0.0254)	Prec@1 100.000 (100.000)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.029)	Data 0.020 (0.021)	Loss 0.0247 (0.0218)	Prec@1 100.000 (99.950)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.032 (0.031)	Data 0.024 (0.022)	Loss 0.0334 (0.0224)	Prec@1 100.000 (99.935)
 * Training Prec@1 99.938
Test: [0/50]	Time 0.159 (0.159)	Loss 0.7207 (0.7207)	Prec@1 82.500 (82.500)
 * Testing Prec@1 79.610
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.137 (0.137)	Data 0.119 (0.119)	Loss 0.0180 (0.0180)	Prec@1 100.000 (100.000)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.029)	Data 0.021 (0.021)	Loss 0.0264 (0.0210)	Prec@1 100.000 (99.965)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.029)	Data 0.020 (0.021)	Loss 0.0207 (0.0214)	Prec@1 100.000 (99.960)
 * Training Prec@1 99.956
Test: [0/50]	Time 0.072 (0.072)	Loss 0.7200 (0.7200)	Prec@1 82.500 (82.500)
 * Testing Prec@1 79.770
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.139 (0.139)	Data 0.120 (0.120)	Loss 0.0226 (0.0226)	Prec@1 100.000 (100.000)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.030)	Data 0.020 (0.022)	Loss 0.0372 (0.0213)	Prec@1 99.500 (99.960)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.029)	Data 0.019 (0.021)	Loss 0.0221 (0.0214)	Prec@1 100.000 (99.958)
 * Training Prec@1 99.962
Test: [0/50]	Time 0.130 (0.130)	Loss 0.7108 (0.7108)	Prec@1 82.500 (82.500)
 * Testing Prec@1 79.890
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 0.142 (0.142)	Data 0.123 (0.123)	Loss 0.0170 (0.0170)	Prec@1 100.000 (100.000)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.029)	Data 0.022 (0.022)	Loss 0.0285 (0.0212)	Prec@1 100.000 (99.980)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.028)	Data 0.020 (0.021)	Loss 0.0182 (0.0221)	Prec@1 99.500 (99.945)
 * Training Prec@1 99.954
Test: [0/50]	Time 0.132 (0.132)	Loss 0.7180 (0.7180)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.830
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.135 (0.135)	Data 0.117 (0.117)	Loss 0.0215 (0.0215)	Prec@1 100.000 (100.000)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.027 (0.030)	Data 0.020 (0.022)	Loss 0.0180 (0.0223)	Prec@1 100.000 (99.960)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.029)	Data 0.021 (0.021)	Loss 0.0212 (0.0220)	Prec@1 100.000 (99.963)
 * Training Prec@1 99.966
Test: [0/50]	Time 0.103 (0.103)	Loss 0.7154 (0.7154)	Prec@1 82.500 (82.500)
 * Testing Prec@1 79.780
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.135 (0.135)	Data 0.120 (0.120)	Loss 0.0191 (0.0191)	Prec@1 100.000 (100.000)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.027 (0.029)	Data 0.020 (0.021)	Loss 0.0147 (0.0215)	Prec@1 100.000 (99.941)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.028 (0.029)	Data 0.021 (0.021)	Loss 0.0264 (0.0221)	Prec@1 100.000 (99.938)
 * Training Prec@1 99.942
Test: [0/50]	Time 0.075 (0.075)	Loss 0.7146 (0.7146)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.860
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.123 (0.123)	Data 0.108 (0.108)	Loss 0.0240 (0.0240)	Prec@1 100.000 (100.000)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.029)	Data 0.022 (0.022)	Loss 0.0307 (0.0214)	Prec@1 99.500 (99.975)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.028)	Data 0.021 (0.022)	Loss 0.0184 (0.0219)	Prec@1 100.000 (99.968)
 * Training Prec@1 99.968
Test: [0/50]	Time 0.072 (0.072)	Loss 0.7079 (0.7079)	Prec@1 83.500 (83.500)
 * Testing Prec@1 79.830
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 0.133 (0.133)	Data 0.116 (0.116)	Loss 0.0264 (0.0264)	Prec@1 100.000 (100.000)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.029)	Data 0.021 (0.023)	Loss 0.0288 (0.0215)	Prec@1 100.000 (99.975)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.028 (0.029)	Data 0.020 (0.023)	Loss 0.0268 (0.0216)	Prec@1 99.500 (99.963)
 * Training Prec@1 99.966
Test: [0/50]	Time 0.107 (0.107)	Loss 0.7177 (0.7177)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.780
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.118 (0.118)	Data 0.104 (0.104)	Loss 0.0183 (0.0183)	Prec@1 100.000 (100.000)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.029)	Data 0.023 (0.022)	Loss 0.0254 (0.0216)	Prec@1 100.000 (99.975)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.028 (0.028)	Data 0.020 (0.022)	Loss 0.0293 (0.0216)	Prec@1 100.000 (99.950)
 * Training Prec@1 99.956
Test: [0/50]	Time 0.146 (0.146)	Loss 0.7127 (0.7127)	Prec@1 83.500 (83.500)
 * Testing Prec@1 79.900
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.141 (0.141)	Data 0.122 (0.122)	Loss 0.0144 (0.0144)	Prec@1 100.000 (100.000)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.031 (0.028)	Data 0.022 (0.021)	Loss 0.0246 (0.0214)	Prec@1 100.000 (99.970)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.028)	Data 0.020 (0.020)	Loss 0.0178 (0.0213)	Prec@1 100.000 (99.968)
 * Training Prec@1 99.962
Test: [0/50]	Time 0.131 (0.131)	Loss 0.7235 (0.7235)	Prec@1 82.500 (82.500)
 * Testing Prec@1 79.770
