Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'plainnet8'
Epoch: [0/80][0/250]	LR: 0.1	Time 0.560 (0.560)	Data 0.157 (0.157)	Loss 2.3055 (2.3055)	Prec@1 14.000 (14.000)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.035 (0.043)	Data 0.026 (0.030)	Loss 1.5877 (1.8524)	Prec@1 36.000 (29.564)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.037 (0.040)	Data 0.027 (0.029)	Loss 1.5050 (1.7135)	Prec@1 41.000 (35.206)
 * Training Prec@1 37.600
main.py:207: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.120 (0.120)	Loss 1.4931 (1.4931)	Prec@1 47.500 (47.500)
 * Testing Prec@1 42.610
main.py:244: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:245: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:253: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 0.235 (0.235)	Data 0.216 (0.216)	Loss 1.3406 (1.3406)	Prec@1 52.000 (52.000)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.037 (0.040)	Data 0.028 (0.030)	Loss 1.1767 (1.3230)	Prec@1 59.000 (51.876)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.026 (0.029)	Loss 1.1974 (1.2568)	Prec@1 57.000 (54.398)
 * Training Prec@1 55.460
Test: [0/50]	Time 0.125 (0.125)	Loss 1.6216 (1.6216)	Prec@1 53.000 (53.000)
 * Testing Prec@1 47.290
Epoch: [2/80][0/250]	LR: 0.1	Time 0.130 (0.130)	Data 0.113 (0.113)	Loss 1.0763 (1.0763)	Prec@1 60.500 (60.500)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.035 (0.039)	Data 0.027 (0.030)	Loss 0.9034 (1.0464)	Prec@1 69.000 (62.223)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.036 (0.040)	Data 0.027 (0.031)	Loss 1.0138 (1.0295)	Prec@1 64.000 (63.030)
 * Training Prec@1 63.570
Test: [0/50]	Time 0.140 (0.140)	Loss 1.3648 (1.3648)	Prec@1 54.500 (54.500)
 * Testing Prec@1 52.300
Epoch: [3/80][0/250]	LR: 0.1	Time 0.213 (0.213)	Data 0.197 (0.197)	Loss 0.9505 (0.9505)	Prec@1 66.000 (66.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.036 (0.040)	Data 0.027 (0.031)	Loss 0.9305 (0.9253)	Prec@1 68.000 (67.173)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.026 (0.029)	Loss 0.9193 (0.9076)	Prec@1 68.000 (67.878)
 * Training Prec@1 68.098
Test: [0/50]	Time 0.156 (0.156)	Loss 0.9386 (0.9386)	Prec@1 68.000 (68.000)
 * Testing Prec@1 64.170
Epoch: [4/80][0/250]	LR: 0.1	Time 0.209 (0.209)	Data 0.191 (0.191)	Loss 0.7397 (0.7397)	Prec@1 72.000 (72.000)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.027 (0.029)	Loss 0.8761 (0.8347)	Prec@1 68.000 (69.985)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.028 (0.030)	Loss 0.8918 (0.8294)	Prec@1 69.000 (70.415)
 * Training Prec@1 70.742
Test: [0/50]	Time 0.145 (0.145)	Loss 0.8766 (0.8766)	Prec@1 66.000 (66.000)
 * Testing Prec@1 69.810
Epoch: [5/80][0/250]	LR: 0.1	Time 0.238 (0.238)	Data 0.219 (0.219)	Loss 0.6839 (0.6839)	Prec@1 74.500 (74.500)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.036 (0.043)	Data 0.026 (0.033)	Loss 0.8349 (0.7656)	Prec@1 73.000 (73.238)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.035 (0.039)	Data 0.026 (0.030)	Loss 0.7793 (0.7606)	Prec@1 70.000 (73.490)
 * Training Prec@1 73.532
Test: [0/50]	Time 0.141 (0.141)	Loss 0.8203 (0.8203)	Prec@1 69.500 (69.500)
 * Testing Prec@1 71.810
Epoch: [6/80][0/250]	LR: 0.1	Time 0.239 (0.239)	Data 0.221 (0.221)	Loss 0.7808 (0.7808)	Prec@1 72.000 (72.000)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.038 (0.039)	Data 0.027 (0.030)	Loss 0.7739 (0.7239)	Prec@1 74.000 (74.644)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.026 (0.029)	Loss 0.7000 (0.7147)	Prec@1 75.500 (75.062)
 * Training Prec@1 75.090
Test: [0/50]	Time 0.148 (0.148)	Loss 0.9526 (0.9526)	Prec@1 67.500 (67.500)
 * Testing Prec@1 67.970
Epoch: [7/80][0/250]	LR: 0.1	Time 0.213 (0.213)	Data 0.196 (0.196)	Loss 0.7136 (0.7136)	Prec@1 76.000 (76.000)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.054 (0.049)	Data 0.045 (0.039)	Loss 0.7724 (0.6860)	Prec@1 77.000 (76.228)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.073 (0.046)	Data 0.062 (0.037)	Loss 0.6344 (0.6779)	Prec@1 78.000 (76.475)
 * Training Prec@1 76.646
Test: [0/50]	Time 0.142 (0.142)	Loss 0.9330 (0.9330)	Prec@1 69.500 (69.500)
 * Testing Prec@1 69.380
Epoch: [8/80][0/250]	LR: 0.1	Time 0.185 (0.185)	Data 0.166 (0.166)	Loss 0.5852 (0.5852)	Prec@1 79.000 (79.000)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.037 (0.037)	Data 0.028 (0.028)	Loss 0.7101 (0.6502)	Prec@1 75.500 (77.480)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.028 (0.029)	Loss 0.6174 (0.6516)	Prec@1 76.000 (77.415)
 * Training Prec@1 77.664
Test: [0/50]	Time 0.142 (0.142)	Loss 0.6508 (0.6508)	Prec@1 77.000 (77.000)
 * Testing Prec@1 75.420
Epoch: [9/80][0/250]	LR: 0.1	Time 0.217 (0.217)	Data 0.200 (0.200)	Loss 0.5128 (0.5128)	Prec@1 83.000 (83.000)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.027 (0.030)	Loss 0.6476 (0.6154)	Prec@1 77.000 (78.619)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.050 (0.039)	Data 0.040 (0.030)	Loss 0.6878 (0.6253)	Prec@1 78.500 (78.187)
 * Training Prec@1 78.236
Test: [0/50]	Time 0.147 (0.147)	Loss 0.8194 (0.8194)	Prec@1 72.500 (72.500)
 * Testing Prec@1 70.680
Epoch: [10/80][0/250]	LR: 0.1	Time 0.159 (0.159)	Data 0.142 (0.142)	Loss 0.5161 (0.5161)	Prec@1 79.500 (79.500)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.047 (0.039)	Data 0.038 (0.030)	Loss 0.5452 (0.5928)	Prec@1 84.500 (79.436)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.026 (0.029)	Loss 0.5703 (0.5996)	Prec@1 79.500 (79.199)
 * Training Prec@1 79.044
Test: [0/50]	Time 0.100 (0.100)	Loss 0.6540 (0.6540)	Prec@1 79.500 (79.500)
 * Testing Prec@1 75.440
Epoch: [11/80][0/250]	LR: 0.1	Time 0.220 (0.220)	Data 0.201 (0.201)	Loss 0.5372 (0.5372)	Prec@1 86.000 (86.000)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.037 (0.046)	Data 0.027 (0.036)	Loss 0.6864 (0.5843)	Prec@1 79.000 (79.728)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.035 (0.041)	Data 0.027 (0.032)	Loss 0.6830 (0.5833)	Prec@1 77.500 (79.629)
 * Training Prec@1 79.704
Test: [0/50]	Time 0.155 (0.155)	Loss 0.5197 (0.5197)	Prec@1 81.500 (81.500)
 * Testing Prec@1 77.970
Epoch: [12/80][0/250]	LR: 0.1	Time 0.214 (0.214)	Data 0.196 (0.196)	Loss 0.5232 (0.5232)	Prec@1 81.500 (81.500)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.036 (0.041)	Data 0.027 (0.032)	Loss 0.6798 (0.5609)	Prec@1 76.500 (80.287)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.031 (0.041)	Data 0.023 (0.031)	Loss 0.5544 (0.5669)	Prec@1 81.500 (80.326)
 * Training Prec@1 80.386
Test: [0/50]	Time 0.155 (0.155)	Loss 0.6329 (0.6329)	Prec@1 77.000 (77.000)
 * Testing Prec@1 75.280
Epoch: [13/80][0/250]	LR: 0.1	Time 0.134 (0.134)	Data 0.117 (0.117)	Loss 0.5310 (0.5310)	Prec@1 83.000 (83.000)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.036 (0.037)	Data 0.027 (0.028)	Loss 0.5758 (0.5537)	Prec@1 82.500 (80.995)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.026 (0.028)	Loss 0.5397 (0.5561)	Prec@1 81.000 (80.843)
 * Training Prec@1 80.874
Test: [0/50]	Time 0.142 (0.142)	Loss 0.6096 (0.6096)	Prec@1 79.000 (79.000)
 * Testing Prec@1 78.620
Epoch: [14/80][0/250]	LR: 0.1	Time 0.219 (0.219)	Data 0.201 (0.201)	Loss 0.4894 (0.4894)	Prec@1 83.500 (83.500)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.036 (0.042)	Data 0.027 (0.033)	Loss 0.5191 (0.5466)	Prec@1 83.500 (81.119)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.053 (0.042)	Data 0.044 (0.032)	Loss 0.4723 (0.5412)	Prec@1 82.000 (81.341)
 * Training Prec@1 81.390
Test: [0/50]	Time 0.116 (0.116)	Loss 0.7988 (0.7988)	Prec@1 73.000 (73.000)
 * Testing Prec@1 73.250
Epoch: [15/80][0/250]	LR: 0.1	Time 0.142 (0.142)	Data 0.125 (0.125)	Loss 0.5246 (0.5246)	Prec@1 82.500 (82.500)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.050 (0.042)	Data 0.040 (0.034)	Loss 0.4722 (0.5159)	Prec@1 82.000 (82.243)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.037 (0.042)	Data 0.026 (0.033)	Loss 0.4527 (0.5275)	Prec@1 86.000 (81.749)
 * Training Prec@1 81.774
Test: [0/50]	Time 0.135 (0.135)	Loss 0.5623 (0.5623)	Prec@1 81.500 (81.500)
 * Testing Prec@1 79.350
Epoch: [16/80][0/250]	LR: 0.1	Time 0.222 (0.222)	Data 0.204 (0.204)	Loss 0.6368 (0.6368)	Prec@1 78.000 (78.000)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.036 (0.043)	Data 0.027 (0.034)	Loss 0.4764 (0.5035)	Prec@1 84.000 (82.569)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.038 (0.043)	Data 0.029 (0.034)	Loss 0.5294 (0.5180)	Prec@1 81.500 (82.065)
 * Training Prec@1 82.024
Test: [0/50]	Time 0.130 (0.130)	Loss 0.7245 (0.7245)	Prec@1 77.000 (77.000)
 * Testing Prec@1 76.260
Epoch: [17/80][0/250]	LR: 0.1	Time 0.218 (0.218)	Data 0.200 (0.200)	Loss 0.5628 (0.5628)	Prec@1 82.000 (82.000)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.037 (0.046)	Data 0.029 (0.036)	Loss 0.3959 (0.5105)	Prec@1 88.000 (82.149)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.038 (0.044)	Data 0.029 (0.035)	Loss 0.4808 (0.5119)	Prec@1 81.000 (81.985)
 * Training Prec@1 82.136
Test: [0/50]	Time 0.131 (0.131)	Loss 0.6274 (0.6274)	Prec@1 77.000 (77.000)
 * Testing Prec@1 77.770
Epoch: [18/80][0/250]	LR: 0.1	Time 0.141 (0.141)	Data 0.123 (0.123)	Loss 0.3956 (0.3956)	Prec@1 87.500 (87.500)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.037 (0.038)	Data 0.027 (0.029)	Loss 0.5952 (0.4987)	Prec@1 80.500 (82.693)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.040 (0.041)	Data 0.031 (0.032)	Loss 0.4894 (0.5061)	Prec@1 79.000 (82.493)
 * Training Prec@1 82.592
Test: [0/50]	Time 0.155 (0.155)	Loss 0.5826 (0.5826)	Prec@1 82.500 (82.500)
 * Testing Prec@1 79.830
Epoch: [19/80][0/250]	LR: 0.1	Time 0.207 (0.207)	Data 0.189 (0.189)	Loss 0.4926 (0.4926)	Prec@1 81.000 (81.000)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.036 (0.044)	Data 0.025 (0.035)	Loss 0.4797 (0.4886)	Prec@1 84.500 (83.050)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.038 (0.045)	Data 0.027 (0.036)	Loss 0.4450 (0.4968)	Prec@1 83.500 (82.741)
 * Training Prec@1 82.890
Test: [0/50]	Time 0.138 (0.138)	Loss 0.5531 (0.5531)	Prec@1 79.000 (79.000)
 * Testing Prec@1 78.560
Epoch: [20/80][0/250]	LR: 0.1	Time 0.140 (0.140)	Data 0.123 (0.123)	Loss 0.3394 (0.3394)	Prec@1 88.500 (88.500)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.046 (0.039)	Data 0.037 (0.030)	Loss 0.4707 (0.4876)	Prec@1 85.000 (83.233)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.027 (0.030)	Loss 0.5376 (0.4882)	Prec@1 79.000 (83.050)
 * Training Prec@1 83.082
Test: [0/50]	Time 0.156 (0.156)	Loss 0.6424 (0.6424)	Prec@1 78.500 (78.500)
 * Testing Prec@1 77.250
Epoch: [21/80][0/250]	LR: 0.1	Time 0.154 (0.154)	Data 0.136 (0.136)	Loss 0.5272 (0.5272)	Prec@1 81.500 (81.500)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.036 (0.041)	Data 0.027 (0.032)	Loss 0.5487 (0.4822)	Prec@1 82.500 (83.455)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.049 (0.041)	Data 0.039 (0.031)	Loss 0.5484 (0.4799)	Prec@1 78.500 (83.537)
 * Training Prec@1 83.450
Test: [0/50]	Time 0.117 (0.117)	Loss 0.6220 (0.6220)	Prec@1 81.000 (81.000)
 * Testing Prec@1 77.650
Epoch: [22/80][0/250]	LR: 0.1	Time 0.213 (0.213)	Data 0.195 (0.195)	Loss 0.4123 (0.4123)	Prec@1 85.000 (85.000)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.035 (0.047)	Data 0.026 (0.038)	Loss 0.3461 (0.4789)	Prec@1 88.000 (83.475)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.038 (0.045)	Data 0.030 (0.036)	Loss 0.4842 (0.4783)	Prec@1 84.000 (83.488)
 * Training Prec@1 83.486
Test: [0/50]	Time 0.122 (0.122)	Loss 0.7072 (0.7072)	Prec@1 75.000 (75.000)
 * Testing Prec@1 76.120
Epoch: [23/80][0/250]	LR: 0.1	Time 0.145 (0.145)	Data 0.127 (0.127)	Loss 0.6057 (0.6057)	Prec@1 81.500 (81.500)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.049 (0.044)	Data 0.039 (0.035)	Loss 0.4541 (0.4619)	Prec@1 87.000 (84.094)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.046 (0.047)	Data 0.037 (0.038)	Loss 0.4710 (0.4674)	Prec@1 81.500 (83.741)
 * Training Prec@1 83.694
Test: [0/50]	Time 0.133 (0.133)	Loss 0.5804 (0.5804)	Prec@1 81.500 (81.500)
 * Testing Prec@1 79.930
Epoch: [24/80][0/250]	LR: 0.1	Time 0.216 (0.216)	Data 0.198 (0.198)	Loss 0.4574 (0.4574)	Prec@1 85.500 (85.500)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.050 (0.047)	Data 0.040 (0.038)	Loss 0.4829 (0.4523)	Prec@1 80.000 (84.094)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.039 (0.045)	Data 0.030 (0.036)	Loss 0.4404 (0.4620)	Prec@1 83.500 (83.848)
 * Training Prec@1 83.858
Test: [0/50]	Time 0.131 (0.131)	Loss 0.5846 (0.5846)	Prec@1 79.000 (79.000)
 * Testing Prec@1 80.130
Epoch: [25/80][0/250]	LR: 0.1	Time 0.214 (0.214)	Data 0.196 (0.196)	Loss 0.4222 (0.4222)	Prec@1 83.500 (83.500)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.035 (0.040)	Data 0.026 (0.031)	Loss 0.5186 (0.4520)	Prec@1 83.500 (84.218)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.026 (0.029)	Loss 0.3307 (0.4532)	Prec@1 89.000 (84.224)
 * Training Prec@1 84.144
Test: [0/50]	Time 0.122 (0.122)	Loss 0.6361 (0.6361)	Prec@1 81.500 (81.500)
 * Testing Prec@1 76.980
Epoch: [26/80][0/250]	LR: 0.1	Time 0.134 (0.134)	Data 0.116 (0.116)	Loss 0.4103 (0.4103)	Prec@1 84.000 (84.000)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.052 (0.043)	Data 0.040 (0.034)	Loss 0.5270 (0.4456)	Prec@1 82.000 (84.693)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.047 (0.043)	Data 0.039 (0.034)	Loss 0.4335 (0.4515)	Prec@1 84.500 (84.361)
 * Training Prec@1 84.384
Test: [0/50]	Time 0.127 (0.127)	Loss 0.5988 (0.5988)	Prec@1 79.000 (79.000)
 * Testing Prec@1 77.940
Epoch: [27/80][0/250]	LR: 0.1	Time 0.146 (0.146)	Data 0.128 (0.128)	Loss 0.4966 (0.4966)	Prec@1 81.000 (81.000)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.047 (0.044)	Data 0.037 (0.035)	Loss 0.4266 (0.4472)	Prec@1 85.500 (84.396)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.037 (0.044)	Data 0.028 (0.034)	Loss 0.3810 (0.4500)	Prec@1 88.000 (84.174)
 * Training Prec@1 84.192
Test: [0/50]	Time 0.150 (0.150)	Loss 0.7637 (0.7637)	Prec@1 74.500 (74.500)
 * Testing Prec@1 75.700
Epoch: [28/80][0/250]	LR: 0.1	Time 0.219 (0.219)	Data 0.202 (0.202)	Loss 0.4095 (0.4095)	Prec@1 85.500 (85.500)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.036 (0.044)	Data 0.027 (0.035)	Loss 0.4085 (0.4423)	Prec@1 87.500 (84.822)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.036 (0.045)	Data 0.027 (0.035)	Loss 0.3489 (0.4467)	Prec@1 86.500 (84.614)
 * Training Prec@1 84.512
Test: [0/50]	Time 0.149 (0.149)	Loss 0.4839 (0.4839)	Prec@1 84.000 (84.000)
 * Testing Prec@1 81.090
Epoch: [29/80][0/250]	LR: 0.1	Time 0.238 (0.238)	Data 0.224 (0.224)	Loss 0.4225 (0.4225)	Prec@1 85.500 (85.500)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.026 (0.030)	Loss 0.4189 (0.4278)	Prec@1 86.000 (85.396)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.027 (0.029)	Loss 0.3851 (0.4388)	Prec@1 87.500 (84.915)
 * Training Prec@1 84.816
Test: [0/50]	Time 0.147 (0.147)	Loss 0.4901 (0.4901)	Prec@1 80.000 (80.000)
 * Testing Prec@1 80.490
Epoch: [30/80][0/250]	LR: 0.1	Time 0.137 (0.137)	Data 0.118 (0.118)	Loss 0.4814 (0.4814)	Prec@1 82.500 (82.500)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.036 (0.041)	Data 0.027 (0.031)	Loss 0.4719 (0.4331)	Prec@1 85.000 (84.916)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.038 (0.040)	Data 0.029 (0.031)	Loss 0.4947 (0.4389)	Prec@1 80.000 (84.724)
 * Training Prec@1 84.814
Test: [0/50]	Time 0.149 (0.149)	Loss 0.6355 (0.6355)	Prec@1 77.500 (77.500)
 * Testing Prec@1 78.360
Epoch: [31/80][0/250]	LR: 0.1	Time 0.138 (0.138)	Data 0.121 (0.121)	Loss 0.4735 (0.4735)	Prec@1 83.000 (83.000)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.028 (0.030)	Loss 0.5650 (0.4371)	Prec@1 82.500 (84.946)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.048 (0.039)	Data 0.039 (0.030)	Loss 0.4675 (0.4362)	Prec@1 85.000 (85.030)
 * Training Prec@1 84.998
Test: [0/50]	Time 0.131 (0.131)	Loss 0.5827 (0.5827)	Prec@1 81.000 (81.000)
 * Testing Prec@1 79.240
Epoch: [32/80][0/250]	LR: 0.1	Time 0.132 (0.132)	Data 0.117 (0.117)	Loss 0.4231 (0.4231)	Prec@1 86.500 (86.500)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.039 (0.046)	Data 0.030 (0.037)	Loss 0.3243 (0.4224)	Prec@1 88.500 (85.317)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.049 (0.046)	Data 0.039 (0.037)	Loss 0.4114 (0.4234)	Prec@1 83.500 (85.423)
 * Training Prec@1 85.418
Test: [0/50]	Time 0.148 (0.148)	Loss 0.5742 (0.5742)	Prec@1 82.000 (82.000)
 * Testing Prec@1 79.900
Epoch: [33/80][0/250]	LR: 0.1	Time 0.215 (0.215)	Data 0.197 (0.197)	Loss 0.3996 (0.3996)	Prec@1 85.500 (85.500)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.036 (0.044)	Data 0.028 (0.035)	Loss 0.4986 (0.4191)	Prec@1 82.000 (85.455)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.049 (0.044)	Data 0.039 (0.034)	Loss 0.4745 (0.4298)	Prec@1 85.500 (85.134)
 * Training Prec@1 85.174
Test: [0/50]	Time 0.132 (0.132)	Loss 0.6339 (0.6339)	Prec@1 77.000 (77.000)
 * Testing Prec@1 78.800
Epoch: [34/80][0/250]	LR: 0.1	Time 0.210 (0.210)	Data 0.192 (0.192)	Loss 0.3647 (0.3647)	Prec@1 86.000 (86.000)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.051 (0.043)	Data 0.040 (0.034)	Loss 0.4258 (0.4176)	Prec@1 86.500 (85.317)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.052 (0.046)	Data 0.042 (0.037)	Loss 0.4687 (0.4221)	Prec@1 83.000 (85.403)
 * Training Prec@1 85.418
Test: [0/50]	Time 0.137 (0.137)	Loss 0.6312 (0.6312)	Prec@1 78.000 (78.000)
 * Testing Prec@1 81.100
Epoch: [35/80][0/250]	LR: 0.1	Time 0.216 (0.216)	Data 0.199 (0.199)	Loss 0.4748 (0.4748)	Prec@1 82.500 (82.500)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.036 (0.043)	Data 0.028 (0.034)	Loss 0.3855 (0.4045)	Prec@1 89.500 (85.916)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.049 (0.043)	Data 0.038 (0.034)	Loss 0.4659 (0.4172)	Prec@1 83.500 (85.547)
 * Training Prec@1 85.508
Test: [0/50]	Time 0.156 (0.156)	Loss 0.6345 (0.6345)	Prec@1 79.500 (79.500)
 * Testing Prec@1 76.760
Epoch: [36/80][0/250]	LR: 0.1	Time 0.178 (0.178)	Data 0.165 (0.165)	Loss 0.5113 (0.5113)	Prec@1 84.500 (84.500)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.038 (0.038)	Data 0.029 (0.029)	Loss 0.4004 (0.4155)	Prec@1 85.000 (85.589)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.036 (0.037)	Data 0.026 (0.028)	Loss 0.2915 (0.4128)	Prec@1 89.500 (85.644)
 * Training Prec@1 85.478
Test: [0/50]	Time 0.124 (0.124)	Loss 0.5607 (0.5607)	Prec@1 78.000 (78.000)
 * Testing Prec@1 80.880
Epoch: [37/80][0/250]	LR: 0.1	Time 0.179 (0.179)	Data 0.162 (0.162)	Loss 0.4016 (0.4016)	Prec@1 85.500 (85.500)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.048 (0.040)	Data 0.038 (0.031)	Loss 0.3293 (0.4105)	Prec@1 89.000 (85.827)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.048 (0.041)	Data 0.038 (0.032)	Loss 0.3048 (0.4132)	Prec@1 91.500 (85.697)
 * Training Prec@1 85.598
Test: [0/50]	Time 0.122 (0.122)	Loss 0.6127 (0.6127)	Prec@1 78.500 (78.500)
 * Testing Prec@1 78.000
Epoch: [38/80][0/250]	LR: 0.1	Time 0.145 (0.145)	Data 0.128 (0.128)	Loss 0.3434 (0.3434)	Prec@1 88.000 (88.000)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.037 (0.043)	Data 0.028 (0.034)	Loss 0.3767 (0.4108)	Prec@1 85.500 (85.802)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.039 (0.041)	Data 0.031 (0.032)	Loss 0.3613 (0.4135)	Prec@1 88.500 (85.716)
 * Training Prec@1 85.690
Test: [0/50]	Time 0.150 (0.150)	Loss 0.6666 (0.6666)	Prec@1 79.000 (79.000)
 * Testing Prec@1 79.970
Epoch: [39/80][0/250]	LR: 0.1	Time 0.174 (0.174)	Data 0.158 (0.158)	Loss 0.4013 (0.4013)	Prec@1 86.500 (86.500)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.037 (0.044)	Data 0.028 (0.035)	Loss 0.5141 (0.4063)	Prec@1 81.500 (85.530)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.037 (0.042)	Data 0.028 (0.033)	Loss 0.4217 (0.4089)	Prec@1 88.000 (85.632)
 * Training Prec@1 85.648
Test: [0/50]	Time 0.164 (0.164)	Loss 0.6307 (0.6307)	Prec@1 76.500 (76.500)
 * Testing Prec@1 80.990
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.150 (0.150)	Data 0.133 (0.133)	Loss 0.3716 (0.3716)	Prec@1 88.500 (88.500)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.045)	Data 0.027 (0.036)	Loss 0.4139 (0.3544)	Prec@1 84.500 (87.856)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.044)	Data 0.026 (0.035)	Loss 0.4395 (0.3457)	Prec@1 85.500 (88.169)
 * Training Prec@1 88.340
Test: [0/50]	Time 0.165 (0.165)	Loss 0.3791 (0.3791)	Prec@1 84.500 (84.500)
 * Testing Prec@1 85.990
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.132 (0.132)	Data 0.114 (0.114)	Loss 0.2887 (0.2887)	Prec@1 90.000 (90.000)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.039 (0.040)	Data 0.032 (0.031)	Loss 0.2784 (0.3274)	Prec@1 92.000 (88.980)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.041)	Data 0.030 (0.032)	Loss 0.2856 (0.3231)	Prec@1 87.000 (89.102)
 * Training Prec@1 89.072
Test: [0/50]	Time 0.137 (0.137)	Loss 0.3740 (0.3740)	Prec@1 84.500 (84.500)
 * Testing Prec@1 85.900
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.137 (0.137)	Data 0.120 (0.120)	Loss 0.2798 (0.2798)	Prec@1 88.000 (88.000)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.040 (0.041)	Data 0.032 (0.033)	Loss 0.2912 (0.3147)	Prec@1 88.500 (89.421)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.039)	Data 0.027 (0.031)	Loss 0.3046 (0.3135)	Prec@1 89.500 (89.423)
 * Training Prec@1 89.228
Test: [0/50]	Time 0.121 (0.121)	Loss 0.3638 (0.3638)	Prec@1 85.000 (85.000)
 * Testing Prec@1 86.250
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.231 (0.231)	Data 0.214 (0.214)	Loss 0.3085 (0.3085)	Prec@1 88.500 (88.500)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.048 (0.041)	Data 0.038 (0.032)	Loss 0.2936 (0.3156)	Prec@1 90.000 (89.163)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.049 (0.041)	Data 0.039 (0.032)	Loss 0.3274 (0.3131)	Prec@1 90.000 (89.333)
 * Training Prec@1 89.340
Test: [0/50]	Time 0.132 (0.132)	Loss 0.3651 (0.3651)	Prec@1 84.500 (84.500)
 * Testing Prec@1 86.520
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.182 (0.182)	Data 0.166 (0.166)	Loss 0.2954 (0.2954)	Prec@1 90.000 (90.000)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.040 (0.045)	Data 0.028 (0.035)	Loss 0.3176 (0.3011)	Prec@1 87.500 (89.604)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.047 (0.043)	Data 0.038 (0.034)	Loss 0.3083 (0.3085)	Prec@1 86.500 (89.435)
 * Training Prec@1 89.388
Test: [0/50]	Time 0.124 (0.124)	Loss 0.3468 (0.3468)	Prec@1 85.000 (85.000)
 * Testing Prec@1 86.370
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.184 (0.184)	Data 0.168 (0.168)	Loss 0.3838 (0.3838)	Prec@1 89.000 (89.000)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.038 (0.043)	Data 0.028 (0.034)	Loss 0.3546 (0.3060)	Prec@1 90.500 (89.584)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.041)	Data 0.027 (0.032)	Loss 0.3404 (0.3086)	Prec@1 90.500 (89.560)
 * Training Prec@1 89.508
Test: [0/50]	Time 0.156 (0.156)	Loss 0.3607 (0.3607)	Prec@1 86.500 (86.500)
 * Testing Prec@1 86.080
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.135 (0.135)	Data 0.117 (0.117)	Loss 0.3418 (0.3418)	Prec@1 89.000 (89.000)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.070 (0.041)	Data 0.059 (0.032)	Loss 0.3216 (0.3017)	Prec@1 88.500 (89.693)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.047 (0.042)	Data 0.038 (0.032)	Loss 0.3639 (0.3024)	Prec@1 84.000 (89.545)
 * Training Prec@1 89.494
Test: [0/50]	Time 0.128 (0.128)	Loss 0.3621 (0.3621)	Prec@1 86.000 (86.000)
 * Testing Prec@1 86.280
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 0.149 (0.149)	Data 0.131 (0.131)	Loss 0.2842 (0.2842)	Prec@1 88.000 (88.000)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.038 (0.041)	Data 0.029 (0.031)	Loss 0.3452 (0.3046)	Prec@1 89.000 (89.381)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.039)	Data 0.026 (0.030)	Loss 0.3926 (0.3031)	Prec@1 87.000 (89.624)
 * Training Prec@1 89.678
Test: [0/50]	Time 0.137 (0.137)	Loss 0.3580 (0.3580)	Prec@1 86.000 (86.000)
 * Testing Prec@1 86.480
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.108 (0.108)	Data 0.091 (0.091)	Loss 0.4015 (0.4015)	Prec@1 89.500 (89.500)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.047 (0.043)	Data 0.038 (0.033)	Loss 0.2764 (0.3016)	Prec@1 90.000 (89.748)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.042)	Data 0.029 (0.033)	Loss 0.2997 (0.3030)	Prec@1 88.000 (89.647)
 * Training Prec@1 89.630
Test: [0/50]	Time 0.140 (0.140)	Loss 0.3630 (0.3630)	Prec@1 86.500 (86.500)
 * Testing Prec@1 86.100
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.223 (0.223)	Data 0.205 (0.205)	Loss 0.3095 (0.3095)	Prec@1 89.000 (89.000)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.043)	Data 0.030 (0.034)	Loss 0.2491 (0.3002)	Prec@1 92.500 (89.480)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.049 (0.043)	Data 0.040 (0.034)	Loss 0.3148 (0.3049)	Prec@1 91.000 (89.465)
 * Training Prec@1 89.588
Test: [0/50]	Time 0.129 (0.129)	Loss 0.3599 (0.3599)	Prec@1 86.000 (86.000)
 * Testing Prec@1 86.290
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.107 (0.107)	Data 0.091 (0.091)	Loss 0.2544 (0.2544)	Prec@1 90.500 (90.500)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.045)	Data 0.028 (0.037)	Loss 0.2705 (0.2982)	Prec@1 90.500 (89.950)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.040 (0.045)	Data 0.030 (0.036)	Loss 0.2878 (0.3011)	Prec@1 88.500 (89.881)
 * Training Prec@1 89.792
Test: [0/50]	Time 0.145 (0.145)	Loss 0.3596 (0.3596)	Prec@1 86.000 (86.000)
 * Testing Prec@1 86.220
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 0.135 (0.135)	Data 0.118 (0.118)	Loss 0.2952 (0.2952)	Prec@1 88.500 (88.500)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.036 (0.038)	Data 0.028 (0.028)	Loss 0.3564 (0.2927)	Prec@1 88.000 (89.881)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.037)	Data 0.029 (0.028)	Loss 0.2548 (0.3009)	Prec@1 91.500 (89.692)
 * Training Prec@1 89.730
Test: [0/50]	Time 0.132 (0.132)	Loss 0.3534 (0.3534)	Prec@1 86.000 (86.000)
 * Testing Prec@1 86.270
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.105 (0.105)	Data 0.087 (0.087)	Loss 0.2970 (0.2970)	Prec@1 89.500 (89.500)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.047 (0.038)	Data 0.038 (0.029)	Loss 0.2257 (0.2938)	Prec@1 92.000 (89.941)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.074 (0.040)	Data 0.065 (0.031)	Loss 0.2776 (0.2969)	Prec@1 89.500 (89.846)
 * Training Prec@1 89.788
Test: [0/50]	Time 0.161 (0.161)	Loss 0.3628 (0.3628)	Prec@1 86.000 (86.000)
 * Testing Prec@1 85.870
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 0.180 (0.180)	Data 0.165 (0.165)	Loss 0.3413 (0.3413)	Prec@1 89.500 (89.500)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.050 (0.041)	Data 0.040 (0.032)	Loss 0.3444 (0.2921)	Prec@1 90.500 (90.089)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.042)	Data 0.027 (0.033)	Loss 0.2384 (0.2891)	Prec@1 91.500 (90.149)
 * Training Prec@1 90.058
Test: [0/50]	Time 0.135 (0.135)	Loss 0.3377 (0.3377)	Prec@1 89.000 (89.000)
 * Testing Prec@1 86.410
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.123 (0.123)	Data 0.106 (0.106)	Loss 0.2699 (0.2699)	Prec@1 90.000 (90.000)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.057 (0.043)	Data 0.047 (0.035)	Loss 0.2600 (0.2936)	Prec@1 92.000 (89.847)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.039 (0.044)	Data 0.029 (0.035)	Loss 0.4438 (0.2919)	Prec@1 86.000 (89.878)
 * Training Prec@1 89.964
Test: [0/50]	Time 0.136 (0.136)	Loss 0.3496 (0.3496)	Prec@1 86.500 (86.500)
 * Testing Prec@1 86.580
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.226 (0.226)	Data 0.211 (0.211)	Loss 0.2343 (0.2343)	Prec@1 93.000 (93.000)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.040 (0.046)	Data 0.031 (0.037)	Loss 0.3757 (0.2912)	Prec@1 85.500 (90.064)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.044)	Data 0.027 (0.035)	Loss 0.3654 (0.2919)	Prec@1 86.500 (89.955)
 * Training Prec@1 89.912
Test: [0/50]	Time 0.160 (0.160)	Loss 0.3607 (0.3607)	Prec@1 88.000 (88.000)
 * Testing Prec@1 86.260
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.140 (0.140)	Data 0.123 (0.123)	Loss 0.2910 (0.2910)	Prec@1 91.000 (91.000)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.045)	Data 0.029 (0.035)	Loss 0.2458 (0.2875)	Prec@1 94.500 (90.183)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.077 (0.045)	Data 0.068 (0.036)	Loss 0.2801 (0.2903)	Prec@1 90.000 (90.030)
 * Training Prec@1 90.096
Test: [0/50]	Time 0.132 (0.132)	Loss 0.3381 (0.3381)	Prec@1 87.500 (87.500)
 * Testing Prec@1 86.600
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.219 (0.219)	Data 0.199 (0.199)	Loss 0.3940 (0.3940)	Prec@1 85.000 (85.000)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.048)	Data 0.025 (0.038)	Loss 0.3572 (0.2812)	Prec@1 89.000 (90.421)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.042)	Data 0.029 (0.033)	Loss 0.3311 (0.2899)	Prec@1 86.500 (90.142)
 * Training Prec@1 90.086
Test: [0/50]	Time 0.140 (0.140)	Loss 0.3669 (0.3669)	Prec@1 86.500 (86.500)
 * Testing Prec@1 86.450
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.149 (0.149)	Data 0.130 (0.130)	Loss 0.2538 (0.2538)	Prec@1 89.500 (89.500)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.036 (0.049)	Data 0.025 (0.039)	Loss 0.2352 (0.2970)	Prec@1 93.000 (89.569)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.044)	Data 0.026 (0.035)	Loss 0.2697 (0.2942)	Prec@1 88.500 (89.694)
 * Training Prec@1 89.822
Test: [0/50]	Time 0.127 (0.127)	Loss 0.3384 (0.3384)	Prec@1 87.500 (87.500)
 * Testing Prec@1 86.550
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.136 (0.136)	Data 0.119 (0.119)	Loss 0.2540 (0.2540)	Prec@1 93.000 (93.000)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.047 (0.041)	Data 0.038 (0.031)	Loss 0.2955 (0.2845)	Prec@1 92.500 (90.252)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.039)	Data 0.029 (0.030)	Loss 0.3638 (0.2854)	Prec@1 88.000 (90.236)
 * Training Prec@1 90.296
Test: [0/50]	Time 0.135 (0.135)	Loss 0.3342 (0.3342)	Prec@1 88.000 (88.000)
 * Testing Prec@1 86.660
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.173 (0.173)	Data 0.157 (0.157)	Loss 0.3358 (0.3358)	Prec@1 88.500 (88.500)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.048 (0.041)	Data 0.039 (0.032)	Loss 0.3208 (0.2845)	Prec@1 88.500 (90.342)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.038 (0.040)	Data 0.028 (0.031)	Loss 0.3071 (0.2828)	Prec@1 90.000 (90.251)
 * Training Prec@1 90.364
Test: [0/50]	Time 0.159 (0.159)	Loss 0.3421 (0.3421)	Prec@1 87.000 (87.000)
 * Testing Prec@1 86.940
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.137 (0.137)	Data 0.117 (0.117)	Loss 0.2793 (0.2793)	Prec@1 90.000 (90.000)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.047)	Data 0.028 (0.037)	Loss 0.2479 (0.2731)	Prec@1 93.000 (90.594)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.039 (0.042)	Data 0.029 (0.032)	Loss 0.2933 (0.2780)	Prec@1 89.500 (90.430)
 * Training Prec@1 90.388
Test: [0/50]	Time 0.151 (0.151)	Loss 0.3394 (0.3394)	Prec@1 87.000 (87.000)
 * Testing Prec@1 86.940
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.105 (0.105)	Data 0.090 (0.090)	Loss 0.2878 (0.2878)	Prec@1 93.000 (93.000)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.037 (0.037)	Data 0.029 (0.028)	Loss 0.3042 (0.2776)	Prec@1 91.000 (90.450)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.035 (0.037)	Data 0.027 (0.028)	Loss 0.2976 (0.2778)	Prec@1 86.500 (90.485)
 * Training Prec@1 90.526
Test: [0/50]	Time 0.146 (0.146)	Loss 0.3396 (0.3396)	Prec@1 86.500 (86.500)
 * Testing Prec@1 86.760
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 0.143 (0.143)	Data 0.126 (0.126)	Loss 0.2831 (0.2831)	Prec@1 90.000 (90.000)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.037 (0.045)	Data 0.029 (0.036)	Loss 0.2686 (0.2733)	Prec@1 90.500 (90.644)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.040 (0.045)	Data 0.029 (0.036)	Loss 0.2440 (0.2773)	Prec@1 91.500 (90.463)
 * Training Prec@1 90.488
Test: [0/50]	Time 0.146 (0.146)	Loss 0.3404 (0.3404)	Prec@1 87.500 (87.500)
 * Testing Prec@1 86.910
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 0.137 (0.137)	Data 0.119 (0.119)	Loss 0.2478 (0.2478)	Prec@1 91.500 (91.500)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.036 (0.037)	Data 0.028 (0.028)	Loss 0.3281 (0.2769)	Prec@1 90.000 (90.614)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.038 (0.038)	Data 0.028 (0.029)	Loss 0.3406 (0.2746)	Prec@1 88.000 (90.585)
 * Training Prec@1 90.630
Test: [0/50]	Time 0.136 (0.136)	Loss 0.3332 (0.3332)	Prec@1 87.500 (87.500)
 * Testing Prec@1 86.850
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.108 (0.108)	Data 0.092 (0.092)	Loss 0.1957 (0.1957)	Prec@1 93.500 (93.500)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.038 (0.042)	Data 0.028 (0.032)	Loss 0.2744 (0.2721)	Prec@1 90.500 (90.594)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.049 (0.041)	Data 0.039 (0.032)	Loss 0.2157 (0.2737)	Prec@1 91.000 (90.600)
 * Training Prec@1 90.568
Test: [0/50]	Time 0.125 (0.125)	Loss 0.3373 (0.3373)	Prec@1 87.000 (87.000)
 * Testing Prec@1 86.900
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 0.139 (0.139)	Data 0.123 (0.123)	Loss 0.2059 (0.2059)	Prec@1 93.500 (93.500)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.036 (0.042)	Data 0.027 (0.033)	Loss 0.2107 (0.2770)	Prec@1 93.000 (90.604)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.055 (0.042)	Data 0.045 (0.032)	Loss 0.2328 (0.2760)	Prec@1 92.000 (90.647)
 * Training Prec@1 90.626
Test: [0/50]	Time 0.144 (0.144)	Loss 0.3340 (0.3340)	Prec@1 87.500 (87.500)
 * Testing Prec@1 86.930
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.137 (0.137)	Data 0.124 (0.124)	Loss 0.2701 (0.2701)	Prec@1 91.500 (91.500)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.037)	Data 0.028 (0.028)	Loss 0.2660 (0.2711)	Prec@1 91.500 (90.743)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.038 (0.038)	Data 0.030 (0.029)	Loss 0.3286 (0.2763)	Prec@1 89.500 (90.512)
 * Training Prec@1 90.552
Test: [0/50]	Time 0.138 (0.138)	Loss 0.3292 (0.3292)	Prec@1 88.000 (88.000)
 * Testing Prec@1 87.000
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.221 (0.221)	Data 0.204 (0.204)	Loss 0.2482 (0.2482)	Prec@1 93.500 (93.500)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.049 (0.046)	Data 0.039 (0.036)	Loss 0.2803 (0.2703)	Prec@1 91.000 (90.856)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.045)	Data 0.029 (0.035)	Loss 0.3252 (0.2731)	Prec@1 87.000 (90.709)
 * Training Prec@1 90.590
Test: [0/50]	Time 0.158 (0.158)	Loss 0.3283 (0.3283)	Prec@1 87.500 (87.500)
 * Testing Prec@1 87.020
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 0.207 (0.207)	Data 0.189 (0.189)	Loss 0.2033 (0.2033)	Prec@1 92.000 (92.000)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.041)	Data 0.026 (0.032)	Loss 0.2529 (0.2710)	Prec@1 91.500 (90.723)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.039)	Data 0.028 (0.030)	Loss 0.3215 (0.2727)	Prec@1 87.500 (90.706)
 * Training Prec@1 90.706
Test: [0/50]	Time 0.122 (0.122)	Loss 0.3415 (0.3415)	Prec@1 87.000 (87.000)
 * Testing Prec@1 86.820
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.107 (0.107)	Data 0.091 (0.091)	Loss 0.2678 (0.2678)	Prec@1 91.000 (91.000)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.037)	Data 0.026 (0.027)	Loss 0.3643 (0.2751)	Prec@1 87.000 (90.559)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.035 (0.036)	Data 0.027 (0.027)	Loss 0.2518 (0.2751)	Prec@1 92.000 (90.669)
 * Training Prec@1 90.726
Test: [0/50]	Time 0.106 (0.106)	Loss 0.3355 (0.3355)	Prec@1 88.000 (88.000)
 * Testing Prec@1 87.100
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.218 (0.218)	Data 0.200 (0.200)	Loss 0.2680 (0.2680)	Prec@1 91.500 (91.500)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.039 (0.042)	Data 0.030 (0.032)	Loss 0.2717 (0.2707)	Prec@1 91.500 (90.713)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.041)	Data 0.049 (0.032)	Loss 0.3114 (0.2756)	Prec@1 88.500 (90.585)
 * Training Prec@1 90.694
Test: [0/50]	Time 0.121 (0.121)	Loss 0.3397 (0.3397)	Prec@1 87.000 (87.000)
 * Testing Prec@1 87.100
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.228 (0.228)	Data 0.210 (0.210)	Loss 0.3244 (0.3244)	Prec@1 89.000 (89.000)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.037 (0.040)	Data 0.028 (0.030)	Loss 0.2360 (0.2785)	Prec@1 91.500 (90.416)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.044 (0.041)	Data 0.034 (0.032)	Loss 0.3169 (0.2757)	Prec@1 90.500 (90.547)
 * Training Prec@1 90.586
Test: [0/50]	Time 0.137 (0.137)	Loss 0.3392 (0.3392)	Prec@1 87.500 (87.500)
 * Testing Prec@1 87.070
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 0.225 (0.225)	Data 0.207 (0.207)	Loss 0.2672 (0.2672)	Prec@1 91.000 (91.000)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.041 (0.044)	Data 0.032 (0.035)	Loss 0.2557 (0.2760)	Prec@1 90.000 (90.629)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.051 (0.043)	Data 0.041 (0.034)	Loss 0.2788 (0.2752)	Prec@1 90.500 (90.699)
 * Training Prec@1 90.658
Test: [0/50]	Time 0.133 (0.133)	Loss 0.3340 (0.3340)	Prec@1 87.500 (87.500)
 * Testing Prec@1 87.080
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.210 (0.210)	Data 0.192 (0.192)	Loss 0.1989 (0.1989)	Prec@1 92.500 (92.500)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.038 (0.038)	Data 0.028 (0.029)	Loss 0.2614 (0.2703)	Prec@1 91.500 (90.866)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.037)	Data 0.027 (0.028)	Loss 0.2586 (0.2736)	Prec@1 92.000 (90.794)
 * Training Prec@1 90.770
Test: [0/50]	Time 0.139 (0.139)	Loss 0.3392 (0.3392)	Prec@1 87.500 (87.500)
 * Testing Prec@1 86.980
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.219 (0.219)	Data 0.202 (0.202)	Loss 0.2714 (0.2714)	Prec@1 89.500 (89.500)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.036 (0.041)	Data 0.028 (0.032)	Loss 0.2391 (0.2748)	Prec@1 94.000 (90.500)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.040)	Data 0.027 (0.030)	Loss 0.3443 (0.2751)	Prec@1 86.500 (90.505)
 * Training Prec@1 90.524
Test: [0/50]	Time 0.148 (0.148)	Loss 0.3436 (0.3436)	Prec@1 87.500 (87.500)
 * Testing Prec@1 86.820
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.131 (0.131)	Data 0.114 (0.114)	Loss 0.2210 (0.2210)	Prec@1 92.000 (92.000)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.037)	Data 0.026 (0.028)	Loss 0.2977 (0.2810)	Prec@1 89.500 (90.446)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.038)	Data 0.027 (0.029)	Loss 0.3526 (0.2762)	Prec@1 86.500 (90.575)
 * Training Prec@1 90.534
Test: [0/50]	Time 0.137 (0.137)	Loss 0.3380 (0.3380)	Prec@1 88.000 (88.000)
 * Testing Prec@1 87.050
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 0.139 (0.139)	Data 0.121 (0.121)	Loss 0.2970 (0.2970)	Prec@1 89.500 (89.500)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.037 (0.042)	Data 0.028 (0.033)	Loss 0.3242 (0.2768)	Prec@1 89.500 (90.658)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.044)	Data 0.029 (0.035)	Loss 0.3177 (0.2752)	Prec@1 91.000 (90.622)
 * Training Prec@1 90.534
Test: [0/50]	Time 0.190 (0.190)	Loss 0.3406 (0.3406)	Prec@1 86.500 (86.500)
 * Testing Prec@1 86.960
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.141 (0.141)	Data 0.120 (0.120)	Loss 0.3562 (0.3562)	Prec@1 87.500 (87.500)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.037 (0.048)	Data 0.030 (0.038)	Loss 0.1908 (0.2680)	Prec@1 93.000 (90.911)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.043)	Data 0.028 (0.034)	Loss 0.3000 (0.2704)	Prec@1 88.500 (90.833)
 * Training Prec@1 90.770
Test: [0/50]	Time 0.127 (0.127)	Loss 0.3396 (0.3396)	Prec@1 87.000 (87.000)
 * Testing Prec@1 86.940
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.145 (0.145)	Data 0.128 (0.128)	Loss 0.2977 (0.2977)	Prec@1 90.500 (90.500)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.057 (0.043)	Data 0.047 (0.034)	Loss 0.2491 (0.2766)	Prec@1 92.000 (90.614)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.048 (0.043)	Data 0.038 (0.034)	Loss 0.2596 (0.2694)	Prec@1 89.500 (90.826)
 * Training Prec@1 90.800
Test: [0/50]	Time 0.143 (0.143)	Loss 0.3339 (0.3339)	Prec@1 87.000 (87.000)
 * Testing Prec@1 86.800
