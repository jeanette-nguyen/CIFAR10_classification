Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'resnet56'
Epoch: [0/80][0/250]	LR: 0.1	Time 2.385 (2.385)	Data 1.418 (1.418)	Loss 2.9427 (2.9427)	Prec@1 8.500 (8.500)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.062 (0.086)	Data 0.001 (0.015)	Loss 1.9598 (2.2747)	Prec@1 28.000 (17.277)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.062 (0.074)	Data 0.001 (0.008)	Loss 1.7152 (2.0507)	Prec@1 38.500 (24.075)
 * Training Prec@1 26.798
main.py:153: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.303 (0.303)	Loss 1.6343 (1.6343)	Prec@1 37.000 (37.000)
 * Testing Prec@1 35.820
main.py:190: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:191: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:199: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 1.337 (1.337)	Data 1.295 (1.295)	Loss 1.5925 (1.5925)	Prec@1 42.000 (42.000)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.062 (0.102)	Data 0.001 (0.019)	Loss 1.5120 (1.5605)	Prec@1 42.000 (41.708)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.062 (0.114)	Data 0.002 (0.011)	Loss 1.2910 (1.5018)	Prec@1 51.500 (44.413)
 * Training Prec@1 45.536
Test: [0/50]	Time 0.229 (0.229)	Loss 1.3205 (1.3205)	Prec@1 53.500 (53.500)
 * Testing Prec@1 51.480
Epoch: [2/80][0/250]	LR: 0.1	Time 0.942 (0.942)	Data 0.897 (0.897)	Loss 1.2493 (1.2493)	Prec@1 52.500 (52.500)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.063 (0.071)	Data 0.001 (0.010)	Loss 1.0286 (1.2350)	Prec@1 63.000 (55.163)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.062 (0.067)	Data 0.001 (0.006)	Loss 0.9066 (1.1740)	Prec@1 65.000 (57.729)
 * Training Prec@1 58.554
Test: [0/50]	Time 0.121 (0.121)	Loss 1.2204 (1.2204)	Prec@1 57.500 (57.500)
 * Testing Prec@1 57.700
Epoch: [3/80][0/250]	LR: 0.1	Time 0.117 (0.117)	Data 0.075 (0.075)	Loss 0.9144 (0.9144)	Prec@1 70.000 (70.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.063 (0.069)	Data 0.001 (0.008)	Loss 0.8751 (0.9461)	Prec@1 72.000 (66.351)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.063 (0.066)	Data 0.001 (0.005)	Loss 0.8784 (0.9239)	Prec@1 70.500 (67.197)
 * Training Prec@1 67.612
Test: [0/50]	Time 0.668 (0.668)	Loss 0.8864 (0.8864)	Prec@1 69.500 (69.500)
 * Testing Prec@1 68.060
Epoch: [4/80][0/250]	LR: 0.1	Time 0.446 (0.446)	Data 0.390 (0.390)	Loss 0.7850 (0.7850)	Prec@1 70.000 (70.000)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.063 (0.115)	Data 0.001 (0.005)	Loss 0.6624 (0.7549)	Prec@1 78.500 (73.530)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.063 (0.122)	Data 0.002 (0.010)	Loss 0.5267 (0.7437)	Prec@1 81.500 (74.022)
 * Training Prec@1 74.132
Test: [0/50]	Time 0.278 (0.278)	Loss 0.8104 (0.8104)	Prec@1 71.500 (71.500)
 * Testing Prec@1 70.730
Epoch: [5/80][0/250]	LR: 0.1	Time 0.798 (0.798)	Data 0.755 (0.755)	Loss 0.5123 (0.5123)	Prec@1 82.000 (82.000)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.063 (0.070)	Data 0.001 (0.009)	Loss 0.6035 (0.6238)	Prec@1 81.000 (78.401)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.063 (0.066)	Data 0.001 (0.005)	Loss 0.6737 (0.6259)	Prec@1 76.500 (78.167)
 * Training Prec@1 78.204
Test: [0/50]	Time 0.862 (0.862)	Loss 0.6455 (0.6455)	Prec@1 83.500 (83.500)
 * Testing Prec@1 75.750
Epoch: [6/80][0/250]	LR: 0.1	Time 0.144 (0.144)	Data 0.100 (0.100)	Loss 0.6244 (0.6244)	Prec@1 78.500 (78.500)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.062 (0.064)	Data 0.001 (0.003)	Loss 0.5646 (0.5259)	Prec@1 82.000 (81.431)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.063 (0.073)	Data 0.001 (0.012)	Loss 0.7632 (0.5326)	Prec@1 71.500 (81.279)
 * Training Prec@1 81.268
Test: [0/50]	Time 1.320 (1.320)	Loss 0.6299 (0.6299)	Prec@1 78.000 (78.000)
 * Testing Prec@1 76.720
Epoch: [7/80][0/250]	LR: 0.1	Time 0.521 (0.521)	Data 0.471 (0.471)	Loss 0.5454 (0.5454)	Prec@1 77.500 (77.500)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.063 (0.071)	Data 0.001 (0.010)	Loss 0.5617 (0.4274)	Prec@1 83.000 (85.351)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.063 (0.067)	Data 0.001 (0.006)	Loss 0.4679 (0.4573)	Prec@1 84.500 (84.306)
 * Training Prec@1 84.226
Test: [0/50]	Time 0.288 (0.288)	Loss 0.6800 (0.6800)	Prec@1 77.000 (77.000)
 * Testing Prec@1 74.850
Epoch: [8/80][0/250]	LR: 0.1	Time 0.135 (0.135)	Data 0.085 (0.085)	Loss 0.3903 (0.3903)	Prec@1 83.500 (83.500)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.063 (0.118)	Data 0.001 (0.002)	Loss 0.3998 (0.3749)	Prec@1 85.000 (86.921)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.062 (0.113)	Data 0.001 (0.008)	Loss 0.3807 (0.3967)	Prec@1 86.500 (86.209)
 * Training Prec@1 86.078
Test: [0/50]	Time 1.352 (1.352)	Loss 0.6559 (0.6559)	Prec@1 81.000 (81.000)
 * Testing Prec@1 78.290
Epoch: [9/80][0/250]	LR: 0.1	Time 2.810 (2.810)	Data 2.765 (2.765)	Loss 0.3149 (0.3149)	Prec@1 89.500 (89.500)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.063 (0.107)	Data 0.001 (0.046)	Loss 0.4254 (0.3195)	Prec@1 82.500 (88.906)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.063 (0.085)	Data 0.001 (0.024)	Loss 0.3938 (0.3439)	Prec@1 83.500 (87.980)
 * Training Prec@1 87.902
Test: [0/50]	Time 1.380 (1.380)	Loss 0.5815 (0.5815)	Prec@1 85.000 (85.000)
 * Testing Prec@1 78.580
Epoch: [10/80][0/250]	LR: 0.1	Time 0.351 (0.351)	Data 0.305 (0.305)	Loss 0.2548 (0.2548)	Prec@1 91.500 (91.500)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.063 (0.066)	Data 0.001 (0.004)	Loss 0.2689 (0.2755)	Prec@1 90.500 (90.287)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.064 (0.067)	Data 0.001 (0.006)	Loss 0.2241 (0.2951)	Prec@1 91.500 (89.550)
 * Training Prec@1 89.340
Test: [0/50]	Time 0.605 (0.605)	Loss 0.5322 (0.5322)	Prec@1 83.000 (83.000)
 * Testing Prec@1 79.820
Epoch: [11/80][0/250]	LR: 0.1	Time 1.113 (1.113)	Data 1.076 (1.076)	Loss 0.2118 (0.2118)	Prec@1 92.000 (92.000)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.063 (0.073)	Data 0.001 (0.012)	Loss 0.3234 (0.2332)	Prec@1 88.500 (91.891)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.063 (0.068)	Data 0.001 (0.007)	Loss 0.3467 (0.2526)	Prec@1 87.500 (91.194)
 * Training Prec@1 90.792
Test: [0/50]	Time 0.777 (0.777)	Loss 0.7842 (0.7842)	Prec@1 77.500 (77.500)
 * Testing Prec@1 74.290
Epoch: [12/80][0/250]	LR: 0.1	Time 0.148 (0.148)	Data 0.106 (0.106)	Loss 0.2188 (0.2188)	Prec@1 92.500 (92.500)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.063 (0.123)	Data 0.001 (0.007)	Loss 0.1199 (0.2057)	Prec@1 95.000 (92.718)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.062 (0.118)	Data 0.001 (0.004)	Loss 0.2960 (0.2245)	Prec@1 89.000 (92.007)
 * Training Prec@1 91.648
Test: [0/50]	Time 1.064 (1.064)	Loss 0.7037 (0.7037)	Prec@1 83.000 (83.000)
 * Testing Prec@1 80.230
Epoch: [13/80][0/250]	LR: 0.1	Time 0.134 (0.134)	Data 0.090 (0.090)	Loss 0.1742 (0.1742)	Prec@1 93.500 (93.500)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.062 (0.063)	Data 0.001 (0.002)	Loss 0.2055 (0.1521)	Prec@1 90.500 (94.792)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.062 (0.063)	Data 0.001 (0.002)	Loss 0.3097 (0.1843)	Prec@1 88.500 (93.545)
 * Training Prec@1 93.136
Test: [0/50]	Time 0.126 (0.126)	Loss 0.6527 (0.6527)	Prec@1 81.000 (81.000)
 * Testing Prec@1 78.830
Epoch: [14/80][0/250]	LR: 0.1	Time 0.447 (0.447)	Data 0.403 (0.403)	Loss 0.1635 (0.1635)	Prec@1 95.500 (95.500)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.063 (0.067)	Data 0.001 (0.005)	Loss 0.1707 (0.1450)	Prec@1 92.000 (95.045)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.063 (0.065)	Data 0.001 (0.003)	Loss 0.2497 (0.1715)	Prec@1 92.500 (94.032)
 * Training Prec@1 93.752
Test: [0/50]	Time 0.955 (0.955)	Loss 0.7298 (0.7298)	Prec@1 82.000 (82.000)
 * Testing Prec@1 78.760
Epoch: [15/80][0/250]	LR: 0.1	Time 0.407 (0.407)	Data 0.363 (0.363)	Loss 0.0696 (0.0696)	Prec@1 98.500 (98.500)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.063 (0.066)	Data 0.001 (0.005)	Loss 0.1549 (0.1325)	Prec@1 93.500 (95.386)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.062 (0.065)	Data 0.001 (0.003)	Loss 0.1813 (0.1518)	Prec@1 91.000 (94.674)
 * Training Prec@1 94.244
Test: [0/50]	Time 0.083 (0.083)	Loss 0.8583 (0.8583)	Prec@1 79.000 (79.000)
 * Testing Prec@1 76.110
Epoch: [16/80][0/250]	LR: 0.1	Time 0.545 (0.545)	Data 0.506 (0.506)	Loss 0.1718 (0.1718)	Prec@1 95.000 (95.000)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.063 (0.068)	Data 0.001 (0.006)	Loss 0.1455 (0.1288)	Prec@1 95.500 (95.609)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.064 (0.066)	Data 0.001 (0.004)	Loss 0.1612 (0.1365)	Prec@1 94.000 (95.259)
 * Training Prec@1 95.034
Test: [0/50]	Time 0.891 (0.891)	Loss 0.9511 (0.9511)	Prec@1 78.500 (78.500)
 * Testing Prec@1 77.960
Epoch: [17/80][0/250]	LR: 0.1	Time 0.364 (0.364)	Data 0.320 (0.320)	Loss 0.1114 (0.1114)	Prec@1 96.500 (96.500)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.063 (0.066)	Data 0.001 (0.004)	Loss 0.0977 (0.1172)	Prec@1 96.000 (95.866)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.063 (0.094)	Data 0.001 (0.006)	Loss 0.1953 (0.1291)	Prec@1 92.500 (95.458)
 * Training Prec@1 95.250
Test: [0/50]	Time 1.516 (1.516)	Loss 0.8444 (0.8444)	Prec@1 78.000 (78.000)
 * Testing Prec@1 76.100
Epoch: [18/80][0/250]	LR: 0.1	Time 0.464 (0.464)	Data 0.414 (0.414)	Loss 0.1292 (0.1292)	Prec@1 94.500 (94.500)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.063 (0.067)	Data 0.001 (0.005)	Loss 0.1216 (0.1035)	Prec@1 96.000 (96.317)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.062 (0.065)	Data 0.001 (0.003)	Loss 0.1831 (0.1139)	Prec@1 93.500 (95.973)
 * Training Prec@1 95.712
Test: [0/50]	Time 0.147 (0.147)	Loss 0.8938 (0.8938)	Prec@1 79.500 (79.500)
 * Testing Prec@1 76.620
Epoch: [19/80][0/250]	LR: 0.1	Time 0.137 (0.137)	Data 0.086 (0.086)	Loss 0.1214 (0.1214)	Prec@1 94.500 (94.500)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.064 (0.063)	Data 0.002 (0.002)	Loss 0.1076 (0.0966)	Prec@1 96.500 (96.594)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.063 (0.063)	Data 0.001 (0.002)	Loss 0.0876 (0.1031)	Prec@1 96.500 (96.430)
 * Training Prec@1 96.288
Test: [0/50]	Time 0.670 (0.670)	Loss 0.7768 (0.7768)	Prec@1 80.000 (80.000)
 * Testing Prec@1 79.910
Epoch: [20/80][0/250]	LR: 0.1	Time 0.527 (0.527)	Data 0.475 (0.475)	Loss 0.0810 (0.0810)	Prec@1 98.500 (98.500)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.063 (0.068)	Data 0.001 (0.006)	Loss 0.0813 (0.0880)	Prec@1 97.000 (96.911)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.063 (0.065)	Data 0.001 (0.004)	Loss 0.2027 (0.0998)	Prec@1 92.000 (96.450)
 * Training Prec@1 96.140
Test: [0/50]	Time 2.030 (2.030)	Loss 0.8116 (0.8116)	Prec@1 81.000 (81.000)
 * Testing Prec@1 78.950
Epoch: [21/80][0/250]	LR: 0.1	Time 0.401 (0.401)	Data 0.343 (0.343)	Loss 0.1254 (0.1254)	Prec@1 96.000 (96.000)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.064 (0.066)	Data 0.001 (0.005)	Loss 0.0807 (0.0760)	Prec@1 96.500 (97.401)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.062 (0.065)	Data 0.001 (0.003)	Loss 0.1770 (0.0850)	Prec@1 93.000 (97.062)
 * Training Prec@1 96.776
Test: [0/50]	Time 0.727 (0.727)	Loss 0.8192 (0.8192)	Prec@1 83.500 (83.500)
 * Testing Prec@1 79.780
Epoch: [22/80][0/250]	LR: 0.1	Time 1.145 (1.145)	Data 1.104 (1.104)	Loss 0.0632 (0.0632)	Prec@1 97.500 (97.500)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.065 (0.074)	Data 0.001 (0.012)	Loss 0.1106 (0.0840)	Prec@1 96.000 (97.000)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.063 (0.074)	Data 0.001 (0.012)	Loss 0.1459 (0.0853)	Prec@1 93.500 (96.965)
 * Training Prec@1 96.840
Test: [0/50]	Time 0.521 (0.521)	Loss 0.8420 (0.8420)	Prec@1 80.000 (80.000)
 * Testing Prec@1 79.610
Epoch: [23/80][0/250]	LR: 0.1	Time 0.531 (0.531)	Data 0.491 (0.491)	Loss 0.0553 (0.0553)	Prec@1 97.500 (97.500)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.063 (0.089)	Data 0.001 (0.028)	Loss 0.0707 (0.0693)	Prec@1 97.500 (97.663)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.062 (0.080)	Data 0.001 (0.019)	Loss 0.0862 (0.0757)	Prec@1 98.000 (97.361)
 * Training Prec@1 97.228
Test: [0/50]	Time 0.725 (0.725)	Loss 1.0190 (1.0190)	Prec@1 78.500 (78.500)
 * Testing Prec@1 79.060
Epoch: [24/80][0/250]	LR: 0.1	Time 0.619 (0.619)	Data 0.575 (0.575)	Loss 0.0275 (0.0275)	Prec@1 99.500 (99.500)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.063 (0.068)	Data 0.001 (0.007)	Loss 0.0558 (0.0684)	Prec@1 97.500 (97.663)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.063 (0.069)	Data 0.001 (0.008)	Loss 0.1303 (0.0775)	Prec@1 95.500 (97.343)
 * Training Prec@1 97.240
Test: [0/50]	Time 0.381 (0.381)	Loss 0.7881 (0.7881)	Prec@1 79.500 (79.500)
 * Testing Prec@1 77.630
Epoch: [25/80][0/250]	LR: 0.1	Time 0.118 (0.118)	Data 0.073 (0.073)	Loss 0.1215 (0.1215)	Prec@1 95.000 (95.000)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.064 (0.064)	Data 0.002 (0.003)	Loss 0.0799 (0.0612)	Prec@1 98.000 (97.906)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.063 (0.063)	Data 0.001 (0.002)	Loss 0.0552 (0.0689)	Prec@1 97.500 (97.669)
 * Training Prec@1 97.592
Test: [0/50]	Time 0.137 (0.137)	Loss 0.9454 (0.9454)	Prec@1 79.500 (79.500)
 * Testing Prec@1 78.460
Epoch: [26/80][0/250]	LR: 0.1	Time 0.787 (0.787)	Data 0.732 (0.732)	Loss 0.0391 (0.0391)	Prec@1 99.000 (99.000)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.064 (0.070)	Data 0.001 (0.009)	Loss 0.0837 (0.0745)	Prec@1 98.000 (97.381)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.062 (0.067)	Data 0.001 (0.005)	Loss 0.0863 (0.0778)	Prec@1 96.500 (97.299)
 * Training Prec@1 97.244
Test: [0/50]	Time 0.258 (0.258)	Loss 1.0743 (1.0743)	Prec@1 80.000 (80.000)
 * Testing Prec@1 77.990
Epoch: [27/80][0/250]	LR: 0.1	Time 0.900 (0.900)	Data 0.811 (0.811)	Loss 0.0601 (0.0601)	Prec@1 97.500 (97.500)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.063 (0.093)	Data 0.001 (0.009)	Loss 0.0332 (0.0596)	Prec@1 99.500 (98.059)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.064 (0.091)	Data 0.001 (0.005)	Loss 0.0909 (0.0707)	Prec@1 95.500 (97.617)
 * Training Prec@1 97.512
Test: [0/50]	Time 0.785 (0.785)	Loss 0.8343 (0.8343)	Prec@1 84.000 (84.000)
 * Testing Prec@1 79.230
Epoch: [28/80][0/250]	LR: 0.1	Time 1.395 (1.395)	Data 1.357 (1.357)	Loss 0.0647 (0.0647)	Prec@1 98.500 (98.500)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.063 (0.087)	Data 0.001 (0.020)	Loss 0.0556 (0.0587)	Prec@1 97.500 (97.941)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.063 (0.075)	Data 0.001 (0.011)	Loss 0.0909 (0.0659)	Prec@1 97.000 (97.699)
 * Training Prec@1 97.632
Test: [0/50]	Time 0.167 (0.167)	Loss 0.9973 (0.9973)	Prec@1 79.500 (79.500)
 * Testing Prec@1 79.800
Epoch: [29/80][0/250]	LR: 0.1	Time 1.169 (1.169)	Data 1.125 (1.125)	Loss 0.0297 (0.0297)	Prec@1 99.000 (99.000)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.063 (0.074)	Data 0.001 (0.012)	Loss 0.0881 (0.0571)	Prec@1 97.000 (98.045)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.063 (0.069)	Data 0.001 (0.007)	Loss 0.0764 (0.0648)	Prec@1 98.000 (97.741)
 * Training Prec@1 97.486
Test: [0/50]	Time 1.017 (1.017)	Loss 1.0725 (1.0725)	Prec@1 77.500 (77.500)
 * Testing Prec@1 78.330
Epoch: [30/80][0/250]	LR: 0.1	Time 0.426 (0.426)	Data 0.386 (0.386)	Loss 0.0782 (0.0782)	Prec@1 97.000 (97.000)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.063 (0.097)	Data 0.001 (0.005)	Loss 0.0201 (0.0709)	Prec@1 99.500 (97.609)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.063 (0.087)	Data 0.001 (0.003)	Loss 0.0764 (0.0724)	Prec@1 96.500 (97.475)
 * Training Prec@1 97.442
Test: [0/50]	Time 0.325 (0.325)	Loss 1.0689 (1.0689)	Prec@1 79.500 (79.500)
 * Testing Prec@1 78.820
Epoch: [31/80][0/250]	LR: 0.1	Time 0.441 (0.441)	Data 0.395 (0.395)	Loss 0.0465 (0.0465)	Prec@1 97.500 (97.500)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.063 (0.067)	Data 0.001 (0.005)	Loss 0.0555 (0.0450)	Prec@1 98.500 (98.460)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.063 (0.065)	Data 0.001 (0.003)	Loss 0.0373 (0.0487)	Prec@1 99.000 (98.318)
 * Training Prec@1 98.166
Test: [0/50]	Time 1.230 (1.230)	Loss 0.9600 (0.9600)	Prec@1 80.500 (80.500)
 * Testing Prec@1 80.930
Epoch: [32/80][0/250]	LR: 0.1	Time 0.452 (0.452)	Data 0.400 (0.400)	Loss 0.0221 (0.0221)	Prec@1 99.500 (99.500)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.063 (0.090)	Data 0.001 (0.029)	Loss 0.0694 (0.0522)	Prec@1 96.500 (98.228)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.063 (0.077)	Data 0.001 (0.015)	Loss 0.0577 (0.0599)	Prec@1 98.000 (97.913)
 * Training Prec@1 97.740
Test: [0/50]	Time 1.105 (1.105)	Loss 1.0488 (1.0488)	Prec@1 83.500 (83.500)
 * Testing Prec@1 80.320
Epoch: [33/80][0/250]	LR: 0.1	Time 0.326 (0.326)	Data 0.278 (0.278)	Loss 0.0378 (0.0378)	Prec@1 98.000 (98.000)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.063 (0.089)	Data 0.002 (0.004)	Loss 0.0423 (0.0688)	Prec@1 98.500 (97.559)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.063 (0.083)	Data 0.001 (0.003)	Loss 0.0571 (0.0787)	Prec@1 97.000 (97.199)
 * Training Prec@1 97.074
Test: [0/50]	Time 0.545 (0.545)	Loss 1.1319 (1.1319)	Prec@1 74.500 (74.500)
 * Testing Prec@1 80.000
Epoch: [34/80][0/250]	LR: 0.1	Time 0.458 (0.458)	Data 0.413 (0.413)	Loss 0.0882 (0.0882)	Prec@1 97.000 (97.000)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.063 (0.067)	Data 0.001 (0.005)	Loss 0.0768 (0.0597)	Prec@1 97.000 (97.965)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.063 (0.065)	Data 0.001 (0.003)	Loss 0.0649 (0.0586)	Prec@1 97.000 (97.985)
 * Training Prec@1 97.920
Test: [0/50]	Time 0.447 (0.447)	Loss 0.9854 (0.9854)	Prec@1 79.000 (79.000)
 * Testing Prec@1 80.150
Epoch: [35/80][0/250]	LR: 0.1	Time 0.606 (0.606)	Data 0.564 (0.564)	Loss 0.0247 (0.0247)	Prec@1 100.000 (100.000)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.063 (0.071)	Data 0.001 (0.010)	Loss 0.0367 (0.0417)	Prec@1 98.500 (98.678)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.064 (0.067)	Data 0.001 (0.006)	Loss 0.0620 (0.0499)	Prec@1 97.500 (98.366)
 * Training Prec@1 98.272
Test: [0/50]	Time 2.497 (2.497)	Loss 1.2641 (1.2641)	Prec@1 79.500 (79.500)
 * Testing Prec@1 79.330
Epoch: [36/80][0/250]	LR: 0.1	Time 0.172 (0.172)	Data 0.118 (0.118)	Loss 0.0149 (0.0149)	Prec@1 100.000 (100.000)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.063 (0.068)	Data 0.001 (0.007)	Loss 0.0304 (0.0394)	Prec@1 99.500 (98.658)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.063 (0.066)	Data 0.001 (0.004)	Loss 0.0757 (0.0387)	Prec@1 96.500 (98.652)
 * Training Prec@1 98.552
Test: [0/50]	Time 0.782 (0.782)	Loss 0.7864 (0.7864)	Prec@1 81.500 (81.500)
 * Testing Prec@1 80.820
Epoch: [37/80][0/250]	LR: 0.1	Time 0.489 (0.489)	Data 0.451 (0.451)	Loss 0.0461 (0.0461)	Prec@1 98.500 (98.500)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.062 (0.079)	Data 0.001 (0.018)	Loss 0.0807 (0.0604)	Prec@1 97.000 (97.832)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.062 (0.071)	Data 0.001 (0.010)	Loss 0.1217 (0.0643)	Prec@1 96.500 (97.744)
 * Training Prec@1 97.590
Test: [0/50]	Time 0.147 (0.147)	Loss 1.2458 (1.2458)	Prec@1 73.000 (73.000)
 * Testing Prec@1 77.640
Epoch: [38/80][0/250]	LR: 0.1	Time 0.130 (0.130)	Data 0.088 (0.088)	Loss 0.0898 (0.0898)	Prec@1 96.500 (96.500)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0590 (0.0712)	Prec@1 98.500 (97.520)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.062 (0.063)	Data 0.001 (0.002)	Loss 0.0753 (0.0669)	Prec@1 97.500 (97.709)
 * Training Prec@1 97.660
Test: [0/50]	Time 1.047 (1.047)	Loss 0.9334 (0.9334)	Prec@1 81.000 (81.000)
 * Testing Prec@1 80.650
Epoch: [39/80][0/250]	LR: 0.1	Time 0.282 (0.282)	Data 0.231 (0.231)	Loss 0.0487 (0.0487)	Prec@1 98.500 (98.500)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.063 (0.065)	Data 0.001 (0.004)	Loss 0.0427 (0.0434)	Prec@1 99.000 (98.485)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.063 (0.064)	Data 0.001 (0.003)	Loss 0.0817 (0.0498)	Prec@1 97.500 (98.266)
 * Training Prec@1 98.086
Test: [0/50]	Time 1.246 (1.246)	Loss 0.9254 (0.9254)	Prec@1 79.500 (79.500)
 * Testing Prec@1 81.310
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.126 (0.126)	Data 0.072 (0.072)	Loss 0.0347 (0.0347)	Prec@1 99.500 (99.500)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0083 (0.0264)	Prec@1 100.000 (99.173)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.063 (0.063)	Data 0.001 (0.002)	Loss 0.0121 (0.0208)	Prec@1 100.000 (99.413)
 * Training Prec@1 99.480
Test: [0/50]	Time 0.162 (0.162)	Loss 0.8124 (0.8124)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.260
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.179 (0.179)	Data 0.138 (0.138)	Loss 0.0036 (0.0036)	Prec@1 100.000 (100.000)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.062 (0.064)	Data 0.001 (0.003)	Loss 0.0044 (0.0053)	Prec@1 100.000 (99.980)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0029 (0.0052)	Prec@1 100.000 (99.968)
 * Training Prec@1 99.966
Test: [0/50]	Time 0.715 (0.715)	Loss 0.8143 (0.8143)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.320
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.130 (0.130)	Data 0.079 (0.079)	Loss 0.0037 (0.0037)	Prec@1 100.000 (100.000)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.481 (0.112)	Data 0.001 (0.006)	Loss 0.0034 (0.0038)	Prec@1 100.000 (99.995)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.063 (0.115)	Data 0.001 (0.004)	Loss 0.0025 (0.0037)	Prec@1 100.000 (99.995)
 * Training Prec@1 99.996
Test: [0/50]	Time 1.648 (1.648)	Loss 0.8110 (0.8110)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.310
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.117 (0.117)	Data 0.068 (0.068)	Loss 0.0021 (0.0021)	Prec@1 100.000 (100.000)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.063 (0.063)	Data 0.001 (0.002)	Loss 0.0025 (0.0027)	Prec@1 100.000 (100.000)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.063 (0.063)	Data 0.001 (0.002)	Loss 0.0050 (0.0027)	Prec@1 100.000 (99.998)
 * Training Prec@1 99.998
Test: [0/50]	Time 3.010 (3.010)	Loss 0.8141 (0.8141)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.580
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.560 (0.560)	Data 0.518 (0.518)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.075)	Data 0.001 (0.007)	Loss 0.0024 (0.0024)	Prec@1 100.000 (99.995)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.063 (0.069)	Data 0.001 (0.004)	Loss 0.0023 (0.0024)	Prec@1 100.000 (99.998)
 * Training Prec@1 99.998
Test: [0/50]	Time 0.329 (0.329)	Loss 0.8153 (0.8153)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.610
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.273 (0.273)	Data 0.233 (0.233)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.004)	Loss 0.0020 (0.0022)	Prec@1 100.000 (100.000)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.068)	Data 0.001 (0.003)	Loss 0.0019 (0.0021)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.799 (0.799)	Loss 0.8094 (0.8094)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.400
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.144 (0.144)	Data 0.094 (0.094)	Loss 0.0024 (0.0024)	Prec@1 100.000 (100.000)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0017 (0.0020)	Prec@1 100.000 (100.000)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0015 (0.0019)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.461 (0.461)	Loss 0.8227 (0.8227)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.510
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 1.926 (1.926)	Data 1.886 (1.886)	Loss 0.0030 (0.0030)	Prec@1 100.000 (100.000)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.063 (0.081)	Data 0.001 (0.020)	Loss 0.0023 (0.0018)	Prec@1 100.000 (100.000)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.072)	Data 0.001 (0.011)	Loss 0.0012 (0.0017)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 1.894 (1.894)	Loss 0.8196 (0.8196)	Prec@1 84.000 (84.000)
 * Testing Prec@1 84.710
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.522 (0.522)	Data 0.467 (0.467)	Loss 0.0014 (0.0014)	Prec@1 100.000 (100.000)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.063 (0.068)	Data 0.002 (0.006)	Loss 0.0012 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.063 (0.066)	Data 0.001 (0.004)	Loss 0.0019 (0.0016)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.150 (0.150)	Loss 0.8297 (0.8297)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.490
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.139 (0.139)	Data 0.076 (0.076)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0010 (0.0014)	Prec@1 100.000 (100.000)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0013 (0.0014)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.161 (0.161)	Loss 0.8278 (0.8278)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.510
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.154 (0.154)	Data 0.091 (0.091)	Loss 0.0017 (0.0017)	Prec@1 100.000 (100.000)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0015 (0.0015)	Prec@1 100.000 (99.995)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0011 (0.0015)	Prec@1 100.000 (99.998)
 * Training Prec@1 99.998
Test: [0/50]	Time 0.158 (0.158)	Loss 0.8160 (0.8160)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.510
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 0.154 (0.154)	Data 0.092 (0.092)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0010 (0.0014)	Prec@1 100.000 (100.000)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0011 (0.0014)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.158 (0.158)	Loss 0.8275 (0.8275)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.470
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.162 (0.162)	Data 0.098 (0.098)	Loss 0.0028 (0.0028)	Prec@1 100.000 (100.000)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.062 (0.064)	Data 0.003 (0.002)	Loss 0.0011 (0.0013)	Prec@1 100.000 (100.000)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.167 (0.167)	Loss 0.8207 (0.8207)	Prec@1 85.000 (85.000)
 * Testing Prec@1 84.450
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 0.154 (0.154)	Data 0.100 (0.100)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0014 (0.0013)	Prec@1 100.000 (100.000)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0007 (0.0013)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.158 (0.158)	Loss 0.8269 (0.8269)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.500
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.153 (0.153)	Data 0.091 (0.091)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0014 (0.0012)	Prec@1 100.000 (100.000)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0010 (0.0011)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.159 (0.159)	Loss 0.8188 (0.8188)	Prec@1 85.000 (85.000)
 * Testing Prec@1 84.490
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.143 (0.143)	Data 0.092 (0.092)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0013 (0.0011)	Prec@1 100.000 (100.000)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0016 (0.0011)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.152 (0.152)	Loss 0.8239 (0.8239)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.540
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.153 (0.153)	Data 0.095 (0.095)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0008 (0.0011)	Prec@1 100.000 (100.000)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0010 (0.0011)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.127 (0.127)	Loss 0.8341 (0.8341)	Prec@1 85.000 (85.000)
 * Testing Prec@1 84.580
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.153 (0.153)	Data 0.090 (0.090)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0008 (0.0011)	Prec@1 100.000 (100.000)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0009 (0.0010)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.101 (0.101)	Loss 0.8307 (0.8307)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.610
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.153 (0.153)	Data 0.091 (0.091)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0006 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0009 (0.0010)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.162 (0.162)	Loss 0.8221 (0.8221)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.570
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.122 (0.122)	Data 0.068 (0.068)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0009 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0007 (0.0010)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.153 (0.153)	Loss 0.8204 (0.8204)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.570
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.152 (0.152)	Data 0.096 (0.096)	Loss 0.0016 (0.0016)	Prec@1 100.000 (100.000)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0007 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0008 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.116 (0.116)	Loss 0.8336 (0.8336)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.590
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.155 (0.155)	Data 0.091 (0.091)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0008 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0014 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.160 (0.160)	Loss 0.8189 (0.8189)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.560
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.150 (0.150)	Data 0.090 (0.090)	Loss 0.0013 (0.0013)	Prec@1 100.000 (100.000)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0007 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0007 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.164 (0.164)	Loss 0.8241 (0.8241)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.550
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 0.117 (0.117)	Data 0.069 (0.069)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0014 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0006 (0.0010)	Prec@1 100.000 (99.998)
 * Training Prec@1 99.998
Test: [0/50]	Time 0.151 (0.151)	Loss 0.8258 (0.8258)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.570
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 0.146 (0.146)	Data 0.081 (0.081)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0011 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.154 (0.154)	Loss 0.8257 (0.8257)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.620
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.149 (0.149)	Data 0.096 (0.096)	Loss 0.0018 (0.0018)	Prec@1 100.000 (100.000)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.065)	Data 0.001 (0.002)	Loss 0.0007 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.003 (0.002)	Loss 0.0005 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.164 (0.164)	Loss 0.8309 (0.8309)	Prec@1 85.000 (85.000)
 * Testing Prec@1 84.580
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 0.155 (0.155)	Data 0.094 (0.094)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0005 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0006 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.156 (0.156)	Loss 0.8270 (0.8270)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.500
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.152 (0.152)	Data 0.090 (0.090)	Loss 0.0011 (0.0011)	Prec@1 100.000 (100.000)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0007 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0006 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.117 (0.117)	Loss 0.8279 (0.8279)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.530
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.140 (0.140)	Data 0.079 (0.079)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0011 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0007 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.114 (0.114)	Loss 0.8256 (0.8256)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.460
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 0.128 (0.128)	Data 0.066 (0.066)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0019 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0005 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.139 (0.139)	Loss 0.8279 (0.8279)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.500
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.170 (0.170)	Data 0.111 (0.111)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.003 (0.002)	Loss 0.0008 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0011 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.158 (0.158)	Loss 0.8249 (0.8249)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.480
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.153 (0.153)	Data 0.094 (0.094)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0008 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0014 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.176 (0.176)	Loss 0.8287 (0.8287)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.490
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.146 (0.146)	Data 0.094 (0.094)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.064)	Data 0.001 (0.002)	Loss 0.0010 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0011 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.161 (0.161)	Loss 0.8214 (0.8214)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.530
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 0.155 (0.155)	Data 0.092 (0.092)	Loss 0.0007 (0.0007)	Prec@1 100.000 (100.000)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.065)	Data 0.001 (0.002)	Loss 0.0007 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0007 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.158 (0.158)	Loss 0.8237 (0.8237)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.480
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.150 (0.150)	Data 0.087 (0.087)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0008 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.065 (0.064)	Data 0.001 (0.002)	Loss 0.0016 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.148 (0.148)	Loss 0.8326 (0.8326)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.530
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.154 (0.154)	Data 0.092 (0.092)	Loss 0.0010 (0.0010)	Prec@1 100.000 (100.000)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.065 (0.064)	Data 0.001 (0.002)	Loss 0.0015 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0020 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.114 (0.114)	Loss 0.8248 (0.8248)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.520
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.142 (0.142)	Data 0.093 (0.093)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0005 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0007 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.152 (0.152)	Loss 0.8252 (0.8252)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.580
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 0.153 (0.153)	Data 0.095 (0.095)	Loss 0.0008 (0.0008)	Prec@1 100.000 (100.000)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0019 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0007 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.153 (0.153)	Loss 0.8306 (0.8306)	Prec@1 86.000 (86.000)
 * Testing Prec@1 84.600
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.148 (0.148)	Data 0.086 (0.086)	Loss 0.0012 (0.0012)	Prec@1 100.000 (100.000)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0008 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0010 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.093 (0.093)	Loss 0.8264 (0.8264)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.520
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.165 (0.165)	Data 0.101 (0.101)	Loss 0.0006 (0.0006)	Prec@1 100.000 (100.000)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.063 (0.064)	Data 0.001 (0.002)	Loss 0.0009 (0.0009)	Prec@1 100.000 (100.000)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.064 (0.064)	Data 0.001 (0.002)	Loss 0.0013 (0.0009)	Prec@1 100.000 (100.000)
 * Training Prec@1 100.000
Test: [0/50]	Time 0.136 (0.136)	Loss 0.8193 (0.8193)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.510
