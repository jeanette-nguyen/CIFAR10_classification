Building CIFAR-10 data loader with 1 workers
Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10/cifar10-data/cifar-10-python.tar.gz
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'lenet'
Epoch: [0/80][0/250]	LR: 0.1	Time 0.297 (0.297)	Data 0.122 (0.122)	Loss 2.3020 (2.3020)	Prec@1 12.500 (12.500)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.055 (0.051)	Data 0.046 (0.044)	Loss 1.8157 (2.0917)	Prec@1 33.000 (21.114)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.054 (0.050)	Data 0.048 (0.043)	Loss 1.6930 (1.9895)	Prec@1 38.500 (25.269)
 * Training Prec@1 27.534
main.py:153: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.101 (0.101)	Loss 1.6859 (1.6859)	Prec@1 38.000 (38.000)
 * Testing Prec@1 38.710
main.py:190: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:191: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:199: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 0.130 (0.130)	Data 0.121 (0.121)	Loss 1.6265 (1.6265)	Prec@1 40.500 (40.500)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.047 (0.050)	Data 0.042 (0.044)	Loss 1.6177 (1.6780)	Prec@1 39.000 (37.168)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.046 (0.049)	Data 0.042 (0.043)	Loss 1.5519 (1.6484)	Prec@1 44.500 (38.448)
 * Training Prec@1 38.894
Test: [0/50]	Time 0.106 (0.106)	Loss 1.4405 (1.4405)	Prec@1 44.500 (44.500)
 * Testing Prec@1 46.120
Epoch: [2/80][0/250]	LR: 0.1	Time 0.158 (0.158)	Data 0.146 (0.146)	Loss 1.5531 (1.5531)	Prec@1 46.500 (46.500)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.051 (0.049)	Data 0.043 (0.044)	Loss 1.5326 (1.5655)	Prec@1 45.000 (43.079)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.048 (0.049)	Data 0.043 (0.043)	Loss 1.5398 (1.5547)	Prec@1 45.500 (43.413)
 * Training Prec@1 43.450
Test: [0/50]	Time 0.104 (0.104)	Loss 1.4173 (1.4173)	Prec@1 47.000 (47.000)
 * Testing Prec@1 45.310
Epoch: [3/80][0/250]	LR: 0.1	Time 0.154 (0.154)	Data 0.141 (0.141)	Loss 1.5542 (1.5542)	Prec@1 44.000 (44.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.047 (0.050)	Data 0.040 (0.044)	Loss 1.6861 (1.5117)	Prec@1 40.500 (45.188)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.057 (0.048)	Data 0.050 (0.043)	Loss 1.5761 (1.5100)	Prec@1 44.000 (45.483)
 * Training Prec@1 45.744
Test: [0/50]	Time 0.101 (0.101)	Loss 1.4225 (1.4225)	Prec@1 51.500 (51.500)
 * Testing Prec@1 48.610
Epoch: [4/80][0/250]	LR: 0.1	Time 0.176 (0.176)	Data 0.163 (0.163)	Loss 1.7675 (1.7675)	Prec@1 37.000 (37.000)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.041 (0.049)	Data 0.036 (0.043)	Loss 1.5294 (1.5022)	Prec@1 45.500 (45.970)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.049 (0.049)	Data 0.044 (0.043)	Loss 1.4199 (1.4742)	Prec@1 49.500 (46.801)
 * Training Prec@1 46.650
Test: [0/50]	Time 0.142 (0.142)	Loss 1.3918 (1.3918)	Prec@1 47.500 (47.500)
 * Testing Prec@1 50.570
Epoch: [5/80][0/250]	LR: 0.1	Time 0.174 (0.174)	Data 0.163 (0.163)	Loss 1.4028 (1.4028)	Prec@1 51.500 (51.500)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.061 (0.050)	Data 0.054 (0.044)	Loss 1.3116 (1.4350)	Prec@1 53.000 (49.069)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.043 (0.048)	Data 0.039 (0.042)	Loss 1.4003 (1.4272)	Prec@1 47.000 (49.216)
 * Training Prec@1 49.184
Test: [0/50]	Time 0.122 (0.122)	Loss 1.3669 (1.3669)	Prec@1 51.500 (51.500)
 * Testing Prec@1 54.200
Epoch: [6/80][0/250]	LR: 0.1	Time 0.170 (0.170)	Data 0.158 (0.158)	Loss 1.4338 (1.4338)	Prec@1 47.000 (47.000)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.044 (0.049)	Data 0.039 (0.042)	Loss 1.6780 (1.3829)	Prec@1 47.000 (50.658)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.056 (0.048)	Data 0.049 (0.042)	Loss 1.5631 (1.3915)	Prec@1 47.500 (50.353)
 * Training Prec@1 50.432
Test: [0/50]	Time 0.089 (0.089)	Loss 1.3003 (1.3003)	Prec@1 57.000 (57.000)
 * Testing Prec@1 55.730
Epoch: [7/80][0/250]	LR: 0.1	Time 0.181 (0.181)	Data 0.170 (0.170)	Loss 1.3554 (1.3554)	Prec@1 51.000 (51.000)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.043 (0.050)	Data 0.037 (0.044)	Loss 1.4210 (1.3810)	Prec@1 49.500 (50.851)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.070 (0.049)	Data 0.064 (0.043)	Loss 1.5059 (1.3865)	Prec@1 42.500 (50.677)
 * Training Prec@1 50.640
Test: [0/50]	Time 0.101 (0.101)	Loss 1.2501 (1.2501)	Prec@1 57.500 (57.500)
 * Testing Prec@1 55.370
Epoch: [8/80][0/250]	LR: 0.1	Time 0.195 (0.195)	Data 0.180 (0.180)	Loss 1.4396 (1.4396)	Prec@1 45.500 (45.500)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.048 (0.050)	Data 0.042 (0.043)	Loss 1.2957 (1.3630)	Prec@1 54.000 (52.178)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.047 (0.049)	Data 0.041 (0.043)	Loss 1.4955 (1.3720)	Prec@1 46.000 (51.781)
 * Training Prec@1 51.576
Test: [0/50]	Time 0.166 (0.166)	Loss 1.2728 (1.2728)	Prec@1 55.000 (55.000)
 * Testing Prec@1 54.610
Epoch: [9/80][0/250]	LR: 0.1	Time 0.175 (0.175)	Data 0.162 (0.162)	Loss 1.2389 (1.2389)	Prec@1 55.000 (55.000)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.048 (0.049)	Data 0.043 (0.043)	Loss 1.4483 (1.3392)	Prec@1 48.500 (52.842)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.048 (0.048)	Data 0.043 (0.042)	Loss 1.4254 (1.3639)	Prec@1 48.000 (51.920)
 * Training Prec@1 52.196
Test: [0/50]	Time 0.121 (0.121)	Loss 1.3857 (1.3857)	Prec@1 48.500 (48.500)
 * Testing Prec@1 50.330
Epoch: [10/80][0/250]	LR: 0.1	Time 0.142 (0.142)	Data 0.132 (0.132)	Loss 1.2444 (1.2444)	Prec@1 55.000 (55.000)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.048 (0.049)	Data 0.043 (0.043)	Loss 1.2698 (1.3458)	Prec@1 60.000 (52.649)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.049 (0.049)	Data 0.042 (0.042)	Loss 1.3512 (1.3306)	Prec@1 57.500 (53.261)
 * Training Prec@1 53.198
Test: [0/50]	Time 0.141 (0.141)	Loss 1.2659 (1.2659)	Prec@1 56.000 (56.000)
 * Testing Prec@1 56.470
Epoch: [11/80][0/250]	LR: 0.1	Time 0.137 (0.137)	Data 0.127 (0.127)	Loss 1.4459 (1.4459)	Prec@1 49.000 (49.000)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.042 (0.047)	Data 0.038 (0.041)	Loss 1.2227 (1.3321)	Prec@1 55.000 (53.193)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.045 (0.046)	Data 0.040 (0.040)	Loss 1.3964 (1.3390)	Prec@1 49.000 (53.010)
 * Training Prec@1 52.946
Test: [0/50]	Time 0.152 (0.152)	Loss 1.3410 (1.3410)	Prec@1 52.000 (52.000)
 * Testing Prec@1 55.270
Epoch: [12/80][0/250]	LR: 0.1	Time 0.184 (0.184)	Data 0.173 (0.173)	Loss 1.3850 (1.3850)	Prec@1 55.000 (55.000)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.044 (0.048)	Data 0.039 (0.042)	Loss 1.4066 (1.3347)	Prec@1 52.500 (53.683)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.053 (0.049)	Data 0.047 (0.043)	Loss 1.3387 (1.3268)	Prec@1 50.000 (53.945)
 * Training Prec@1 53.818
Test: [0/50]	Time 0.146 (0.146)	Loss 1.2112 (1.2112)	Prec@1 54.500 (54.500)
 * Testing Prec@1 57.990
Epoch: [13/80][0/250]	LR: 0.1	Time 0.168 (0.168)	Data 0.156 (0.156)	Loss 1.2843 (1.2843)	Prec@1 51.000 (51.000)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.044 (0.048)	Data 0.038 (0.042)	Loss 1.3322 (1.3122)	Prec@1 53.000 (54.599)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.042 (0.047)	Data 0.035 (0.041)	Loss 1.3022 (1.3093)	Prec@1 56.500 (54.821)
 * Training Prec@1 54.822
Test: [0/50]	Time 0.110 (0.110)	Loss 1.2894 (1.2894)	Prec@1 57.500 (57.500)
 * Testing Prec@1 58.270
Epoch: [14/80][0/250]	LR: 0.1	Time 0.179 (0.179)	Data 0.165 (0.165)	Loss 1.2966 (1.2966)	Prec@1 49.500 (49.500)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.047 (0.047)	Data 0.042 (0.041)	Loss 1.3906 (1.3247)	Prec@1 56.000 (54.188)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.051 (0.048)	Data 0.044 (0.042)	Loss 1.3293 (1.3301)	Prec@1 55.000 (53.970)
 * Training Prec@1 54.304
Test: [0/50]	Time 0.170 (0.170)	Loss 1.1947 (1.1947)	Prec@1 58.000 (58.000)
 * Testing Prec@1 57.720
Epoch: [15/80][0/250]	LR: 0.1	Time 0.150 (0.150)	Data 0.138 (0.138)	Loss 1.4635 (1.4635)	Prec@1 48.000 (48.000)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.044 (0.051)	Data 0.038 (0.044)	Loss 1.3634 (1.3088)	Prec@1 50.500 (54.708)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.049 (0.048)	Data 0.041 (0.042)	Loss 1.2474 (1.2932)	Prec@1 55.500 (55.246)
 * Training Prec@1 54.992
Test: [0/50]	Time 0.106 (0.106)	Loss 1.2768 (1.2768)	Prec@1 56.500 (56.500)
 * Testing Prec@1 56.650
Epoch: [16/80][0/250]	LR: 0.1	Time 0.156 (0.156)	Data 0.145 (0.145)	Loss 1.3555 (1.3555)	Prec@1 52.000 (52.000)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.043 (0.049)	Data 0.038 (0.043)	Loss 1.2730 (1.2802)	Prec@1 55.500 (55.465)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.047 (0.049)	Data 0.040 (0.043)	Loss 1.1426 (1.3016)	Prec@1 60.500 (54.943)
 * Training Prec@1 54.854
Test: [0/50]	Time 0.158 (0.158)	Loss 1.2825 (1.2825)	Prec@1 58.000 (58.000)
 * Testing Prec@1 59.510
Epoch: [17/80][0/250]	LR: 0.1	Time 0.174 (0.174)	Data 0.162 (0.162)	Loss 1.2974 (1.2974)	Prec@1 60.000 (60.000)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.042 (0.048)	Data 0.035 (0.042)	Loss 1.3896 (1.3132)	Prec@1 55.500 (54.366)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.044 (0.046)	Data 0.039 (0.040)	Loss 1.3913 (1.3122)	Prec@1 53.000 (54.545)
 * Training Prec@1 54.816
Test: [0/50]	Time 0.142 (0.142)	Loss 1.1504 (1.1504)	Prec@1 62.000 (62.000)
 * Testing Prec@1 58.800
Epoch: [18/80][0/250]	LR: 0.1	Time 0.159 (0.159)	Data 0.149 (0.149)	Loss 1.2817 (1.2817)	Prec@1 58.000 (58.000)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.050 (0.050)	Data 0.044 (0.043)	Loss 1.3681 (1.2957)	Prec@1 52.000 (55.183)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.047 (0.048)	Data 0.040 (0.042)	Loss 1.2934 (1.2891)	Prec@1 56.500 (55.460)
 * Training Prec@1 55.528
Test: [0/50]	Time 0.156 (0.156)	Loss 1.1523 (1.1523)	Prec@1 63.500 (63.500)
 * Testing Prec@1 59.580
Epoch: [19/80][0/250]	LR: 0.1	Time 0.143 (0.143)	Data 0.132 (0.132)	Loss 1.2550 (1.2550)	Prec@1 56.500 (56.500)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.062 (0.050)	Data 0.057 (0.043)	Loss 1.5365 (1.2873)	Prec@1 52.000 (55.347)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.041 (0.048)	Data 0.036 (0.042)	Loss 1.4171 (1.2890)	Prec@1 54.500 (55.119)
 * Training Prec@1 55.192
Test: [0/50]	Time 0.148 (0.148)	Loss 1.2863 (1.2863)	Prec@1 53.500 (53.500)
 * Testing Prec@1 59.050
Epoch: [20/80][0/250]	LR: 0.1	Time 0.164 (0.164)	Data 0.150 (0.150)	Loss 1.2210 (1.2210)	Prec@1 58.500 (58.500)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.040 (0.050)	Data 0.035 (0.044)	Loss 1.3174 (1.2822)	Prec@1 57.000 (55.287)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.042 (0.047)	Data 0.037 (0.042)	Loss 1.2916 (1.2809)	Prec@1 50.000 (55.657)
 * Training Prec@1 55.902
Test: [0/50]	Time 0.146 (0.146)	Loss 1.2787 (1.2787)	Prec@1 58.000 (58.000)
 * Testing Prec@1 60.040
Epoch: [21/80][0/250]	LR: 0.1	Time 0.163 (0.163)	Data 0.152 (0.152)	Loss 1.2126 (1.2126)	Prec@1 60.000 (60.000)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.045 (0.047)	Data 0.039 (0.042)	Loss 1.2283 (1.2539)	Prec@1 54.000 (56.728)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.046 (0.047)	Data 0.041 (0.041)	Loss 1.2382 (1.2562)	Prec@1 55.000 (56.721)
 * Training Prec@1 56.692
Test: [0/50]	Time 0.149 (0.149)	Loss 1.3489 (1.3489)	Prec@1 57.500 (57.500)
 * Testing Prec@1 56.800
Epoch: [22/80][0/250]	LR: 0.1	Time 0.126 (0.126)	Data 0.116 (0.116)	Loss 1.1879 (1.1879)	Prec@1 61.500 (61.500)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.045 (0.047)	Data 0.039 (0.041)	Loss 1.2312 (1.2952)	Prec@1 58.000 (55.450)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.044 (0.047)	Data 0.037 (0.041)	Loss 1.1201 (1.2908)	Prec@1 56.500 (55.331)
 * Training Prec@1 55.436
Test: [0/50]	Time 0.120 (0.120)	Loss 1.3289 (1.3289)	Prec@1 54.000 (54.000)
 * Testing Prec@1 57.730
Epoch: [23/80][0/250]	LR: 0.1	Time 0.162 (0.162)	Data 0.150 (0.150)	Loss 1.2530 (1.2530)	Prec@1 54.500 (54.500)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.045 (0.050)	Data 0.038 (0.044)	Loss 1.2197 (1.2547)	Prec@1 58.500 (56.743)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.042 (0.050)	Data 0.037 (0.044)	Loss 1.3555 (1.2686)	Prec@1 55.500 (56.142)
 * Training Prec@1 56.074
Test: [0/50]	Time 0.126 (0.126)	Loss 1.3943 (1.3943)	Prec@1 54.500 (54.500)
 * Testing Prec@1 57.140
Epoch: [24/80][0/250]	LR: 0.1	Time 0.134 (0.134)	Data 0.122 (0.122)	Loss 1.4220 (1.4220)	Prec@1 51.000 (51.000)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.045 (0.048)	Data 0.039 (0.042)	Loss 1.2274 (1.2607)	Prec@1 60.500 (56.465)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.043 (0.048)	Data 0.038 (0.042)	Loss 1.3296 (1.2629)	Prec@1 53.500 (56.137)
 * Training Prec@1 56.128
Test: [0/50]	Time 0.110 (0.110)	Loss 1.1874 (1.1874)	Prec@1 61.000 (61.000)
 * Testing Prec@1 60.760
Epoch: [25/80][0/250]	LR: 0.1	Time 0.164 (0.164)	Data 0.152 (0.152)	Loss 1.2775 (1.2775)	Prec@1 51.000 (51.000)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.054 (0.048)	Data 0.047 (0.042)	Loss 1.3902 (1.2772)	Prec@1 55.500 (55.634)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.048 (0.047)	Data 0.044 (0.041)	Loss 1.2739 (1.2679)	Prec@1 61.000 (56.388)
 * Training Prec@1 56.282
Test: [0/50]	Time 0.124 (0.124)	Loss 1.1606 (1.1606)	Prec@1 60.000 (60.000)
 * Testing Prec@1 61.030
Epoch: [26/80][0/250]	LR: 0.1	Time 0.146 (0.146)	Data 0.137 (0.137)	Loss 1.3157 (1.3157)	Prec@1 51.000 (51.000)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.045 (0.049)	Data 0.039 (0.043)	Loss 1.1299 (1.2491)	Prec@1 62.500 (57.025)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.058 (0.048)	Data 0.052 (0.041)	Loss 1.2882 (1.2492)	Prec@1 56.500 (56.915)
 * Training Prec@1 56.680
Test: [0/50]	Time 0.168 (0.168)	Loss 1.3201 (1.3201)	Prec@1 55.000 (55.000)
 * Testing Prec@1 58.330
Epoch: [27/80][0/250]	LR: 0.1	Time 0.179 (0.179)	Data 0.167 (0.167)	Loss 1.3031 (1.3031)	Prec@1 55.000 (55.000)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.044 (0.048)	Data 0.037 (0.041)	Loss 1.1417 (1.2507)	Prec@1 57.000 (57.089)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.044 (0.048)	Data 0.036 (0.042)	Loss 1.2747 (1.2453)	Prec@1 56.500 (57.226)
 * Training Prec@1 57.122
Test: [0/50]	Time 0.116 (0.116)	Loss 1.1332 (1.1332)	Prec@1 59.500 (59.500)
 * Testing Prec@1 62.270
Epoch: [28/80][0/250]	LR: 0.1	Time 0.120 (0.120)	Data 0.109 (0.109)	Loss 1.1210 (1.1210)	Prec@1 57.000 (57.000)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.043 (0.052)	Data 0.036 (0.045)	Loss 1.2592 (1.2314)	Prec@1 58.500 (57.347)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.046 (0.050)	Data 0.040 (0.043)	Loss 1.2283 (1.2405)	Prec@1 59.000 (57.119)
 * Training Prec@1 56.892
Test: [0/50]	Time 0.158 (0.158)	Loss 1.1871 (1.1871)	Prec@1 61.000 (61.000)
 * Testing Prec@1 59.550
Epoch: [29/80][0/250]	LR: 0.1	Time 0.156 (0.156)	Data 0.144 (0.144)	Loss 1.2611 (1.2611)	Prec@1 51.500 (51.500)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.051 (0.047)	Data 0.044 (0.041)	Loss 1.2216 (1.2963)	Prec@1 60.000 (55.802)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.043 (0.047)	Data 0.037 (0.041)	Loss 1.3684 (1.2675)	Prec@1 53.500 (56.560)
 * Training Prec@1 56.524
Test: [0/50]	Time 0.125 (0.125)	Loss 1.2556 (1.2556)	Prec@1 53.000 (53.000)
 * Testing Prec@1 58.410
Epoch: [30/80][0/250]	LR: 0.1	Time 0.185 (0.185)	Data 0.174 (0.174)	Loss 1.3292 (1.3292)	Prec@1 55.500 (55.500)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.046 (0.047)	Data 0.039 (0.041)	Loss 1.3541 (1.2331)	Prec@1 50.500 (57.416)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.045 (0.046)	Data 0.039 (0.040)	Loss 1.2525 (1.2323)	Prec@1 56.500 (57.759)
 * Training Prec@1 57.556
Test: [0/50]	Time 0.108 (0.108)	Loss 1.1388 (1.1388)	Prec@1 61.500 (61.500)
 * Testing Prec@1 61.330
Epoch: [31/80][0/250]	LR: 0.1	Time 0.139 (0.139)	Data 0.128 (0.128)	Loss 1.1990 (1.1990)	Prec@1 58.500 (58.500)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.043 (0.047)	Data 0.039 (0.042)	Loss 1.1213 (1.2506)	Prec@1 61.500 (57.371)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.043 (0.046)	Data 0.039 (0.041)	Loss 1.1159 (1.2369)	Prec@1 61.000 (57.627)
 * Training Prec@1 57.450
Test: [0/50]	Time 0.114 (0.114)	Loss 1.2240 (1.2240)	Prec@1 57.000 (57.000)
 * Testing Prec@1 57.100
Epoch: [32/80][0/250]	LR: 0.1	Time 0.133 (0.133)	Data 0.121 (0.121)	Loss 1.3976 (1.3976)	Prec@1 49.500 (49.500)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.050 (0.046)	Data 0.044 (0.040)	Loss 1.3220 (1.2666)	Prec@1 53.500 (56.480)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.044 (0.046)	Data 0.038 (0.040)	Loss 1.3993 (1.2604)	Prec@1 55.000 (56.654)
 * Training Prec@1 56.778
Test: [0/50]	Time 0.144 (0.144)	Loss 1.3015 (1.3015)	Prec@1 58.000 (58.000)
 * Testing Prec@1 60.580
Epoch: [33/80][0/250]	LR: 0.1	Time 0.163 (0.163)	Data 0.148 (0.148)	Loss 1.3436 (1.3436)	Prec@1 52.000 (52.000)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.043 (0.050)	Data 0.035 (0.045)	Loss 1.2455 (1.2459)	Prec@1 58.000 (56.975)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.049 (0.049)	Data 0.044 (0.044)	Loss 1.2831 (1.2535)	Prec@1 50.000 (56.878)
 * Training Prec@1 57.322
Test: [0/50]	Time 0.157 (0.157)	Loss 1.0914 (1.0914)	Prec@1 61.500 (61.500)
 * Testing Prec@1 61.330
Epoch: [34/80][0/250]	LR: 0.1	Time 0.157 (0.157)	Data 0.144 (0.144)	Loss 1.2166 (1.2166)	Prec@1 60.500 (60.500)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.047 (0.048)	Data 0.041 (0.043)	Loss 1.3334 (1.2261)	Prec@1 53.000 (58.035)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.047 (0.048)	Data 0.041 (0.042)	Loss 1.2803 (1.2303)	Prec@1 56.000 (58.077)
 * Training Prec@1 58.000
Test: [0/50]	Time 0.109 (0.109)	Loss 1.1746 (1.1746)	Prec@1 62.000 (62.000)
 * Testing Prec@1 62.460
Epoch: [35/80][0/250]	LR: 0.1	Time 0.188 (0.188)	Data 0.177 (0.177)	Loss 1.1596 (1.1596)	Prec@1 60.500 (60.500)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.047 (0.051)	Data 0.041 (0.045)	Loss 1.1148 (1.2056)	Prec@1 63.000 (59.257)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.044 (0.048)	Data 0.039 (0.043)	Loss 1.4109 (1.2213)	Prec@1 55.500 (58.201)
 * Training Prec@1 57.966
Test: [0/50]	Time 0.167 (0.167)	Loss 1.1066 (1.1066)	Prec@1 59.000 (59.000)
 * Testing Prec@1 60.830
Epoch: [36/80][0/250]	LR: 0.1	Time 0.166 (0.166)	Data 0.156 (0.156)	Loss 1.0528 (1.0528)	Prec@1 63.000 (63.000)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.045 (0.047)	Data 0.037 (0.041)	Loss 1.3383 (1.2354)	Prec@1 59.500 (58.025)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.042 (0.047)	Data 0.037 (0.041)	Loss 1.2266 (1.2179)	Prec@1 56.500 (58.478)
 * Training Prec@1 58.334
Test: [0/50]	Time 0.104 (0.104)	Loss 1.1646 (1.1646)	Prec@1 61.500 (61.500)
 * Testing Prec@1 62.600
Epoch: [37/80][0/250]	LR: 0.1	Time 0.165 (0.165)	Data 0.155 (0.155)	Loss 1.2559 (1.2559)	Prec@1 57.000 (57.000)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.047 (0.048)	Data 0.042 (0.042)	Loss 1.1610 (1.2234)	Prec@1 59.000 (58.475)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.043 (0.047)	Data 0.038 (0.041)	Loss 1.1639 (1.2354)	Prec@1 59.000 (58.157)
 * Training Prec@1 58.254
Test: [0/50]	Time 0.113 (0.113)	Loss 1.1351 (1.1351)	Prec@1 63.500 (63.500)
 * Testing Prec@1 59.760
Epoch: [38/80][0/250]	LR: 0.1	Time 0.161 (0.161)	Data 0.151 (0.151)	Loss 1.3059 (1.3059)	Prec@1 58.500 (58.500)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.043 (0.049)	Data 0.039 (0.043)	Loss 1.2154 (1.2363)	Prec@1 59.000 (57.787)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.045 (0.047)	Data 0.040 (0.042)	Loss 1.2634 (1.2330)	Prec@1 58.000 (57.945)
 * Training Prec@1 58.064
Test: [0/50]	Time 0.124 (0.124)	Loss 1.2954 (1.2954)	Prec@1 54.000 (54.000)
 * Testing Prec@1 61.270
Epoch: [39/80][0/250]	LR: 0.1	Time 0.154 (0.154)	Data 0.145 (0.145)	Loss 1.1845 (1.1845)	Prec@1 60.500 (60.500)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.049 (0.052)	Data 0.043 (0.046)	Loss 1.3276 (1.2254)	Prec@1 54.500 (58.599)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.041 (0.049)	Data 0.036 (0.044)	Loss 1.2307 (1.2206)	Prec@1 56.500 (58.301)
 * Training Prec@1 58.502
Test: [0/50]	Time 0.119 (0.119)	Loss 1.0935 (1.0935)	Prec@1 63.500 (63.500)
 * Testing Prec@1 60.390
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.164 (0.164)	Data 0.154 (0.154)	Loss 1.1995 (1.1995)	Prec@1 59.500 (59.500)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.076 (0.049)	Data 0.070 (0.044)	Loss 1.0833 (1.0717)	Prec@1 63.500 (62.876)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.048 (0.049)	Data 0.043 (0.044)	Loss 0.9619 (1.0536)	Prec@1 65.000 (63.913)
 * Training Prec@1 63.932
Test: [0/50]	Time 0.164 (0.164)	Loss 0.9450 (0.9450)	Prec@1 70.500 (70.500)
 * Testing Prec@1 67.630
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.180 (0.180)	Data 0.169 (0.169)	Loss 0.9733 (0.9733)	Prec@1 65.000 (65.000)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.044 (0.048)	Data 0.040 (0.042)	Loss 0.9193 (1.0096)	Prec@1 67.500 (65.035)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.052 (0.049)	Data 0.046 (0.043)	Loss 1.1261 (1.0023)	Prec@1 61.500 (65.311)
 * Training Prec@1 65.414
Test: [0/50]	Time 0.108 (0.108)	Loss 0.9043 (0.9043)	Prec@1 70.500 (70.500)
 * Testing Prec@1 67.870
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.172 (0.172)	Data 0.163 (0.163)	Loss 1.0518 (1.0518)	Prec@1 62.000 (62.000)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.041 (0.047)	Data 0.037 (0.041)	Loss 0.9715 (0.9963)	Prec@1 66.500 (65.812)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.042 (0.046)	Data 0.037 (0.040)	Loss 0.9591 (0.9902)	Prec@1 63.500 (65.915)
 * Training Prec@1 65.830
Test: [0/50]	Time 0.120 (0.120)	Loss 0.9158 (0.9158)	Prec@1 68.000 (68.000)
 * Testing Prec@1 68.130
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.126 (0.126)	Data 0.111 (0.111)	Loss 1.1630 (1.1630)	Prec@1 61.000 (61.000)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.044 (0.047)	Data 0.038 (0.041)	Loss 1.1017 (0.9740)	Prec@1 57.500 (66.361)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.045 (0.048)	Data 0.039 (0.042)	Loss 0.9820 (0.9731)	Prec@1 63.000 (66.224)
 * Training Prec@1 66.266
Test: [0/50]	Time 0.099 (0.099)	Loss 0.9169 (0.9169)	Prec@1 67.500 (67.500)
 * Testing Prec@1 68.900
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.144 (0.144)	Data 0.133 (0.133)	Loss 0.8923 (0.8923)	Prec@1 69.500 (69.500)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.050 (0.048)	Data 0.045 (0.043)	Loss 0.9682 (0.9646)	Prec@1 67.500 (66.668)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.046 (0.049)	Data 0.041 (0.043)	Loss 1.0855 (0.9646)	Prec@1 63.000 (66.617)
 * Training Prec@1 66.590
Test: [0/50]	Time 0.114 (0.114)	Loss 0.9062 (0.9062)	Prec@1 69.000 (69.000)
 * Testing Prec@1 69.090
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.180 (0.180)	Data 0.169 (0.169)	Loss 1.0872 (1.0872)	Prec@1 63.000 (63.000)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.044 (0.048)	Data 0.039 (0.042)	Loss 1.0116 (0.9631)	Prec@1 65.000 (66.351)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.050 (0.048)	Data 0.043 (0.042)	Loss 1.0478 (0.9569)	Prec@1 62.000 (66.567)
 * Training Prec@1 66.460
Test: [0/50]	Time 0.139 (0.139)	Loss 0.8840 (0.8840)	Prec@1 67.500 (67.500)
 * Testing Prec@1 69.190
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.149 (0.149)	Data 0.137 (0.137)	Loss 0.9250 (0.9250)	Prec@1 67.500 (67.500)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.051 (0.050)	Data 0.046 (0.043)	Loss 1.0214 (0.9615)	Prec@1 63.500 (66.594)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.047 (0.049)	Data 0.043 (0.043)	Loss 0.9295 (0.9573)	Prec@1 65.000 (66.639)
 * Training Prec@1 66.744
Test: [0/50]	Time 0.165 (0.165)	Loss 0.9137 (0.9137)	Prec@1 69.500 (69.500)
 * Testing Prec@1 69.160
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 0.163 (0.163)	Data 0.153 (0.153)	Loss 0.8762 (0.8762)	Prec@1 73.000 (73.000)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.051 (0.049)	Data 0.046 (0.043)	Loss 1.0604 (0.9504)	Prec@1 65.500 (66.901)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.051 (0.048)	Data 0.046 (0.042)	Loss 0.8969 (0.9470)	Prec@1 71.500 (67.032)
 * Training Prec@1 67.220
Test: [0/50]	Time 0.166 (0.166)	Loss 0.9060 (0.9060)	Prec@1 67.500 (67.500)
 * Testing Prec@1 68.900
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.169 (0.169)	Data 0.159 (0.159)	Loss 0.9307 (0.9307)	Prec@1 64.000 (64.000)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.077 (0.048)	Data 0.071 (0.043)	Loss 0.9811 (0.9400)	Prec@1 68.500 (67.495)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.045 (0.048)	Data 0.040 (0.043)	Loss 0.9714 (0.9420)	Prec@1 60.000 (67.393)
 * Training Prec@1 67.192
Test: [0/50]	Time 0.114 (0.114)	Loss 0.8997 (0.8997)	Prec@1 67.500 (67.500)
 * Testing Prec@1 70.250
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.152 (0.152)	Data 0.139 (0.139)	Loss 0.9145 (0.9145)	Prec@1 69.000 (69.000)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.042 (0.048)	Data 0.037 (0.042)	Loss 0.8771 (0.9356)	Prec@1 70.500 (67.540)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.047 (0.046)	Data 0.042 (0.041)	Loss 1.0400 (0.9411)	Prec@1 64.500 (67.246)
 * Training Prec@1 67.160
Test: [0/50]	Time 0.106 (0.106)	Loss 0.8604 (0.8604)	Prec@1 71.000 (71.000)
 * Testing Prec@1 70.240
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.184 (0.184)	Data 0.173 (0.173)	Loss 0.9060 (0.9060)	Prec@1 69.500 (69.500)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.056 (0.048)	Data 0.051 (0.042)	Loss 0.8656 (0.9204)	Prec@1 74.500 (67.708)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.048 (0.048)	Data 0.041 (0.042)	Loss 0.9362 (0.9313)	Prec@1 65.000 (67.500)
 * Training Prec@1 67.528
Test: [0/50]	Time 0.148 (0.148)	Loss 0.8676 (0.8676)	Prec@1 70.000 (70.000)
 * Testing Prec@1 70.000
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 0.185 (0.185)	Data 0.176 (0.176)	Loss 0.9809 (0.9809)	Prec@1 65.000 (65.000)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.048 (0.051)	Data 0.038 (0.045)	Loss 0.9171 (0.9148)	Prec@1 65.500 (67.861)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.050 (0.050)	Data 0.043 (0.044)	Loss 0.9743 (0.9206)	Prec@1 63.000 (67.851)
 * Training Prec@1 67.812
Test: [0/50]	Time 0.177 (0.177)	Loss 0.8549 (0.8549)	Prec@1 68.000 (68.000)
 * Testing Prec@1 70.190
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.172 (0.172)	Data 0.161 (0.161)	Loss 0.9200 (0.9200)	Prec@1 69.500 (69.500)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.047 (0.051)	Data 0.043 (0.045)	Loss 0.8560 (0.9267)	Prec@1 71.000 (67.515)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.049 (0.050)	Data 0.042 (0.044)	Loss 0.8670 (0.9255)	Prec@1 68.000 (67.567)
 * Training Prec@1 67.686
Test: [0/50]	Time 0.118 (0.118)	Loss 0.8511 (0.8511)	Prec@1 70.000 (70.000)
 * Testing Prec@1 70.460
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 0.129 (0.129)	Data 0.117 (0.117)	Loss 0.9083 (0.9083)	Prec@1 72.000 (72.000)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.047 (0.050)	Data 0.043 (0.044)	Loss 0.9472 (0.9363)	Prec@1 66.500 (66.950)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.044 (0.049)	Data 0.040 (0.043)	Loss 0.8847 (0.9215)	Prec@1 70.500 (67.684)
 * Training Prec@1 67.882
Test: [0/50]	Time 0.117 (0.117)	Loss 0.8557 (0.8557)	Prec@1 67.000 (67.000)
 * Testing Prec@1 70.570
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.153 (0.153)	Data 0.143 (0.143)	Loss 0.8573 (0.8573)	Prec@1 70.000 (70.000)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.044 (0.049)	Data 0.036 (0.043)	Loss 0.9468 (0.9225)	Prec@1 67.000 (67.965)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.071 (0.048)	Data 0.064 (0.042)	Loss 0.7915 (0.9163)	Prec@1 72.500 (68.067)
 * Training Prec@1 68.156
Test: [0/50]	Time 0.111 (0.111)	Loss 0.8449 (0.8449)	Prec@1 69.000 (69.000)
 * Testing Prec@1 70.410
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.132 (0.132)	Data 0.118 (0.118)	Loss 0.8971 (0.8971)	Prec@1 72.000 (72.000)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.052 (0.047)	Data 0.048 (0.041)	Loss 0.8617 (0.9100)	Prec@1 72.000 (68.619)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.045 (0.048)	Data 0.040 (0.042)	Loss 0.8644 (0.9049)	Prec@1 72.500 (68.542)
 * Training Prec@1 68.464
Test: [0/50]	Time 0.165 (0.165)	Loss 0.8772 (0.8772)	Prec@1 71.000 (71.000)
 * Testing Prec@1 70.820
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.181 (0.181)	Data 0.170 (0.170)	Loss 0.8575 (0.8575)	Prec@1 67.500 (67.500)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.051 (0.050)	Data 0.044 (0.044)	Loss 0.7854 (0.9074)	Prec@1 69.500 (68.050)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.043 (0.048)	Data 0.036 (0.042)	Loss 0.9616 (0.9093)	Prec@1 68.500 (68.022)
 * Training Prec@1 68.186
Test: [0/50]	Time 0.155 (0.155)	Loss 0.8778 (0.8778)	Prec@1 67.500 (67.500)
 * Testing Prec@1 70.850
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.144 (0.144)	Data 0.131 (0.131)	Loss 0.8730 (0.8730)	Prec@1 70.000 (70.000)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.047 (0.049)	Data 0.041 (0.043)	Loss 0.9942 (0.9115)	Prec@1 64.500 (68.059)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.057 (0.049)	Data 0.050 (0.043)	Loss 0.7880 (0.9055)	Prec@1 72.500 (68.321)
 * Training Prec@1 68.446
Test: [0/50]	Time 0.108 (0.108)	Loss 0.8747 (0.8747)	Prec@1 69.500 (69.500)
 * Testing Prec@1 70.440
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.178 (0.178)	Data 0.167 (0.167)	Loss 0.9872 (0.9872)	Prec@1 63.000 (63.000)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.043 (0.046)	Data 0.038 (0.039)	Loss 0.8214 (0.9086)	Prec@1 70.000 (68.287)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.042 (0.046)	Data 0.036 (0.040)	Loss 1.0130 (0.9022)	Prec@1 64.500 (68.629)
 * Training Prec@1 68.582
Test: [0/50]	Time 0.153 (0.153)	Loss 0.8341 (0.8341)	Prec@1 71.000 (71.000)
 * Testing Prec@1 71.090
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.162 (0.162)	Data 0.151 (0.151)	Loss 0.9394 (0.9394)	Prec@1 68.500 (68.500)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.042 (0.049)	Data 0.037 (0.043)	Loss 0.8108 (0.9003)	Prec@1 72.000 (68.743)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.044 (0.047)	Data 0.039 (0.041)	Loss 1.0581 (0.8966)	Prec@1 65.000 (68.801)
 * Training Prec@1 68.732
Test: [0/50]	Time 0.117 (0.117)	Loss 0.8517 (0.8517)	Prec@1 68.500 (68.500)
 * Testing Prec@1 70.980
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.179 (0.179)	Data 0.166 (0.166)	Loss 0.8686 (0.8686)	Prec@1 73.000 (73.000)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.041 (0.051)	Data 0.036 (0.043)	Loss 0.9021 (0.8936)	Prec@1 68.000 (68.921)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.044 (0.049)	Data 0.039 (0.042)	Loss 0.8752 (0.8839)	Prec@1 70.000 (69.010)
 * Training Prec@1 69.090
Test: [0/50]	Time 0.155 (0.155)	Loss 0.8458 (0.8458)	Prec@1 71.000 (71.000)
 * Testing Prec@1 71.490
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.135 (0.135)	Data 0.121 (0.121)	Loss 0.8472 (0.8472)	Prec@1 68.000 (68.000)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.056 (0.050)	Data 0.050 (0.044)	Loss 0.9152 (0.8798)	Prec@1 65.000 (69.342)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.058 (0.050)	Data 0.051 (0.044)	Loss 0.8247 (0.8814)	Prec@1 70.500 (69.244)
 * Training Prec@1 69.330
Test: [0/50]	Time 0.150 (0.150)	Loss 0.8408 (0.8408)	Prec@1 70.500 (70.500)
 * Testing Prec@1 71.740
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.128 (0.128)	Data 0.117 (0.117)	Loss 0.9206 (0.9206)	Prec@1 65.000 (65.000)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.044 (0.046)	Data 0.039 (0.041)	Loss 0.9110 (0.8800)	Prec@1 68.000 (69.238)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.043 (0.046)	Data 0.038 (0.040)	Loss 0.8078 (0.8716)	Prec@1 73.500 (69.299)
 * Training Prec@1 69.328
Test: [0/50]	Time 0.172 (0.172)	Loss 0.8415 (0.8415)	Prec@1 70.500 (70.500)
 * Testing Prec@1 71.750
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 0.146 (0.146)	Data 0.130 (0.130)	Loss 0.8418 (0.8418)	Prec@1 71.000 (71.000)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.042 (0.047)	Data 0.038 (0.042)	Loss 0.8440 (0.8831)	Prec@1 73.500 (69.198)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.043 (0.047)	Data 0.038 (0.042)	Loss 0.9232 (0.8732)	Prec@1 67.500 (69.828)
 * Training Prec@1 69.884
Test: [0/50]	Time 0.108 (0.108)	Loss 0.8450 (0.8450)	Prec@1 71.000 (71.000)
 * Testing Prec@1 71.870
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 0.148 (0.148)	Data 0.137 (0.137)	Loss 0.9188 (0.9188)	Prec@1 68.500 (68.500)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.044 (0.047)	Data 0.040 (0.041)	Loss 0.9336 (0.8700)	Prec@1 66.000 (69.624)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.048 (0.046)	Data 0.043 (0.041)	Loss 1.0157 (0.8720)	Prec@1 65.500 (69.540)
 * Training Prec@1 69.690
Test: [0/50]	Time 0.142 (0.142)	Loss 0.8372 (0.8372)	Prec@1 71.000 (71.000)
 * Testing Prec@1 71.850
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.163 (0.163)	Data 0.153 (0.153)	Loss 0.8000 (0.8000)	Prec@1 71.500 (71.500)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.044 (0.048)	Data 0.039 (0.043)	Loss 1.0931 (0.8780)	Prec@1 63.000 (69.262)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.047 (0.048)	Data 0.040 (0.042)	Loss 0.7727 (0.8737)	Prec@1 75.500 (69.256)
 * Training Prec@1 69.304
Test: [0/50]	Time 0.105 (0.105)	Loss 0.8428 (0.8428)	Prec@1 71.000 (71.000)
 * Testing Prec@1 71.790
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 0.135 (0.135)	Data 0.125 (0.125)	Loss 0.9697 (0.9697)	Prec@1 65.500 (65.500)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.051 (0.051)	Data 0.044 (0.044)	Loss 0.8518 (0.8692)	Prec@1 69.000 (69.817)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.044 (0.049)	Data 0.040 (0.043)	Loss 0.9050 (0.8700)	Prec@1 66.000 (69.779)
 * Training Prec@1 69.696
Test: [0/50]	Time 0.165 (0.165)	Loss 0.8426 (0.8426)	Prec@1 70.000 (70.000)
 * Testing Prec@1 71.940
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.143 (0.143)	Data 0.132 (0.132)	Loss 0.9069 (0.9069)	Prec@1 70.500 (70.500)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.049 (0.047)	Data 0.042 (0.042)	Loss 0.9412 (0.8750)	Prec@1 65.000 (69.312)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.044 (0.046)	Data 0.038 (0.041)	Loss 0.9396 (0.8800)	Prec@1 67.000 (69.204)
 * Training Prec@1 69.266
Test: [0/50]	Time 0.144 (0.144)	Loss 0.8400 (0.8400)	Prec@1 71.000 (71.000)
 * Testing Prec@1 71.950
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.159 (0.159)	Data 0.149 (0.149)	Loss 0.9877 (0.9877)	Prec@1 66.000 (66.000)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.045 (0.050)	Data 0.040 (0.045)	Loss 0.9609 (0.8753)	Prec@1 67.000 (69.366)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.046 (0.048)	Data 0.039 (0.043)	Loss 0.8317 (0.8706)	Prec@1 73.500 (69.570)
 * Training Prec@1 69.672
Test: [0/50]	Time 0.160 (0.160)	Loss 0.8349 (0.8349)	Prec@1 71.000 (71.000)
 * Testing Prec@1 71.980
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 0.176 (0.176)	Data 0.165 (0.165)	Loss 0.8924 (0.8924)	Prec@1 66.000 (66.000)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.049 (0.047)	Data 0.043 (0.042)	Loss 0.7878 (0.8779)	Prec@1 71.000 (69.500)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.044 (0.046)	Data 0.039 (0.041)	Loss 1.0175 (0.8757)	Prec@1 66.500 (69.475)
 * Training Prec@1 69.542
Test: [0/50]	Time 0.171 (0.171)	Loss 0.8473 (0.8473)	Prec@1 69.500 (69.500)
 * Testing Prec@1 71.650
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.175 (0.175)	Data 0.162 (0.162)	Loss 0.9493 (0.9493)	Prec@1 65.000 (65.000)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.048 (0.047)	Data 0.042 (0.042)	Loss 0.8638 (0.8713)	Prec@1 68.000 (69.079)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.048 (0.047)	Data 0.041 (0.042)	Loss 0.7916 (0.8723)	Prec@1 73.000 (69.296)
 * Training Prec@1 69.298
Test: [0/50]	Time 0.097 (0.097)	Loss 0.8401 (0.8401)	Prec@1 71.000 (71.000)
 * Testing Prec@1 71.640
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.184 (0.184)	Data 0.172 (0.172)	Loss 0.9601 (0.9601)	Prec@1 66.000 (66.000)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.044 (0.049)	Data 0.039 (0.043)	Loss 0.8628 (0.8612)	Prec@1 72.000 (69.772)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.049 (0.047)	Data 0.044 (0.041)	Loss 0.8879 (0.8717)	Prec@1 72.000 (69.612)
 * Training Prec@1 69.522
Test: [0/50]	Time 0.081 (0.081)	Loss 0.8360 (0.8360)	Prec@1 71.000 (71.000)
 * Testing Prec@1 71.680
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.177 (0.177)	Data 0.163 (0.163)	Loss 0.8508 (0.8508)	Prec@1 76.000 (76.000)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.046 (0.050)	Data 0.040 (0.044)	Loss 0.9178 (0.8748)	Prec@1 68.500 (69.733)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.045 (0.048)	Data 0.039 (0.042)	Loss 1.0162 (0.8718)	Prec@1 64.000 (69.774)
 * Training Prec@1 69.892
Test: [0/50]	Time 0.132 (0.132)	Loss 0.8411 (0.8411)	Prec@1 71.000 (71.000)
 * Testing Prec@1 71.870
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 0.178 (0.178)	Data 0.168 (0.168)	Loss 0.8571 (0.8571)	Prec@1 72.000 (72.000)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.052 (0.050)	Data 0.044 (0.044)	Loss 0.9105 (0.8707)	Prec@1 67.500 (69.332)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.051 (0.050)	Data 0.045 (0.044)	Loss 0.8895 (0.8702)	Prec@1 66.000 (69.405)
 * Training Prec@1 69.454
Test: [0/50]	Time 0.132 (0.132)	Loss 0.8372 (0.8372)	Prec@1 71.500 (71.500)
 * Testing Prec@1 71.990
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.201 (0.201)	Data 0.184 (0.184)	Loss 0.8054 (0.8054)	Prec@1 71.000 (71.000)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.049 (0.047)	Data 0.044 (0.041)	Loss 0.8690 (0.8684)	Prec@1 70.000 (69.347)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.045 (0.046)	Data 0.039 (0.040)	Loss 0.7931 (0.8634)	Prec@1 73.500 (69.873)
 * Training Prec@1 69.768
Test: [0/50]	Time 0.158 (0.158)	Loss 0.8321 (0.8321)	Prec@1 70.500 (70.500)
 * Testing Prec@1 71.930
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.180 (0.180)	Data 0.165 (0.165)	Loss 0.9049 (0.9049)	Prec@1 65.500 (65.500)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.047 (0.048)	Data 0.042 (0.042)	Loss 0.8640 (0.8539)	Prec@1 71.000 (70.228)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.045 (0.046)	Data 0.041 (0.041)	Loss 0.8231 (0.8632)	Prec@1 72.000 (69.826)
 * Training Prec@1 69.606
Test: [0/50]	Time 0.182 (0.182)	Loss 0.8337 (0.8337)	Prec@1 70.500 (70.500)
 * Testing Prec@1 71.770
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.165 (0.165)	Data 0.155 (0.155)	Loss 0.8546 (0.8546)	Prec@1 69.500 (69.500)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.042 (0.048)	Data 0.037 (0.042)	Loss 0.8918 (0.8668)	Prec@1 65.500 (69.614)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.044 (0.047)	Data 0.040 (0.041)	Loss 0.9439 (0.8633)	Prec@1 67.500 (69.764)
 * Training Prec@1 69.672
Test: [0/50]	Time 0.125 (0.125)	Loss 0.8283 (0.8283)	Prec@1 71.000 (71.000)
 * Testing Prec@1 71.850
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 0.159 (0.159)	Data 0.146 (0.146)	Loss 0.8149 (0.8149)	Prec@1 73.000 (73.000)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.043 (0.051)	Data 0.034 (0.044)	Loss 0.8286 (0.8614)	Prec@1 70.000 (69.733)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.054 (0.048)	Data 0.049 (0.042)	Loss 0.8155 (0.8697)	Prec@1 71.000 (69.624)
 * Training Prec@1 69.578
Test: [0/50]	Time 0.143 (0.143)	Loss 0.8249 (0.8249)	Prec@1 71.500 (71.500)
 * Testing Prec@1 71.990
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.184 (0.184)	Data 0.170 (0.170)	Loss 0.9187 (0.9187)	Prec@1 65.500 (65.500)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.045 (0.049)	Data 0.038 (0.043)	Loss 0.8873 (0.8701)	Prec@1 65.500 (69.579)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.040 (0.048)	Data 0.034 (0.042)	Loss 0.8966 (0.8711)	Prec@1 66.500 (69.612)
 * Training Prec@1 69.542
Test: [0/50]	Time 0.115 (0.115)	Loss 0.8340 (0.8340)	Prec@1 70.500 (70.500)
 * Testing Prec@1 71.830
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.170 (0.170)	Data 0.157 (0.157)	Loss 0.8422 (0.8422)	Prec@1 66.500 (66.500)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.049 (0.049)	Data 0.044 (0.043)	Loss 0.7262 (0.8697)	Prec@1 72.000 (69.554)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.047 (0.049)	Data 0.041 (0.043)	Loss 0.7050 (0.8624)	Prec@1 77.000 (69.853)
 * Training Prec@1 69.896
Test: [0/50]	Time 0.123 (0.123)	Loss 0.8303 (0.8303)	Prec@1 70.500 (70.500)
 * Testing Prec@1 71.960
