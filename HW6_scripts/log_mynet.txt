Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'mynet'
Epoch: [0/80][0/250]	LR: 0.1	Time 0.426 (0.426)	Data 0.113 (0.113)	Loss 2.3028 (2.3028)	Prec@1 7.500 (7.500)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.034 (0.040)	Data 0.027 (0.030)	Loss 2.3014 (2.3040)	Prec@1 9.500 (9.847)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.028 (0.029)	Loss 2.3009 (2.3037)	Prec@1 9.500 (9.925)
 * Training Prec@1 10.538
main.py:153: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.141 (0.141)	Loss 2.2354 (2.2354)	Prec@1 16.000 (16.000)
 * Testing Prec@1 18.450
main.py:190: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:191: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:199: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 0.097 (0.097)	Data 0.080 (0.080)	Loss 2.2348 (2.2348)	Prec@1 20.000 (20.000)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.036 (0.036)	Data 0.030 (0.029)	Loss 1.9645 (2.0767)	Prec@1 22.500 (22.441)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.035 (0.036)	Data 0.027 (0.030)	Loss 1.8551 (2.0036)	Prec@1 29.000 (24.672)
 * Training Prec@1 25.550
Test: [0/50]	Time 0.145 (0.145)	Loss 1.8626 (1.8626)	Prec@1 26.500 (26.500)
 * Testing Prec@1 27.710
Epoch: [2/80][0/250]	LR: 0.1	Time 0.193 (0.193)	Data 0.175 (0.175)	Loss 1.9252 (1.9252)	Prec@1 27.500 (27.500)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.028 (0.031)	Loss 2.0989 (1.8276)	Prec@1 21.000 (32.069)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.027 (0.029)	Loss 1.8510 (1.8260)	Prec@1 28.000 (32.149)
 * Training Prec@1 32.830
Test: [0/50]	Time 0.122 (0.122)	Loss 1.5614 (1.5614)	Prec@1 43.000 (43.000)
 * Testing Prec@1 41.470
Epoch: [3/80][0/250]	LR: 0.1	Time 0.111 (0.111)	Data 0.094 (0.094)	Loss 1.6333 (1.6333)	Prec@1 37.000 (37.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.032 (0.037)	Data 0.025 (0.030)	Loss 1.7286 (1.6767)	Prec@1 36.500 (37.718)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.027 (0.029)	Loss 1.5725 (1.6527)	Prec@1 42.500 (38.435)
 * Training Prec@1 38.744
Test: [0/50]	Time 0.079 (0.079)	Loss 1.5620 (1.5620)	Prec@1 41.000 (41.000)
 * Testing Prec@1 40.620
Epoch: [4/80][0/250]	LR: 0.1	Time 0.124 (0.124)	Data 0.105 (0.105)	Loss 1.6209 (1.6209)	Prec@1 41.500 (41.500)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.039 (0.039)	Data 0.032 (0.032)	Loss 1.5404 (1.6049)	Prec@1 36.500 (40.530)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.034 (0.041)	Data 0.027 (0.033)	Loss 1.6095 (1.5836)	Prec@1 40.000 (41.550)
 * Training Prec@1 41.946
Test: [0/50]	Time 0.131 (0.131)	Loss 1.3357 (1.3357)	Prec@1 49.000 (49.000)
 * Testing Prec@1 46.880
Epoch: [5/80][0/250]	LR: 0.1	Time 0.122 (0.122)	Data 0.106 (0.106)	Loss 1.5001 (1.5001)	Prec@1 43.500 (43.500)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.049 (0.036)	Data 0.041 (0.029)	Loss 1.5829 (1.4965)	Prec@1 38.000 (45.178)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.046 (0.038)	Data 0.038 (0.031)	Loss 1.6762 (1.4985)	Prec@1 36.000 (45.557)
 * Training Prec@1 46.062
Test: [0/50]	Time 0.120 (0.120)	Loss 1.2960 (1.2960)	Prec@1 55.000 (55.000)
 * Testing Prec@1 51.250
Epoch: [6/80][0/250]	LR: 0.1	Time 0.177 (0.177)	Data 0.159 (0.159)	Loss 1.4010 (1.4010)	Prec@1 48.500 (48.500)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.037 (0.036)	Data 0.028 (0.029)	Loss 1.4734 (1.4327)	Prec@1 44.500 (47.743)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.036 (0.036)	Data 0.030 (0.029)	Loss 1.3799 (1.4181)	Prec@1 54.000 (48.420)
 * Training Prec@1 48.544
Test: [0/50]	Time 0.127 (0.127)	Loss 1.1767 (1.1767)	Prec@1 57.500 (57.500)
 * Testing Prec@1 52.960
Epoch: [7/80][0/250]	LR: 0.1	Time 0.198 (0.198)	Data 0.179 (0.179)	Loss 1.3791 (1.3791)	Prec@1 52.500 (52.500)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.034 (0.038)	Data 0.027 (0.030)	Loss 1.2681 (1.3747)	Prec@1 56.000 (50.178)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.035 (0.036)	Data 0.028 (0.029)	Loss 1.3226 (1.3730)	Prec@1 50.000 (50.540)
 * Training Prec@1 50.474
Test: [0/50]	Time 0.126 (0.126)	Loss 1.3095 (1.3095)	Prec@1 54.000 (54.000)
 * Testing Prec@1 52.000
Epoch: [8/80][0/250]	LR: 0.1	Time 0.122 (0.122)	Data 0.105 (0.105)	Loss 1.4802 (1.4802)	Prec@1 45.500 (45.500)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.037 (0.036)	Data 0.030 (0.029)	Loss 1.3559 (1.3555)	Prec@1 53.500 (51.564)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.035 (0.036)	Data 0.028 (0.029)	Loss 1.2625 (1.3529)	Prec@1 54.500 (51.321)
 * Training Prec@1 51.732
Test: [0/50]	Time 0.116 (0.116)	Loss 1.2706 (1.2706)	Prec@1 55.500 (55.500)
 * Testing Prec@1 53.560
Epoch: [9/80][0/250]	LR: 0.1	Time 0.206 (0.206)	Data 0.188 (0.188)	Loss 1.3800 (1.3800)	Prec@1 47.000 (47.000)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.027 (0.030)	Loss 1.1848 (1.3103)	Prec@1 55.500 (52.713)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.027 (0.030)	Loss 1.2317 (1.3188)	Prec@1 55.000 (52.572)
 * Training Prec@1 52.722
Test: [0/50]	Time 0.108 (0.108)	Loss 1.2793 (1.2793)	Prec@1 51.500 (51.500)
 * Testing Prec@1 54.210
Epoch: [10/80][0/250]	LR: 0.1	Time 0.185 (0.185)	Data 0.167 (0.167)	Loss 1.3888 (1.3888)	Prec@1 49.500 (49.500)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.028 (0.030)	Loss 1.1522 (1.3236)	Prec@1 55.500 (52.550)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.027 (0.029)	Loss 1.2817 (1.3034)	Prec@1 54.000 (53.127)
 * Training Prec@1 53.188
Test: [0/50]	Time 0.113 (0.113)	Loss 1.1423 (1.1423)	Prec@1 53.500 (53.500)
 * Testing Prec@1 57.140
Epoch: [11/80][0/250]	LR: 0.1	Time 0.211 (0.211)	Data 0.190 (0.190)	Loss 1.4757 (1.4757)	Prec@1 49.000 (49.000)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.028 (0.030)	Loss 1.4034 (1.2904)	Prec@1 50.500 (53.856)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.036 (0.040)	Data 0.029 (0.032)	Loss 1.3475 (1.2999)	Prec@1 56.000 (53.498)
 * Training Prec@1 53.544
Test: [0/50]	Time 0.119 (0.119)	Loss 1.1056 (1.1056)	Prec@1 58.000 (58.000)
 * Testing Prec@1 57.350
Epoch: [12/80][0/250]	LR: 0.1	Time 0.198 (0.198)	Data 0.179 (0.179)	Loss 1.2774 (1.2774)	Prec@1 55.500 (55.500)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.037 (0.040)	Data 0.030 (0.033)	Loss 1.3999 (1.2633)	Prec@1 50.500 (55.356)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.028 (0.031)	Loss 1.2805 (1.2715)	Prec@1 60.000 (55.035)
 * Training Prec@1 55.046
Test: [0/50]	Time 0.110 (0.110)	Loss 1.1518 (1.1518)	Prec@1 61.000 (61.000)
 * Testing Prec@1 56.730
Epoch: [13/80][0/250]	LR: 0.1	Time 0.195 (0.195)	Data 0.177 (0.177)	Loss 1.3248 (1.3248)	Prec@1 56.500 (56.500)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.038 (0.038)	Data 0.028 (0.031)	Loss 1.2089 (1.2770)	Prec@1 57.500 (54.431)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.040 (0.037)	Data 0.033 (0.031)	Loss 1.3408 (1.2660)	Prec@1 53.000 (55.020)
 * Training Prec@1 54.706
Test: [0/50]	Time 0.114 (0.114)	Loss 1.2171 (1.2171)	Prec@1 54.500 (54.500)
 * Testing Prec@1 57.270
Epoch: [14/80][0/250]	LR: 0.1	Time 0.187 (0.187)	Data 0.170 (0.170)	Loss 1.2666 (1.2666)	Prec@1 56.000 (56.000)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.033 (0.038)	Data 0.026 (0.030)	Loss 1.1064 (1.2526)	Prec@1 64.000 (55.302)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.037 (0.036)	Data 0.030 (0.029)	Loss 1.2928 (1.2567)	Prec@1 53.000 (55.391)
 * Training Prec@1 55.118
Test: [0/50]	Time 0.124 (0.124)	Loss 1.2538 (1.2538)	Prec@1 57.000 (57.000)
 * Testing Prec@1 54.350
Epoch: [15/80][0/250]	LR: 0.1	Time 0.133 (0.133)	Data 0.115 (0.115)	Loss 1.3785 (1.3785)	Prec@1 47.500 (47.500)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.028 (0.031)	Loss 1.3332 (1.2851)	Prec@1 55.000 (54.302)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.027 (0.030)	Loss 1.0356 (1.2650)	Prec@1 63.500 (55.100)
 * Training Prec@1 55.348
Test: [0/50]	Time 0.128 (0.128)	Loss 1.0748 (1.0748)	Prec@1 67.000 (67.000)
 * Testing Prec@1 61.700
Epoch: [16/80][0/250]	LR: 0.1	Time 0.205 (0.205)	Data 0.187 (0.187)	Loss 1.3692 (1.3692)	Prec@1 52.500 (52.500)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.029 (0.031)	Loss 1.1759 (1.2636)	Prec@1 61.500 (55.436)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.036 (0.037)	Data 0.029 (0.030)	Loss 1.2372 (1.2481)	Prec@1 55.500 (55.826)
 * Training Prec@1 56.108
Test: [0/50]	Time 0.125 (0.125)	Loss 1.0569 (1.0569)	Prec@1 61.000 (61.000)
 * Testing Prec@1 58.660
Epoch: [17/80][0/250]	LR: 0.1	Time 0.186 (0.186)	Data 0.169 (0.169)	Loss 1.0665 (1.0665)	Prec@1 60.000 (60.000)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.029 (0.031)	Loss 1.2538 (1.2526)	Prec@1 56.000 (55.847)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.037 (0.037)	Data 0.029 (0.030)	Loss 1.2530 (1.2472)	Prec@1 57.500 (55.868)
 * Training Prec@1 56.064
Test: [0/50]	Time 0.113 (0.113)	Loss 1.0162 (1.0162)	Prec@1 63.000 (63.000)
 * Testing Prec@1 60.310
Epoch: [18/80][0/250]	LR: 0.1	Time 0.194 (0.194)	Data 0.176 (0.176)	Loss 1.2597 (1.2597)	Prec@1 56.000 (56.000)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.043 (0.039)	Data 0.035 (0.031)	Loss 1.1640 (1.2533)	Prec@1 56.500 (55.342)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.036 (0.037)	Data 0.031 (0.030)	Loss 1.1193 (1.2394)	Prec@1 58.500 (56.082)
 * Training Prec@1 55.986
Test: [0/50]	Time 0.124 (0.124)	Loss 1.0631 (1.0631)	Prec@1 63.500 (63.500)
 * Testing Prec@1 60.490
Epoch: [19/80][0/250]	LR: 0.1	Time 0.192 (0.192)	Data 0.173 (0.173)	Loss 1.3037 (1.3037)	Prec@1 51.500 (51.500)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.028 (0.031)	Loss 1.2034 (1.2352)	Prec@1 57.500 (56.678)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.027 (0.029)	Loss 1.1362 (1.2319)	Prec@1 58.500 (56.724)
 * Training Prec@1 56.794
Test: [0/50]	Time 0.119 (0.119)	Loss 1.2736 (1.2736)	Prec@1 54.000 (54.000)
 * Testing Prec@1 57.590
Epoch: [20/80][0/250]	LR: 0.1	Time 0.213 (0.213)	Data 0.195 (0.195)	Loss 1.1095 (1.1095)	Prec@1 61.500 (61.500)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.034 (0.040)	Data 0.028 (0.033)	Loss 1.2715 (1.2280)	Prec@1 54.000 (56.896)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.034 (0.038)	Data 0.028 (0.031)	Loss 1.1483 (1.2490)	Prec@1 56.000 (56.000)
 * Training Prec@1 55.880
Test: [0/50]	Time 0.121 (0.121)	Loss 1.1438 (1.1438)	Prec@1 56.000 (56.000)
 * Testing Prec@1 59.800
Epoch: [21/80][0/250]	LR: 0.1	Time 0.184 (0.184)	Data 0.168 (0.168)	Loss 1.2308 (1.2308)	Prec@1 54.000 (54.000)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.036 (0.037)	Data 0.028 (0.031)	Loss 1.3335 (1.2501)	Prec@1 51.500 (55.752)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.040 (0.036)	Data 0.033 (0.029)	Loss 1.2664 (1.2412)	Prec@1 56.000 (56.236)
 * Training Prec@1 56.342
Test: [0/50]	Time 0.110 (0.110)	Loss 1.0936 (1.0936)	Prec@1 59.000 (59.000)
 * Testing Prec@1 59.770
Epoch: [22/80][0/250]	LR: 0.1	Time 0.198 (0.198)	Data 0.178 (0.178)	Loss 1.1693 (1.1693)	Prec@1 60.000 (60.000)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.038 (0.039)	Data 0.031 (0.031)	Loss 1.3169 (1.2571)	Prec@1 53.000 (56.025)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.028 (0.030)	Loss 1.1763 (1.2387)	Prec@1 58.000 (56.771)
 * Training Prec@1 56.778
Test: [0/50]	Time 0.106 (0.106)	Loss 1.3130 (1.3130)	Prec@1 53.500 (53.500)
 * Testing Prec@1 57.880
Epoch: [23/80][0/250]	LR: 0.1	Time 0.207 (0.207)	Data 0.188 (0.188)	Loss 1.2346 (1.2346)	Prec@1 56.000 (56.000)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.029 (0.031)	Loss 1.2316 (1.2180)	Prec@1 55.500 (57.322)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.033 (0.038)	Data 0.026 (0.031)	Loss 1.0666 (1.2369)	Prec@1 59.000 (56.706)
 * Training Prec@1 57.068
Test: [0/50]	Time 0.113 (0.113)	Loss 1.1246 (1.1246)	Prec@1 58.000 (58.000)
 * Testing Prec@1 58.970
Epoch: [24/80][0/250]	LR: 0.1	Time 0.203 (0.203)	Data 0.185 (0.185)	Loss 1.3701 (1.3701)	Prec@1 54.000 (54.000)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.033 (0.036)	Data 0.026 (0.029)	Loss 1.3262 (1.2044)	Prec@1 57.000 (57.713)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.034 (0.035)	Data 0.028 (0.029)	Loss 1.0736 (1.2316)	Prec@1 60.500 (56.813)
 * Training Prec@1 56.704
Test: [0/50]	Time 0.113 (0.113)	Loss 1.1868 (1.1868)	Prec@1 62.000 (62.000)
 * Testing Prec@1 61.490
Epoch: [25/80][0/250]	LR: 0.1	Time 0.220 (0.220)	Data 0.203 (0.203)	Loss 1.1777 (1.1777)	Prec@1 60.500 (60.500)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.029 (0.031)	Loss 1.3327 (1.2451)	Prec@1 52.500 (56.342)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.076 (0.037)	Data 0.069 (0.030)	Loss 1.2145 (1.2480)	Prec@1 59.000 (56.159)
 * Training Prec@1 56.380
Test: [0/50]	Time 0.121 (0.121)	Loss 1.0913 (1.0913)	Prec@1 63.500 (63.500)
 * Testing Prec@1 59.510
Epoch: [26/80][0/250]	LR: 0.1	Time 0.139 (0.139)	Data 0.121 (0.121)	Loss 1.2168 (1.2168)	Prec@1 56.000 (56.000)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.029 (0.030)	Loss 1.2549 (1.2490)	Prec@1 57.500 (56.208)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.038 (0.037)	Data 0.031 (0.030)	Loss 1.0689 (1.2364)	Prec@1 60.500 (56.540)
 * Training Prec@1 56.474
Test: [0/50]	Time 0.094 (0.094)	Loss 1.2827 (1.2827)	Prec@1 53.000 (53.000)
 * Testing Prec@1 56.800
Epoch: [27/80][0/250]	LR: 0.1	Time 0.104 (0.104)	Data 0.087 (0.087)	Loss 1.2791 (1.2791)	Prec@1 57.000 (57.000)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.028 (0.029)	Loss 1.2522 (1.2414)	Prec@1 55.500 (56.619)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.035 (0.036)	Data 0.028 (0.029)	Loss 1.1436 (1.2377)	Prec@1 60.000 (56.756)
 * Training Prec@1 56.594
Test: [0/50]	Time 0.115 (0.115)	Loss 1.1351 (1.1351)	Prec@1 59.000 (59.000)
 * Testing Prec@1 60.220
Epoch: [28/80][0/250]	LR: 0.1	Time 0.190 (0.190)	Data 0.170 (0.170)	Loss 1.1819 (1.1819)	Prec@1 60.000 (60.000)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.035 (0.039)	Data 0.029 (0.031)	Loss 1.3477 (1.2681)	Prec@1 58.000 (55.634)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.027 (0.030)	Loss 1.2355 (1.2854)	Prec@1 57.500 (54.823)
 * Training Prec@1 54.918
Test: [0/50]	Time 0.109 (0.109)	Loss 1.3052 (1.3052)	Prec@1 56.500 (56.500)
 * Testing Prec@1 58.510
Epoch: [29/80][0/250]	LR: 0.1	Time 0.126 (0.126)	Data 0.109 (0.109)	Loss 1.3043 (1.3043)	Prec@1 53.500 (53.500)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.036 (0.037)	Data 0.029 (0.030)	Loss 1.1479 (1.2319)	Prec@1 58.000 (56.356)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.027 (0.029)	Loss 1.3159 (1.2368)	Prec@1 55.000 (56.378)
 * Training Prec@1 56.382
Test: [0/50]	Time 0.109 (0.109)	Loss 1.1634 (1.1634)	Prec@1 63.000 (63.000)
 * Testing Prec@1 58.620
Epoch: [30/80][0/250]	LR: 0.1	Time 0.136 (0.136)	Data 0.118 (0.118)	Loss 1.1576 (1.1576)	Prec@1 57.500 (57.500)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.028 (0.030)	Loss 1.2246 (1.2418)	Prec@1 58.000 (56.411)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.035 (0.036)	Data 0.028 (0.029)	Loss 1.2217 (1.2283)	Prec@1 57.500 (56.749)
 * Training Prec@1 56.470
Test: [0/50]	Time 0.112 (0.112)	Loss 1.2514 (1.2514)	Prec@1 56.000 (56.000)
 * Testing Prec@1 55.870
Epoch: [31/80][0/250]	LR: 0.1	Time 0.194 (0.194)	Data 0.177 (0.177)	Loss 1.3297 (1.3297)	Prec@1 55.000 (55.000)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.034 (0.037)	Data 0.027 (0.029)	Loss 1.3188 (1.2561)	Prec@1 47.500 (56.030)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.036 (0.036)	Data 0.030 (0.029)	Loss 1.2095 (1.2527)	Prec@1 57.000 (56.119)
 * Training Prec@1 56.364
Test: [0/50]	Time 0.086 (0.086)	Loss 1.0658 (1.0658)	Prec@1 63.500 (63.500)
 * Testing Prec@1 60.280
Epoch: [32/80][0/250]	LR: 0.1	Time 0.126 (0.126)	Data 0.109 (0.109)	Loss 1.1458 (1.1458)	Prec@1 58.500 (58.500)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.036 (0.036)	Data 0.029 (0.030)	Loss 1.2823 (1.2295)	Prec@1 56.500 (56.337)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.027 (0.029)	Loss 1.4543 (1.2566)	Prec@1 47.500 (55.973)
 * Training Prec@1 55.880
Test: [0/50]	Time 0.108 (0.108)	Loss 1.1646 (1.1646)	Prec@1 57.500 (57.500)
 * Testing Prec@1 58.880
Epoch: [33/80][0/250]	LR: 0.1	Time 0.132 (0.132)	Data 0.115 (0.115)	Loss 1.3282 (1.3282)	Prec@1 56.000 (56.000)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.028 (0.030)	Loss 1.2692 (1.2294)	Prec@1 56.000 (57.545)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.027 (0.029)	Loss 1.4748 (1.2349)	Prec@1 47.000 (56.893)
 * Training Prec@1 56.720
Test: [0/50]	Time 0.112 (0.112)	Loss 1.1690 (1.1690)	Prec@1 57.500 (57.500)
 * Testing Prec@1 58.820
Epoch: [34/80][0/250]	LR: 0.1	Time 0.206 (0.206)	Data 0.188 (0.188)	Loss 1.1641 (1.1641)	Prec@1 68.500 (68.500)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.033 (0.040)	Data 0.028 (0.033)	Loss 1.0892 (1.2417)	Prec@1 58.500 (56.802)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.034 (0.038)	Data 0.028 (0.031)	Loss 1.1225 (1.2320)	Prec@1 61.500 (56.903)
 * Training Prec@1 56.778
Test: [0/50]	Time 0.112 (0.112)	Loss 1.1111 (1.1111)	Prec@1 60.000 (60.000)
 * Testing Prec@1 58.430
Epoch: [35/80][0/250]	LR: 0.1	Time 0.131 (0.131)	Data 0.111 (0.111)	Loss 1.1753 (1.1753)	Prec@1 58.500 (58.500)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.038 (0.036)	Data 0.030 (0.029)	Loss 1.1934 (1.2262)	Prec@1 59.500 (57.114)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.035 (0.036)	Data 0.028 (0.029)	Loss 1.2662 (1.2272)	Prec@1 57.500 (56.975)
 * Training Prec@1 56.802
Test: [0/50]	Time 0.091 (0.091)	Loss 1.1835 (1.1835)	Prec@1 53.500 (53.500)
 * Testing Prec@1 58.760
Epoch: [36/80][0/250]	LR: 0.1	Time 0.141 (0.141)	Data 0.123 (0.123)	Loss 1.3179 (1.3179)	Prec@1 58.500 (58.500)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.027 (0.029)	Loss 1.3096 (1.2286)	Prec@1 50.500 (57.050)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.034 (0.036)	Data 0.029 (0.029)	Loss 1.3399 (1.2194)	Prec@1 55.000 (57.440)
 * Training Prec@1 57.392
Test: [0/50]	Time 0.114 (0.114)	Loss 1.1490 (1.1490)	Prec@1 58.000 (58.000)
 * Testing Prec@1 59.960
Epoch: [37/80][0/250]	LR: 0.1	Time 0.204 (0.204)	Data 0.185 (0.185)	Loss 1.1346 (1.1346)	Prec@1 64.000 (64.000)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.034 (0.039)	Data 0.027 (0.031)	Loss 1.3638 (1.2774)	Prec@1 53.500 (55.936)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.037 (0.037)	Data 0.030 (0.030)	Loss 1.1801 (1.2643)	Prec@1 58.500 (56.017)
 * Training Prec@1 56.192
Test: [0/50]	Time 0.106 (0.106)	Loss 1.2359 (1.2359)	Prec@1 59.000 (59.000)
 * Testing Prec@1 60.290
Epoch: [38/80][0/250]	LR: 0.1	Time 0.190 (0.190)	Data 0.174 (0.174)	Loss 1.3432 (1.3432)	Prec@1 54.500 (54.500)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.028 (0.031)	Loss 1.3142 (1.2308)	Prec@1 52.500 (57.203)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.035 (0.037)	Data 0.028 (0.030)	Loss 1.2437 (1.2409)	Prec@1 57.500 (57.082)
 * Training Prec@1 57.244
Test: [0/50]	Time 0.114 (0.114)	Loss 1.2372 (1.2372)	Prec@1 59.000 (59.000)
 * Testing Prec@1 58.960
Epoch: [39/80][0/250]	LR: 0.1	Time 0.215 (0.215)	Data 0.196 (0.196)	Loss 1.2099 (1.2099)	Prec@1 57.500 (57.500)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.029 (0.031)	Loss 1.1393 (1.2675)	Prec@1 63.000 (55.619)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.045 (0.037)	Data 0.039 (0.030)	Loss 1.1264 (1.2487)	Prec@1 60.500 (56.326)
 * Training Prec@1 56.342
Test: [0/50]	Time 0.116 (0.116)	Loss 1.1659 (1.1659)	Prec@1 59.500 (59.500)
 * Testing Prec@1 61.180
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.209 (0.209)	Data 0.191 (0.191)	Loss 1.2912 (1.2912)	Prec@1 54.500 (54.500)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.041 (0.039)	Data 0.033 (0.032)	Loss 0.9454 (1.1016)	Prec@1 69.500 (61.545)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.038)	Data 0.028 (0.031)	Loss 0.9216 (1.0628)	Prec@1 69.500 (62.706)
 * Training Prec@1 63.086
Test: [0/50]	Time 0.118 (0.118)	Loss 0.9433 (0.9433)	Prec@1 65.000 (65.000)
 * Testing Prec@1 66.740
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.190 (0.190)	Data 0.173 (0.173)	Loss 1.0161 (1.0161)	Prec@1 60.500 (60.500)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.039)	Data 0.030 (0.032)	Loss 0.9961 (0.9735)	Prec@1 61.000 (65.163)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.039)	Data 0.030 (0.032)	Loss 1.0480 (0.9767)	Prec@1 61.500 (65.366)
 * Training Prec@1 65.362
Test: [0/50]	Time 0.128 (0.128)	Loss 0.8935 (0.8935)	Prec@1 69.000 (69.000)
 * Testing Prec@1 67.650
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.203 (0.203)	Data 0.183 (0.183)	Loss 0.9721 (0.9721)	Prec@1 64.500 (64.500)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.039)	Data 0.029 (0.031)	Loss 0.9152 (0.9478)	Prec@1 71.500 (66.495)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.037)	Data 0.030 (0.030)	Loss 0.8729 (0.9405)	Prec@1 70.500 (66.813)
 * Training Prec@1 66.818
Test: [0/50]	Time 0.105 (0.105)	Loss 0.8918 (0.8918)	Prec@1 67.500 (67.500)
 * Testing Prec@1 68.310
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.205 (0.205)	Data 0.188 (0.188)	Loss 0.8945 (0.8945)	Prec@1 70.500 (70.500)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.037)	Data 0.030 (0.030)	Loss 0.8959 (0.9312)	Prec@1 70.000 (67.228)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.036)	Data 0.028 (0.029)	Loss 0.8729 (0.9283)	Prec@1 70.000 (67.438)
 * Training Prec@1 67.466
Test: [0/50]	Time 0.117 (0.117)	Loss 0.9046 (0.9046)	Prec@1 65.000 (65.000)
 * Testing Prec@1 68.630
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.183 (0.183)	Data 0.163 (0.163)	Loss 0.8714 (0.8714)	Prec@1 72.000 (72.000)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.034 (0.036)	Data 0.028 (0.029)	Loss 0.9348 (0.9120)	Prec@1 69.000 (68.015)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.036)	Data 0.031 (0.029)	Loss 1.0468 (0.9116)	Prec@1 64.000 (67.908)
 * Training Prec@1 67.862
Test: [0/50]	Time 0.108 (0.108)	Loss 0.8746 (0.8746)	Prec@1 69.500 (69.500)
 * Testing Prec@1 69.080
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.194 (0.194)	Data 0.174 (0.174)	Loss 0.8510 (0.8510)	Prec@1 69.500 (69.500)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.038)	Data 0.029 (0.031)	Loss 0.9550 (0.8944)	Prec@1 66.000 (68.302)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.034 (0.036)	Data 0.027 (0.030)	Loss 0.9008 (0.8944)	Prec@1 68.000 (68.246)
 * Training Prec@1 68.100
Test: [0/50]	Time 0.103 (0.103)	Loss 0.8529 (0.8529)	Prec@1 68.500 (68.500)
 * Testing Prec@1 69.720
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.182 (0.182)	Data 0.165 (0.165)	Loss 0.9116 (0.9116)	Prec@1 68.000 (68.000)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.036)	Data 0.028 (0.029)	Loss 0.9688 (0.8842)	Prec@1 68.000 (68.851)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.036)	Data 0.028 (0.029)	Loss 0.9438 (0.8841)	Prec@1 67.000 (68.868)
 * Training Prec@1 68.708
Test: [0/50]	Time 0.107 (0.107)	Loss 0.8377 (0.8377)	Prec@1 68.500 (68.500)
 * Testing Prec@1 69.270
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 0.130 (0.130)	Data 0.112 (0.112)	Loss 0.9261 (0.9261)	Prec@1 68.500 (68.500)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.033 (0.036)	Data 0.027 (0.029)	Loss 0.9627 (0.8730)	Prec@1 66.500 (69.535)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.037)	Data 0.028 (0.030)	Loss 0.9334 (0.8691)	Prec@1 68.500 (69.475)
 * Training Prec@1 69.352
Test: [0/50]	Time 0.120 (0.120)	Loss 0.8074 (0.8074)	Prec@1 69.500 (69.500)
 * Testing Prec@1 70.340
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.212 (0.212)	Data 0.193 (0.193)	Loss 0.8163 (0.8163)	Prec@1 71.500 (71.500)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.034 (0.038)	Data 0.027 (0.031)	Loss 0.7470 (0.8675)	Prec@1 72.500 (69.406)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.037)	Data 0.029 (0.030)	Loss 1.0041 (0.8665)	Prec@1 62.000 (69.500)
 * Training Prec@1 69.468
Test: [0/50]	Time 0.119 (0.119)	Loss 0.8135 (0.8135)	Prec@1 71.000 (71.000)
 * Testing Prec@1 70.180
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.196 (0.196)	Data 0.178 (0.178)	Loss 0.9258 (0.9258)	Prec@1 66.000 (66.000)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.038)	Data 0.030 (0.031)	Loss 0.8995 (0.8534)	Prec@1 68.500 (69.965)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.034 (0.037)	Data 0.027 (0.030)	Loss 0.9422 (0.8580)	Prec@1 68.000 (69.689)
 * Training Prec@1 69.674
Test: [0/50]	Time 0.119 (0.119)	Loss 0.8381 (0.8381)	Prec@1 68.000 (68.000)
 * Testing Prec@1 70.480
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.187 (0.187)	Data 0.169 (0.169)	Loss 0.8309 (0.8309)	Prec@1 67.000 (67.000)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.078 (0.041)	Data 0.070 (0.034)	Loss 0.8393 (0.8620)	Prec@1 75.000 (69.658)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.040)	Data 0.028 (0.034)	Loss 0.7654 (0.8520)	Prec@1 75.500 (70.005)
 * Training Prec@1 69.980
Test: [0/50]	Time 0.128 (0.128)	Loss 0.8076 (0.8076)	Prec@1 73.500 (73.500)
 * Testing Prec@1 70.790
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 0.197 (0.197)	Data 0.179 (0.179)	Loss 0.8435 (0.8435)	Prec@1 70.500 (70.500)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.037)	Data 0.027 (0.030)	Loss 0.8032 (0.8475)	Prec@1 72.000 (69.856)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.036)	Data 0.028 (0.029)	Loss 0.7162 (0.8423)	Prec@1 73.500 (70.149)
 * Training Prec@1 70.166
Test: [0/50]	Time 0.095 (0.095)	Loss 0.7994 (0.7994)	Prec@1 72.500 (72.500)
 * Testing Prec@1 70.740
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.191 (0.191)	Data 0.172 (0.172)	Loss 0.8950 (0.8950)	Prec@1 69.000 (69.000)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.034 (0.036)	Data 0.027 (0.029)	Loss 0.8311 (0.8340)	Prec@1 73.000 (70.678)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.035)	Data 0.028 (0.028)	Loss 0.9322 (0.8344)	Prec@1 68.500 (70.475)
 * Training Prec@1 70.422
Test: [0/50]	Time 0.117 (0.117)	Loss 0.7961 (0.7961)	Prec@1 72.000 (72.000)
 * Testing Prec@1 71.150
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 0.210 (0.210)	Data 0.192 (0.192)	Loss 0.7077 (0.7077)	Prec@1 75.500 (75.500)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.038)	Data 0.030 (0.031)	Loss 0.9268 (0.8248)	Prec@1 70.500 (71.252)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.036)	Data 0.028 (0.029)	Loss 0.9769 (0.8266)	Prec@1 66.500 (71.035)
 * Training Prec@1 70.978
Test: [0/50]	Time 0.106 (0.106)	Loss 0.8057 (0.8057)	Prec@1 72.500 (72.500)
 * Testing Prec@1 71.290
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.192 (0.192)	Data 0.175 (0.175)	Loss 0.8889 (0.8889)	Prec@1 69.500 (69.500)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.038)	Data 0.029 (0.031)	Loss 0.8088 (0.8152)	Prec@1 68.000 (71.163)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.034 (0.037)	Data 0.027 (0.030)	Loss 0.8885 (0.8264)	Prec@1 66.500 (70.761)
 * Training Prec@1 70.786
Test: [0/50]	Time 0.143 (0.143)	Loss 0.7533 (0.7533)	Prec@1 73.000 (73.000)
 * Testing Prec@1 71.500
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.120 (0.120)	Data 0.104 (0.104)	Loss 0.8586 (0.8586)	Prec@1 70.000 (70.000)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.035 (0.036)	Data 0.029 (0.029)	Loss 0.8975 (0.8187)	Prec@1 67.500 (70.787)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.034 (0.036)	Data 0.027 (0.029)	Loss 0.8430 (0.8140)	Prec@1 70.500 (71.062)
 * Training Prec@1 71.272
Test: [0/50]	Time 0.113 (0.113)	Loss 0.7797 (0.7797)	Prec@1 70.000 (70.000)
 * Testing Prec@1 70.820
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.135 (0.135)	Data 0.117 (0.117)	Loss 0.9443 (0.9443)	Prec@1 68.000 (68.000)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.036 (0.041)	Data 0.030 (0.034)	Loss 0.9794 (0.8138)	Prec@1 68.500 (71.460)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.039)	Data 0.031 (0.032)	Loss 0.8143 (0.8135)	Prec@1 69.500 (71.316)
 * Training Prec@1 71.158
Test: [0/50]	Time 0.111 (0.111)	Loss 0.8057 (0.8057)	Prec@1 70.500 (70.500)
 * Testing Prec@1 71.370
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.201 (0.201)	Data 0.183 (0.183)	Loss 0.8772 (0.8772)	Prec@1 67.000 (67.000)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.039 (0.039)	Data 0.032 (0.032)	Loss 0.8332 (0.8001)	Prec@1 68.500 (71.738)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.039)	Data 0.028 (0.032)	Loss 0.8111 (0.8064)	Prec@1 69.500 (71.507)
 * Training Prec@1 71.516
Test: [0/50]	Time 0.123 (0.123)	Loss 0.7804 (0.7804)	Prec@1 71.500 (71.500)
 * Testing Prec@1 71.670
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.190 (0.190)	Data 0.171 (0.171)	Loss 0.8051 (0.8051)	Prec@1 73.500 (73.500)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.036 (0.038)	Data 0.028 (0.031)	Loss 0.7640 (0.7956)	Prec@1 73.500 (71.787)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.037)	Data 0.029 (0.030)	Loss 0.7166 (0.8015)	Prec@1 74.500 (71.445)
 * Training Prec@1 71.592
Test: [0/50]	Time 0.103 (0.103)	Loss 0.7415 (0.7415)	Prec@1 73.000 (73.000)
 * Testing Prec@1 71.680
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.195 (0.195)	Data 0.177 (0.177)	Loss 0.8536 (0.8536)	Prec@1 71.500 (71.500)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.034 (0.038)	Data 0.027 (0.031)	Loss 0.6951 (0.7909)	Prec@1 75.000 (72.020)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.035 (0.036)	Data 0.028 (0.029)	Loss 0.7185 (0.7967)	Prec@1 76.000 (71.791)
 * Training Prec@1 71.792
Test: [0/50]	Time 0.116 (0.116)	Loss 0.7377 (0.7377)	Prec@1 70.500 (70.500)
 * Testing Prec@1 71.540
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.132 (0.132)	Data 0.115 (0.115)	Loss 0.6629 (0.6629)	Prec@1 78.000 (78.000)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.037)	Data 0.028 (0.030)	Loss 0.7241 (0.7856)	Prec@1 77.000 (72.446)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.035 (0.036)	Data 0.028 (0.029)	Loss 0.7375 (0.7781)	Prec@1 74.000 (72.657)
 * Training Prec@1 72.586
Test: [0/50]	Time 0.115 (0.115)	Loss 0.7361 (0.7361)	Prec@1 71.500 (71.500)
 * Testing Prec@1 72.270
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.187 (0.187)	Data 0.169 (0.169)	Loss 0.6389 (0.6389)	Prec@1 75.500 (75.500)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.040 (0.044)	Data 0.035 (0.037)	Loss 0.6992 (0.7671)	Prec@1 76.500 (72.812)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.041)	Data 0.028 (0.034)	Loss 0.6905 (0.7780)	Prec@1 79.500 (72.448)
 * Training Prec@1 72.606
Test: [0/50]	Time 0.126 (0.126)	Loss 0.7386 (0.7386)	Prec@1 73.000 (73.000)
 * Testing Prec@1 72.250
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.143 (0.143)	Data 0.123 (0.123)	Loss 0.6940 (0.6940)	Prec@1 74.500 (74.500)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.037 (0.037)	Data 0.030 (0.030)	Loss 0.7623 (0.7684)	Prec@1 68.500 (72.851)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.034 (0.036)	Data 0.027 (0.029)	Loss 0.6613 (0.7674)	Prec@1 75.000 (72.963)
 * Training Prec@1 73.014
Test: [0/50]	Time 0.118 (0.118)	Loss 0.7268 (0.7268)	Prec@1 72.000 (72.000)
 * Testing Prec@1 72.340
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 0.203 (0.203)	Data 0.185 (0.185)	Loss 0.6437 (0.6437)	Prec@1 76.000 (76.000)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.036 (0.038)	Data 0.027 (0.031)	Loss 0.7272 (0.7772)	Prec@1 74.500 (72.584)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.034 (0.040)	Data 0.028 (0.033)	Loss 0.9303 (0.7711)	Prec@1 69.500 (72.664)
 * Training Prec@1 72.624
Test: [0/50]	Time 0.126 (0.126)	Loss 0.7255 (0.7255)	Prec@1 71.500 (71.500)
 * Testing Prec@1 72.570
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 0.198 (0.198)	Data 0.180 (0.180)	Loss 0.7363 (0.7363)	Prec@1 74.000 (74.000)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.038)	Data 0.027 (0.031)	Loss 0.7967 (0.7623)	Prec@1 71.500 (73.163)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.038 (0.037)	Data 0.031 (0.030)	Loss 0.8043 (0.7663)	Prec@1 73.000 (73.162)
 * Training Prec@1 73.004
Test: [0/50]	Time 0.122 (0.122)	Loss 0.7144 (0.7144)	Prec@1 73.000 (73.000)
 * Testing Prec@1 72.410
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.184 (0.184)	Data 0.166 (0.166)	Loss 0.8098 (0.8098)	Prec@1 68.000 (68.000)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.038)	Data 0.028 (0.030)	Loss 0.7598 (0.7711)	Prec@1 71.000 (72.906)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.037)	Data 0.029 (0.030)	Loss 0.7322 (0.7689)	Prec@1 73.500 (72.866)
 * Training Prec@1 72.922
Test: [0/50]	Time 0.111 (0.111)	Loss 0.7179 (0.7179)	Prec@1 72.500 (72.500)
 * Testing Prec@1 72.530
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 0.126 (0.126)	Data 0.109 (0.109)	Loss 0.7707 (0.7707)	Prec@1 72.000 (72.000)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.036)	Data 0.028 (0.028)	Loss 0.8199 (0.7699)	Prec@1 70.500 (72.792)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.035 (0.035)	Data 0.028 (0.028)	Loss 0.7437 (0.7680)	Prec@1 72.500 (72.821)
 * Training Prec@1 73.086
Test: [0/50]	Time 0.138 (0.138)	Loss 0.7239 (0.7239)	Prec@1 72.500 (72.500)
 * Testing Prec@1 72.460
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.151 (0.151)	Data 0.132 (0.132)	Loss 0.8060 (0.8060)	Prec@1 71.500 (71.500)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.039 (0.040)	Data 0.032 (0.033)	Loss 0.8003 (0.7717)	Prec@1 75.500 (72.827)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.035 (0.041)	Data 0.028 (0.034)	Loss 0.6410 (0.7623)	Prec@1 78.000 (73.092)
 * Training Prec@1 73.050
Test: [0/50]	Time 0.124 (0.124)	Loss 0.7111 (0.7111)	Prec@1 73.000 (73.000)
 * Testing Prec@1 72.600
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.197 (0.197)	Data 0.179 (0.179)	Loss 0.6452 (0.6452)	Prec@1 76.500 (76.500)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.039 (0.039)	Data 0.031 (0.032)	Loss 0.7101 (0.7526)	Prec@1 78.000 (73.396)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.038)	Data 0.030 (0.031)	Loss 0.8045 (0.7616)	Prec@1 71.500 (73.244)
 * Training Prec@1 73.110
Test: [0/50]	Time 0.133 (0.133)	Loss 0.7062 (0.7062)	Prec@1 72.500 (72.500)
 * Testing Prec@1 72.650
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 0.194 (0.194)	Data 0.176 (0.176)	Loss 0.8118 (0.8118)	Prec@1 69.000 (69.000)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.038)	Data 0.027 (0.030)	Loss 0.6482 (0.7605)	Prec@1 78.500 (73.262)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.036)	Data 0.029 (0.029)	Loss 0.8161 (0.7590)	Prec@1 70.000 (73.149)
 * Training Prec@1 73.022
Test: [0/50]	Time 0.094 (0.094)	Loss 0.6950 (0.6950)	Prec@1 73.500 (73.500)
 * Testing Prec@1 72.740
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.209 (0.209)	Data 0.191 (0.191)	Loss 0.8297 (0.8297)	Prec@1 70.000 (70.000)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.036 (0.037)	Data 0.028 (0.030)	Loss 0.8022 (0.7635)	Prec@1 75.000 (73.040)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.038 (0.036)	Data 0.032 (0.029)	Loss 0.7550 (0.7642)	Prec@1 73.000 (73.055)
 * Training Prec@1 73.094
Test: [0/50]	Time 0.119 (0.119)	Loss 0.7075 (0.7075)	Prec@1 73.500 (73.500)
 * Testing Prec@1 72.550
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.123 (0.123)	Data 0.106 (0.106)	Loss 0.7432 (0.7432)	Prec@1 73.000 (73.000)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.036)	Data 0.028 (0.029)	Loss 0.8387 (0.7643)	Prec@1 71.500 (72.916)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.036)	Data 0.030 (0.029)	Loss 0.6813 (0.7629)	Prec@1 75.000 (73.045)
 * Training Prec@1 73.078
Test: [0/50]	Time 0.114 (0.114)	Loss 0.7023 (0.7023)	Prec@1 73.500 (73.500)
 * Testing Prec@1 72.730
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.187 (0.187)	Data 0.170 (0.170)	Loss 0.7773 (0.7773)	Prec@1 72.500 (72.500)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.038)	Data 0.027 (0.031)	Loss 0.6672 (0.7655)	Prec@1 77.000 (72.683)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.034 (0.037)	Data 0.027 (0.030)	Loss 0.6695 (0.7591)	Prec@1 76.500 (73.085)
 * Training Prec@1 73.056
Test: [0/50]	Time 0.092 (0.092)	Loss 0.7072 (0.7072)	Prec@1 72.000 (72.000)
 * Testing Prec@1 72.940
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 0.199 (0.199)	Data 0.182 (0.182)	Loss 0.6974 (0.6974)	Prec@1 78.500 (78.500)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.037)	Data 0.028 (0.030)	Loss 0.9020 (0.7576)	Prec@1 69.500 (73.163)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.034 (0.036)	Data 0.027 (0.029)	Loss 0.6519 (0.7607)	Prec@1 75.500 (73.132)
 * Training Prec@1 73.034
Test: [0/50]	Time 0.113 (0.113)	Loss 0.7095 (0.7095)	Prec@1 72.000 (72.000)
 * Testing Prec@1 72.850
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.214 (0.214)	Data 0.196 (0.196)	Loss 0.8044 (0.8044)	Prec@1 73.000 (73.000)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.046 (0.041)	Data 0.039 (0.033)	Loss 0.6964 (0.7541)	Prec@1 76.000 (73.550)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.034 (0.040)	Data 0.028 (0.033)	Loss 0.7454 (0.7564)	Prec@1 74.500 (73.259)
 * Training Prec@1 73.126
Test: [0/50]	Time 0.113 (0.113)	Loss 0.7063 (0.7063)	Prec@1 73.500 (73.500)
 * Testing Prec@1 72.890
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.194 (0.194)	Data 0.176 (0.176)	Loss 0.7462 (0.7462)	Prec@1 77.000 (77.000)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.038)	Data 0.028 (0.031)	Loss 0.7754 (0.7630)	Prec@1 68.500 (73.005)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.037)	Data 0.030 (0.030)	Loss 0.7947 (0.7628)	Prec@1 75.500 (73.045)
 * Training Prec@1 73.096
Test: [0/50]	Time 0.126 (0.126)	Loss 0.7052 (0.7052)	Prec@1 73.000 (73.000)
 * Testing Prec@1 72.880
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.226 (0.226)	Data 0.209 (0.209)	Loss 0.8217 (0.8217)	Prec@1 70.000 (70.000)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.035 (0.038)	Data 0.028 (0.031)	Loss 0.8603 (0.7674)	Prec@1 74.500 (72.757)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.039 (0.037)	Data 0.032 (0.030)	Loss 0.7193 (0.7610)	Prec@1 74.000 (73.214)
 * Training Prec@1 73.246
Test: [0/50]	Time 0.084 (0.084)	Loss 0.6990 (0.6990)	Prec@1 73.000 (73.000)
 * Testing Prec@1 72.830
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 0.199 (0.199)	Data 0.182 (0.182)	Loss 0.7509 (0.7509)	Prec@1 74.500 (74.500)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.041 (0.037)	Data 0.033 (0.030)	Loss 0.8052 (0.7665)	Prec@1 69.500 (72.921)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.036)	Data 0.030 (0.030)	Loss 0.7800 (0.7605)	Prec@1 69.500 (72.965)
 * Training Prec@1 72.950
Test: [0/50]	Time 0.112 (0.112)	Loss 0.7042 (0.7042)	Prec@1 73.500 (73.500)
 * Testing Prec@1 72.820
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.202 (0.202)	Data 0.184 (0.184)	Loss 0.9173 (0.9173)	Prec@1 68.000 (68.000)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.037)	Data 0.028 (0.030)	Loss 0.8260 (0.7590)	Prec@1 72.000 (72.837)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.036)	Data 0.029 (0.029)	Loss 0.9373 (0.7542)	Prec@1 64.000 (73.124)
 * Training Prec@1 72.966
Test: [0/50]	Time 0.132 (0.132)	Loss 0.7056 (0.7056)	Prec@1 71.000 (71.000)
 * Testing Prec@1 72.860
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.191 (0.191)	Data 0.172 (0.172)	Loss 0.6988 (0.6988)	Prec@1 73.500 (73.500)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.039)	Data 0.027 (0.031)	Loss 0.7774 (0.7505)	Prec@1 73.000 (73.535)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.035 (0.037)	Data 0.028 (0.031)	Loss 0.7818 (0.7574)	Prec@1 74.000 (73.299)
 * Training Prec@1 73.324
Test: [0/50]	Time 0.113 (0.113)	Loss 0.6996 (0.6996)	Prec@1 72.500 (72.500)
 * Testing Prec@1 72.780
