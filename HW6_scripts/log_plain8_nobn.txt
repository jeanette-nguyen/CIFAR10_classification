Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'plainnet8'
Epoch: [0/80][0/250]	LR: 0.1	Time 0.415 (0.415)	Data 0.104 (0.104)	Loss 2.2971 (2.2971)	Prec@1 13.000 (13.000)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.025 (0.030)	Data 0.019 (0.021)	Loss 2.1724 (2.1947)	Prec@1 15.000 (15.312)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.021 (0.020)	Loss 2.0009 (2.0703)	Prec@1 23.500 (20.224)
 * Training Prec@1 22.124
main.py:198: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.103 (0.103)	Loss 1.7333 (1.7333)	Prec@1 33.500 (33.500)
 * Testing Prec@1 32.910
main.py:235: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:236: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:244: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 0.105 (0.105)	Data 0.091 (0.091)	Loss 1.8474 (1.8474)	Prec@1 35.500 (35.500)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.025 (0.026)	Data 0.020 (0.019)	Loss 1.5891 (1.7372)	Prec@1 38.500 (34.550)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.024 (0.025)	Data 0.017 (0.019)	Loss 1.4848 (1.7002)	Prec@1 41.500 (36.323)
 * Training Prec@1 37.142
Test: [0/50]	Time 0.107 (0.107)	Loss 1.5261 (1.5261)	Prec@1 45.000 (45.000)
 * Testing Prec@1 43.480
Epoch: [2/80][0/250]	LR: 0.1	Time 0.115 (0.115)	Data 0.102 (0.102)	Loss 1.5978 (1.5978)	Prec@1 43.000 (43.000)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.023 (0.026)	Data 0.017 (0.020)	Loss 1.5330 (1.5190)	Prec@1 41.000 (43.980)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.024 (0.027)	Data 0.018 (0.020)	Loss 1.4438 (1.5018)	Prec@1 46.000 (44.943)
 * Training Prec@1 45.756
Test: [0/50]	Time 0.113 (0.113)	Loss 1.3402 (1.3402)	Prec@1 48.000 (48.000)
 * Testing Prec@1 51.380
Epoch: [3/80][0/250]	LR: 0.1	Time 0.133 (0.133)	Data 0.121 (0.121)	Loss 1.2790 (1.2790)	Prec@1 50.000 (50.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.024 (0.026)	Data 0.018 (0.020)	Loss 1.4885 (1.3533)	Prec@1 47.000 (50.743)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.017 (0.019)	Loss 1.3049 (1.3178)	Prec@1 52.000 (52.072)
 * Training Prec@1 52.450
Test: [0/50]	Time 0.093 (0.093)	Loss 1.2341 (1.2341)	Prec@1 52.000 (52.000)
 * Testing Prec@1 56.420
Epoch: [4/80][0/250]	LR: 0.1	Time 0.160 (0.160)	Data 0.145 (0.145)	Loss 1.0739 (1.0739)	Prec@1 60.500 (60.500)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.026 (0.026)	Data 0.021 (0.020)	Loss 1.2566 (1.2206)	Prec@1 54.500 (56.243)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.026 (0.026)	Data 0.021 (0.021)	Loss 1.2735 (1.2048)	Prec@1 50.500 (57.090)
 * Training Prec@1 57.500
Test: [0/50]	Time 0.158 (0.158)	Loss 1.1477 (1.1477)	Prec@1 61.000 (61.000)
 * Testing Prec@1 60.660
Epoch: [5/80][0/250]	LR: 0.1	Time 0.103 (0.103)	Data 0.089 (0.089)	Loss 1.0736 (1.0736)	Prec@1 59.500 (59.500)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.025 (0.026)	Data 0.019 (0.020)	Loss 1.1145 (1.0952)	Prec@1 64.500 (61.158)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.023 (0.026)	Data 0.017 (0.020)	Loss 1.0698 (1.0877)	Prec@1 64.000 (61.400)
 * Training Prec@1 61.758
Test: [0/50]	Time 0.155 (0.155)	Loss 1.1248 (1.1248)	Prec@1 58.000 (58.000)
 * Testing Prec@1 60.970
Epoch: [6/80][0/250]	LR: 0.1	Time 0.154 (0.154)	Data 0.140 (0.140)	Loss 0.9370 (0.9370)	Prec@1 65.500 (65.500)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.022 (0.026)	Data 0.017 (0.020)	Loss 1.0107 (1.0269)	Prec@1 65.000 (64.084)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.026 (0.026)	Data 0.019 (0.020)	Loss 1.1599 (1.0228)	Prec@1 64.500 (64.042)
 * Training Prec@1 64.184
Test: [0/50]	Time 0.096 (0.096)	Loss 0.9780 (0.9780)	Prec@1 62.500 (62.500)
 * Testing Prec@1 64.300
Epoch: [7/80][0/250]	LR: 0.1	Time 0.136 (0.136)	Data 0.125 (0.125)	Loss 0.9454 (0.9454)	Prec@1 66.500 (66.500)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.021 (0.026)	Data 0.015 (0.019)	Loss 1.0471 (0.9470)	Prec@1 63.500 (66.614)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.026 (0.026)	Data 0.020 (0.019)	Loss 0.9740 (0.9546)	Prec@1 66.000 (66.520)
 * Training Prec@1 66.596
Test: [0/50]	Time 0.118 (0.118)	Loss 0.9085 (0.9085)	Prec@1 68.000 (68.000)
 * Testing Prec@1 66.730
Epoch: [8/80][0/250]	LR: 0.1	Time 0.117 (0.117)	Data 0.104 (0.104)	Loss 0.8784 (0.8784)	Prec@1 68.500 (68.500)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.026 (0.025)	Data 0.019 (0.018)	Loss 0.9619 (0.8815)	Prec@1 65.000 (69.094)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.017 (0.018)	Loss 0.7814 (0.8878)	Prec@1 73.000 (69.104)
 * Training Prec@1 68.836
Test: [0/50]	Time 0.105 (0.105)	Loss 0.9269 (0.9269)	Prec@1 69.000 (69.000)
 * Testing Prec@1 66.880
Epoch: [9/80][0/250]	LR: 0.1	Time 0.170 (0.170)	Data 0.156 (0.156)	Loss 0.8380 (0.8380)	Prec@1 69.000 (69.000)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.024 (0.027)	Data 0.018 (0.020)	Loss 0.7592 (0.8269)	Prec@1 76.500 (71.223)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.023 (0.026)	Data 0.016 (0.020)	Loss 0.7385 (0.8221)	Prec@1 72.500 (71.363)
 * Training Prec@1 71.298
Test: [0/50]	Time 0.123 (0.123)	Loss 0.9930 (0.9930)	Prec@1 64.000 (64.000)
 * Testing Prec@1 65.570
Epoch: [10/80][0/250]	LR: 0.1	Time 0.143 (0.143)	Data 0.130 (0.130)	Loss 0.7225 (0.7225)	Prec@1 73.500 (73.500)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.016 (0.019)	Loss 0.7062 (0.7886)	Prec@1 75.500 (72.757)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.017 (0.018)	Loss 0.7128 (0.7811)	Prec@1 75.000 (73.060)
 * Training Prec@1 73.100
Test: [0/50]	Time 0.096 (0.096)	Loss 0.8186 (0.8186)	Prec@1 74.500 (74.500)
 * Testing Prec@1 70.110
Epoch: [11/80][0/250]	LR: 0.1	Time 0.099 (0.099)	Data 0.086 (0.086)	Loss 0.7194 (0.7194)	Prec@1 75.500 (75.500)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.038 (0.026)	Data 0.032 (0.020)	Loss 0.7125 (0.7372)	Prec@1 76.000 (74.257)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.025 (0.026)	Data 0.019 (0.020)	Loss 0.7377 (0.7377)	Prec@1 72.500 (74.269)
 * Training Prec@1 73.944
Test: [0/50]	Time 0.129 (0.129)	Loss 0.8231 (0.8231)	Prec@1 70.000 (70.000)
 * Testing Prec@1 71.100
Epoch: [12/80][0/250]	LR: 0.1	Time 0.170 (0.170)	Data 0.156 (0.156)	Loss 0.7224 (0.7224)	Prec@1 76.500 (76.500)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.021 (0.021)	Loss 0.7136 (0.6958)	Prec@1 78.000 (75.856)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.021 (0.027)	Data 0.015 (0.020)	Loss 0.5550 (0.7160)	Prec@1 79.000 (75.109)
 * Training Prec@1 75.144
Test: [0/50]	Time 0.093 (0.093)	Loss 0.7346 (0.7346)	Prec@1 74.000 (74.000)
 * Testing Prec@1 71.450
Epoch: [13/80][0/250]	LR: 0.1	Time 0.188 (0.188)	Data 0.173 (0.173)	Loss 0.5524 (0.5524)	Prec@1 81.000 (81.000)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.022 (0.027)	Data 0.016 (0.021)	Loss 0.7144 (0.6663)	Prec@1 72.000 (76.802)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.025 (0.027)	Data 0.019 (0.020)	Loss 0.6937 (0.6847)	Prec@1 75.000 (76.182)
 * Training Prec@1 76.242
Test: [0/50]	Time 0.104 (0.104)	Loss 0.7540 (0.7540)	Prec@1 73.000 (73.000)
 * Testing Prec@1 71.660
Epoch: [14/80][0/250]	LR: 0.1	Time 0.120 (0.120)	Data 0.106 (0.106)	Loss 0.6485 (0.6485)	Prec@1 77.000 (77.000)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.027 (0.026)	Data 0.021 (0.020)	Loss 0.5972 (0.6171)	Prec@1 78.500 (78.450)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.023 (0.026)	Data 0.017 (0.020)	Loss 0.6074 (0.6420)	Prec@1 79.500 (77.582)
 * Training Prec@1 77.390
Test: [0/50]	Time 0.106 (0.106)	Loss 0.7322 (0.7322)	Prec@1 76.500 (76.500)
 * Testing Prec@1 72.840
Epoch: [15/80][0/250]	LR: 0.1	Time 0.171 (0.171)	Data 0.157 (0.157)	Loss 0.5750 (0.5750)	Prec@1 82.000 (82.000)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.027 (0.027)	Data 0.020 (0.021)	Loss 0.7551 (0.6252)	Prec@1 74.000 (78.054)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.024 (0.026)	Data 0.018 (0.020)	Loss 0.6100 (0.6313)	Prec@1 78.000 (77.888)
 * Training Prec@1 77.828
Test: [0/50]	Time 0.100 (0.100)	Loss 0.7727 (0.7727)	Prec@1 70.500 (70.500)
 * Testing Prec@1 70.900
Epoch: [16/80][0/250]	LR: 0.1	Time 0.155 (0.155)	Data 0.141 (0.141)	Loss 0.5444 (0.5444)	Prec@1 80.500 (80.500)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.024 (0.028)	Data 0.018 (0.021)	Loss 0.6431 (0.5917)	Prec@1 80.000 (79.545)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.024 (0.027)	Data 0.018 (0.021)	Loss 0.6080 (0.6157)	Prec@1 81.500 (78.689)
 * Training Prec@1 78.474
Test: [0/50]	Time 0.109 (0.109)	Loss 0.7875 (0.7875)	Prec@1 75.000 (75.000)
 * Testing Prec@1 72.170
Epoch: [17/80][0/250]	LR: 0.1	Time 0.149 (0.149)	Data 0.135 (0.135)	Loss 0.6284 (0.6284)	Prec@1 79.000 (79.000)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.023 (0.027)	Data 0.016 (0.020)	Loss 0.5566 (0.5774)	Prec@1 78.000 (80.168)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.022 (0.026)	Data 0.016 (0.019)	Loss 0.5263 (0.5966)	Prec@1 82.000 (79.308)
 * Training Prec@1 79.054
Test: [0/50]	Time 0.103 (0.103)	Loss 0.7390 (0.7390)	Prec@1 75.000 (75.000)
 * Testing Prec@1 70.880
Epoch: [18/80][0/250]	LR: 0.1	Time 0.149 (0.149)	Data 0.135 (0.135)	Loss 0.6515 (0.6515)	Prec@1 76.000 (76.000)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.025 (0.026)	Data 0.019 (0.020)	Loss 0.6505 (0.5621)	Prec@1 77.000 (80.436)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.025 (0.025)	Data 0.020 (0.019)	Loss 0.6664 (0.5730)	Prec@1 76.500 (80.042)
 * Training Prec@1 79.948
Test: [0/50]	Time 0.103 (0.103)	Loss 0.7950 (0.7950)	Prec@1 76.500 (76.500)
 * Testing Prec@1 72.820
Epoch: [19/80][0/250]	LR: 0.1	Time 0.104 (0.104)	Data 0.090 (0.090)	Loss 0.4853 (0.4853)	Prec@1 80.000 (80.000)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.032 (0.028)	Data 0.026 (0.022)	Loss 0.5328 (0.5392)	Prec@1 81.500 (81.134)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.021 (0.022)	Loss 0.6537 (0.5572)	Prec@1 79.000 (80.580)
 * Training Prec@1 79.770
Test: [0/50]	Time 0.097 (0.097)	Loss 0.7334 (0.7334)	Prec@1 76.000 (76.000)
 * Testing Prec@1 70.400
Epoch: [20/80][0/250]	LR: 0.1	Time 0.147 (0.147)	Data 0.135 (0.135)	Loss 0.5346 (0.5346)	Prec@1 82.500 (82.500)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.030 (0.026)	Data 0.021 (0.020)	Loss 0.7108 (0.5530)	Prec@1 72.000 (80.619)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.028 (0.026)	Data 0.021 (0.020)	Loss 0.5289 (0.5610)	Prec@1 83.000 (80.460)
 * Training Prec@1 80.404
Test: [0/50]	Time 0.091 (0.091)	Loss 0.8395 (0.8395)	Prec@1 77.000 (77.000)
 * Testing Prec@1 71.920
Epoch: [21/80][0/250]	LR: 0.1	Time 0.151 (0.151)	Data 0.138 (0.138)	Loss 0.4232 (0.4232)	Prec@1 86.000 (86.000)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.023 (0.028)	Data 0.017 (0.022)	Loss 0.5538 (0.5086)	Prec@1 81.500 (82.015)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.026 (0.027)	Data 0.020 (0.021)	Loss 0.5614 (0.5348)	Prec@1 81.500 (81.271)
 * Training Prec@1 80.932
Test: [0/50]	Time 0.097 (0.097)	Loss 0.8121 (0.8121)	Prec@1 72.500 (72.500)
 * Testing Prec@1 72.290
Epoch: [22/80][0/250]	LR: 0.1	Time 0.151 (0.151)	Data 0.135 (0.135)	Loss 0.4254 (0.4254)	Prec@1 83.000 (83.000)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.025 (0.027)	Data 0.018 (0.020)	Loss 0.6491 (0.5358)	Prec@1 79.000 (81.436)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.026 (0.026)	Data 0.020 (0.020)	Loss 0.4886 (0.5354)	Prec@1 82.000 (81.455)
 * Training Prec@1 81.244
Test: [0/50]	Time 0.107 (0.107)	Loss 0.8098 (0.8098)	Prec@1 76.000 (76.000)
 * Testing Prec@1 72.850
Epoch: [23/80][0/250]	LR: 0.1	Time 0.178 (0.178)	Data 0.165 (0.165)	Loss 0.3853 (0.3853)	Prec@1 87.500 (87.500)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.024 (0.027)	Data 0.017 (0.021)	Loss 0.6202 (0.5159)	Prec@1 80.000 (81.990)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.033 (0.026)	Data 0.026 (0.020)	Loss 0.5198 (0.5339)	Prec@1 80.500 (81.336)
 * Training Prec@1 81.164
Test: [0/50]	Time 0.108 (0.108)	Loss 0.8173 (0.8173)	Prec@1 77.000 (77.000)
 * Testing Prec@1 73.270
Epoch: [24/80][0/250]	LR: 0.1	Time 0.125 (0.125)	Data 0.111 (0.111)	Loss 0.4483 (0.4483)	Prec@1 84.500 (84.500)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.030 (0.026)	Data 0.023 (0.020)	Loss 0.7174 (0.4927)	Prec@1 75.000 (82.624)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.023 (0.026)	Data 0.017 (0.019)	Loss 0.5467 (0.5081)	Prec@1 81.500 (82.154)
 * Training Prec@1 81.926
Test: [0/50]	Time 0.101 (0.101)	Loss 0.7630 (0.7630)	Prec@1 75.500 (75.500)
 * Testing Prec@1 72.390
Epoch: [25/80][0/250]	LR: 0.1	Time 0.107 (0.107)	Data 0.094 (0.094)	Loss 0.4737 (0.4737)	Prec@1 82.000 (82.000)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.027 (0.026)	Data 0.021 (0.020)	Loss 0.4786 (0.4790)	Prec@1 85.500 (82.851)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.024 (0.026)	Data 0.020 (0.020)	Loss 0.6399 (0.5023)	Prec@1 80.000 (82.167)
 * Training Prec@1 81.942
Test: [0/50]	Time 0.102 (0.102)	Loss 0.8759 (0.8759)	Prec@1 74.000 (74.000)
 * Testing Prec@1 73.030
Epoch: [26/80][0/250]	LR: 0.1	Time 0.150 (0.150)	Data 0.137 (0.137)	Loss 0.4530 (0.4530)	Prec@1 86.000 (86.000)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.024 (0.026)	Data 0.018 (0.019)	Loss 0.4569 (0.4768)	Prec@1 84.500 (83.356)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.026 (0.026)	Data 0.020 (0.019)	Loss 0.5436 (0.4989)	Prec@1 80.500 (82.505)
 * Training Prec@1 82.386
Test: [0/50]	Time 0.112 (0.112)	Loss 0.8618 (0.8618)	Prec@1 74.500 (74.500)
 * Testing Prec@1 70.710
Epoch: [27/80][0/250]	LR: 0.1	Time 0.170 (0.170)	Data 0.157 (0.157)	Loss 0.5793 (0.5793)	Prec@1 78.500 (78.500)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.024 (0.027)	Data 0.018 (0.021)	Loss 0.6310 (0.4955)	Prec@1 79.000 (82.579)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.024 (0.026)	Data 0.018 (0.020)	Loss 0.4533 (0.5002)	Prec@1 83.500 (82.376)
 * Training Prec@1 82.018
Test: [0/50]	Time 0.097 (0.097)	Loss 0.8245 (0.8245)	Prec@1 74.500 (74.500)
 * Testing Prec@1 73.260
Epoch: [28/80][0/250]	LR: 0.1	Time 0.104 (0.104)	Data 0.090 (0.090)	Loss 0.3673 (0.3673)	Prec@1 90.000 (90.000)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.025 (0.027)	Data 0.019 (0.021)	Loss 0.4872 (0.4882)	Prec@1 82.000 (82.381)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.025 (0.026)	Data 0.019 (0.020)	Loss 0.6246 (0.4962)	Prec@1 83.000 (82.433)
 * Training Prec@1 82.110
Test: [0/50]	Time 0.098 (0.098)	Loss 0.9706 (0.9706)	Prec@1 71.500 (71.500)
 * Testing Prec@1 70.250
Epoch: [29/80][0/250]	LR: 0.1	Time 0.158 (0.158)	Data 0.144 (0.144)	Loss 0.4880 (0.4880)	Prec@1 85.000 (85.000)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.025 (0.026)	Data 0.019 (0.020)	Loss 0.6612 (0.4816)	Prec@1 75.500 (83.040)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.033 (0.026)	Data 0.027 (0.019)	Loss 0.4808 (0.4855)	Prec@1 82.500 (82.843)
 * Training Prec@1 82.448
Test: [0/50]	Time 0.096 (0.096)	Loss 1.0026 (1.0026)	Prec@1 73.000 (73.000)
 * Testing Prec@1 71.200
Epoch: [30/80][0/250]	LR: 0.1	Time 0.165 (0.165)	Data 0.152 (0.152)	Loss 0.4503 (0.4503)	Prec@1 87.000 (87.000)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.027 (0.028)	Data 0.021 (0.021)	Loss 0.5597 (0.4550)	Prec@1 81.500 (84.292)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.027 (0.027)	Data 0.021 (0.020)	Loss 0.6256 (0.4768)	Prec@1 81.000 (83.438)
 * Training Prec@1 83.008
Test: [0/50]	Time 0.117 (0.117)	Loss 0.8760 (0.8760)	Prec@1 70.000 (70.000)
 * Testing Prec@1 70.850
Epoch: [31/80][0/250]	LR: 0.1	Time 0.147 (0.147)	Data 0.133 (0.133)	Loss 0.4715 (0.4715)	Prec@1 87.500 (87.500)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.027 (0.026)	Data 0.021 (0.020)	Loss 0.4539 (0.4454)	Prec@1 80.500 (84.371)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.022 (0.026)	Data 0.016 (0.020)	Loss 0.5659 (0.4707)	Prec@1 81.000 (83.502)
 * Training Prec@1 83.082
Test: [0/50]	Time 0.105 (0.105)	Loss 0.8901 (0.8901)	Prec@1 72.000 (72.000)
 * Testing Prec@1 71.980
Epoch: [32/80][0/250]	LR: 0.1	Time 0.117 (0.117)	Data 0.104 (0.104)	Loss 0.5054 (0.5054)	Prec@1 81.000 (81.000)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.025 (0.026)	Data 0.018 (0.020)	Loss 0.4325 (0.4343)	Prec@1 86.500 (84.609)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.025 (0.025)	Data 0.019 (0.019)	Loss 0.5801 (0.4663)	Prec@1 79.000 (83.488)
 * Training Prec@1 83.098
Test: [0/50]	Time 0.095 (0.095)	Loss 0.8781 (0.8781)	Prec@1 73.500 (73.500)
 * Testing Prec@1 71.940
Epoch: [33/80][0/250]	LR: 0.1	Time 0.154 (0.154)	Data 0.142 (0.142)	Loss 0.4917 (0.4917)	Prec@1 82.500 (82.500)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.024 (0.025)	Data 0.019 (0.018)	Loss 0.5952 (0.4365)	Prec@1 78.000 (84.698)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.022 (0.025)	Data 0.016 (0.018)	Loss 0.3508 (0.4673)	Prec@1 87.000 (83.592)
 * Training Prec@1 83.292
Test: [0/50]	Time 0.130 (0.130)	Loss 0.8899 (0.8899)	Prec@1 74.000 (74.000)
 * Testing Prec@1 71.640
Epoch: [34/80][0/250]	LR: 0.1	Time 0.150 (0.150)	Data 0.136 (0.136)	Loss 0.5671 (0.5671)	Prec@1 81.000 (81.000)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.023 (0.025)	Data 0.017 (0.019)	Loss 0.5202 (0.4430)	Prec@1 82.500 (84.609)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.024 (0.025)	Data 0.018 (0.019)	Loss 0.4225 (0.4543)	Prec@1 83.000 (84.090)
 * Training Prec@1 83.768
Test: [0/50]	Time 0.110 (0.110)	Loss 0.8399 (0.8399)	Prec@1 74.000 (74.000)
 * Testing Prec@1 72.210
Epoch: [35/80][0/250]	LR: 0.1	Time 0.157 (0.157)	Data 0.142 (0.142)	Loss 0.4124 (0.4124)	Prec@1 85.500 (85.500)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.023 (0.026)	Data 0.017 (0.019)	Loss 0.4108 (0.4274)	Prec@1 84.000 (84.896)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.028 (0.026)	Data 0.022 (0.019)	Loss 0.6472 (0.4508)	Prec@1 77.000 (84.107)
 * Training Prec@1 83.814
Test: [0/50]	Time 0.093 (0.093)	Loss 0.9014 (0.9014)	Prec@1 76.000 (76.000)
 * Testing Prec@1 72.530
Epoch: [36/80][0/250]	LR: 0.1	Time 0.148 (0.148)	Data 0.135 (0.135)	Loss 0.5030 (0.5030)	Prec@1 80.500 (80.500)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.025 (0.026)	Data 0.019 (0.020)	Loss 0.3760 (0.4171)	Prec@1 88.000 (85.297)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.024 (0.025)	Data 0.018 (0.019)	Loss 0.5734 (0.4411)	Prec@1 78.500 (84.517)
 * Training Prec@1 84.180
Test: [0/50]	Time 0.095 (0.095)	Loss 0.9120 (0.9120)	Prec@1 76.500 (76.500)
 * Testing Prec@1 71.520
Epoch: [37/80][0/250]	LR: 0.1	Time 0.157 (0.157)	Data 0.144 (0.144)	Loss 0.4641 (0.4641)	Prec@1 83.500 (83.500)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.028 (0.027)	Data 0.022 (0.021)	Loss 0.3371 (0.4034)	Prec@1 87.000 (85.812)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.026 (0.026)	Data 0.020 (0.020)	Loss 0.4546 (0.4443)	Prec@1 84.500 (84.465)
 * Training Prec@1 83.828
Test: [0/50]	Time 0.106 (0.106)	Loss 0.7907 (0.7907)	Prec@1 77.500 (77.500)
 * Testing Prec@1 71.030
Epoch: [38/80][0/250]	LR: 0.1	Time 0.179 (0.179)	Data 0.165 (0.165)	Loss 0.5944 (0.5944)	Prec@1 80.000 (80.000)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.023 (0.027)	Data 0.017 (0.020)	Loss 0.4178 (0.4370)	Prec@1 86.500 (84.455)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.027 (0.026)	Data 0.020 (0.020)	Loss 0.4838 (0.4446)	Prec@1 82.500 (84.328)
 * Training Prec@1 84.080
Test: [0/50]	Time 0.105 (0.105)	Loss 0.8342 (0.8342)	Prec@1 73.000 (73.000)
 * Testing Prec@1 71.910
Epoch: [39/80][0/250]	LR: 0.1	Time 0.164 (0.164)	Data 0.151 (0.151)	Loss 0.4014 (0.4014)	Prec@1 86.500 (86.500)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.025 (0.027)	Data 0.018 (0.021)	Loss 0.5656 (0.4128)	Prec@1 82.000 (85.248)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.024 (0.026)	Data 0.017 (0.020)	Loss 0.5673 (0.4438)	Prec@1 81.000 (84.271)
 * Training Prec@1 83.638
Test: [0/50]	Time 0.092 (0.092)	Loss 0.9475 (0.9475)	Prec@1 71.000 (71.000)
 * Testing Prec@1 70.730
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.156 (0.156)	Data 0.143 (0.143)	Loss 0.3786 (0.3786)	Prec@1 87.500 (87.500)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.025 (0.028)	Data 0.019 (0.021)	Loss 0.2149 (0.2926)	Prec@1 91.000 (89.807)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.034 (0.026)	Data 0.028 (0.020)	Loss 0.3050 (0.2583)	Prec@1 90.500 (90.945)
 * Training Prec@1 91.284
Test: [0/50]	Time 0.092 (0.092)	Loss 0.9169 (0.9169)	Prec@1 78.000 (78.000)
 * Testing Prec@1 76.100
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.153 (0.153)	Data 0.139 (0.139)	Loss 0.1987 (0.1987)	Prec@1 94.500 (94.500)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.025 (0.027)	Data 0.019 (0.020)	Loss 0.2259 (0.1625)	Prec@1 91.000 (94.406)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.026 (0.026)	Data 0.020 (0.020)	Loss 0.1848 (0.1648)	Prec@1 94.000 (94.294)
 * Training Prec@1 94.334
Test: [0/50]	Time 0.092 (0.092)	Loss 0.9410 (0.9410)	Prec@1 79.000 (79.000)
 * Testing Prec@1 76.090
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.163 (0.163)	Data 0.149 (0.149)	Loss 0.1677 (0.1677)	Prec@1 94.500 (94.500)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.023 (0.027)	Data 0.017 (0.021)	Loss 0.0813 (0.1301)	Prec@1 99.000 (95.822)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.025 (0.026)	Data 0.019 (0.020)	Loss 0.1363 (0.1306)	Prec@1 94.500 (95.684)
 * Training Prec@1 95.648
Test: [0/50]	Time 0.098 (0.098)	Loss 1.0204 (1.0204)	Prec@1 77.000 (77.000)
 * Testing Prec@1 76.490
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.157 (0.157)	Data 0.145 (0.145)	Loss 0.1049 (0.1049)	Prec@1 96.500 (96.500)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.020 (0.026)	Data 0.014 (0.020)	Loss 0.0982 (0.1057)	Prec@1 96.000 (96.550)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.027 (0.026)	Data 0.021 (0.020)	Loss 0.0961 (0.1082)	Prec@1 96.500 (96.448)
 * Training Prec@1 96.450
Test: [0/50]	Time 0.087 (0.087)	Loss 1.0435 (1.0435)	Prec@1 79.500 (79.500)
 * Testing Prec@1 76.320
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.154 (0.154)	Data 0.140 (0.140)	Loss 0.0875 (0.0875)	Prec@1 98.000 (98.000)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.025 (0.028)	Data 0.019 (0.022)	Loss 0.0879 (0.0887)	Prec@1 97.500 (97.233)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.023 (0.027)	Data 0.017 (0.020)	Loss 0.0630 (0.0899)	Prec@1 97.500 (97.172)
 * Training Prec@1 97.138
Test: [0/50]	Time 0.104 (0.104)	Loss 1.1386 (1.1386)	Prec@1 80.000 (80.000)
 * Testing Prec@1 76.260
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.114 (0.114)	Data 0.101 (0.101)	Loss 0.0963 (0.0963)	Prec@1 96.500 (96.500)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.024 (0.027)	Data 0.018 (0.021)	Loss 0.0875 (0.0751)	Prec@1 98.000 (97.876)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.029 (0.027)	Data 0.023 (0.020)	Loss 0.0799 (0.0749)	Prec@1 97.500 (97.808)
 * Training Prec@1 97.720
Test: [0/50]	Time 0.103 (0.103)	Loss 1.1496 (1.1496)	Prec@1 77.000 (77.000)
 * Testing Prec@1 76.450
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.141 (0.141)	Data 0.126 (0.126)	Loss 0.0700 (0.0700)	Prec@1 98.000 (98.000)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.023 (0.028)	Data 0.017 (0.022)	Loss 0.0800 (0.0639)	Prec@1 97.000 (98.223)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.028 (0.026)	Data 0.022 (0.020)	Loss 0.0973 (0.0629)	Prec@1 97.000 (98.224)
 * Training Prec@1 98.148
Test: [0/50]	Time 0.094 (0.094)	Loss 1.2606 (1.2606)	Prec@1 77.500 (77.500)
 * Testing Prec@1 76.400
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 0.157 (0.157)	Data 0.144 (0.144)	Loss 0.0293 (0.0293)	Prec@1 99.500 (99.500)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.029 (0.027)	Data 0.022 (0.021)	Loss 0.0494 (0.0515)	Prec@1 98.500 (98.713)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.031 (0.027)	Data 0.025 (0.020)	Loss 0.0400 (0.0536)	Prec@1 98.500 (98.619)
 * Training Prec@1 98.592
Test: [0/50]	Time 0.102 (0.102)	Loss 1.2837 (1.2837)	Prec@1 80.000 (80.000)
 * Testing Prec@1 76.430
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.174 (0.174)	Data 0.160 (0.160)	Loss 0.0241 (0.0241)	Prec@1 100.000 (100.000)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.024 (0.029)	Data 0.018 (0.023)	Loss 0.0281 (0.0441)	Prec@1 99.500 (98.916)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.025 (0.028)	Data 0.019 (0.021)	Loss 0.0411 (0.0449)	Prec@1 100.000 (98.928)
 * Training Prec@1 98.920
Test: [0/50]	Time 0.107 (0.107)	Loss 1.3880 (1.3880)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.560
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.122 (0.122)	Data 0.108 (0.108)	Loss 0.0480 (0.0480)	Prec@1 99.000 (99.000)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.021 (0.027)	Data 0.015 (0.021)	Loss 0.0521 (0.0354)	Prec@1 98.000 (99.327)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.025 (0.026)	Data 0.019 (0.020)	Loss 0.0193 (0.0367)	Prec@1 100.000 (99.266)
 * Training Prec@1 99.226
Test: [0/50]	Time 0.092 (0.092)	Loss 1.4588 (1.4588)	Prec@1 77.000 (77.000)
 * Testing Prec@1 76.210
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.108 (0.108)	Data 0.093 (0.093)	Loss 0.0230 (0.0230)	Prec@1 100.000 (100.000)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.026 (0.026)	Data 0.020 (0.020)	Loss 0.0341 (0.0307)	Prec@1 99.000 (99.446)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.026 (0.026)	Data 0.020 (0.020)	Loss 0.0495 (0.0305)	Prec@1 99.000 (99.435)
 * Training Prec@1 99.428
Test: [0/50]	Time 0.097 (0.097)	Loss 1.5038 (1.5038)	Prec@1 77.000 (77.000)
 * Testing Prec@1 76.330
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 0.104 (0.104)	Data 0.090 (0.090)	Loss 0.0217 (0.0217)	Prec@1 100.000 (100.000)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.027 (0.025)	Data 0.021 (0.019)	Loss 0.0314 (0.0244)	Prec@1 99.500 (99.624)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.024 (0.025)	Data 0.018 (0.019)	Loss 0.0212 (0.0252)	Prec@1 99.500 (99.590)
 * Training Prec@1 99.574
Test: [0/50]	Time 0.092 (0.092)	Loss 1.5432 (1.5432)	Prec@1 79.000 (79.000)
 * Testing Prec@1 76.450
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.113 (0.113)	Data 0.099 (0.099)	Loss 0.0111 (0.0111)	Prec@1 100.000 (100.000)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.026 (0.028)	Data 0.020 (0.021)	Loss 0.0159 (0.0202)	Prec@1 100.000 (99.812)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.028 (0.027)	Data 0.023 (0.021)	Loss 0.0215 (0.0212)	Prec@1 100.000 (99.739)
 * Training Prec@1 99.720
Test: [0/50]	Time 0.150 (0.150)	Loss 1.6222 (1.6222)	Prec@1 76.500 (76.500)
 * Testing Prec@1 76.210
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 0.153 (0.153)	Data 0.138 (0.138)	Loss 0.0243 (0.0243)	Prec@1 100.000 (100.000)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.025 (0.027)	Data 0.018 (0.021)	Loss 0.0164 (0.0178)	Prec@1 100.000 (99.822)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.026 (0.027)	Data 0.020 (0.020)	Loss 0.0187 (0.0184)	Prec@1 100.000 (99.808)
 * Training Prec@1 99.798
Test: [0/50]	Time 0.096 (0.096)	Loss 1.6814 (1.6814)	Prec@1 77.000 (77.000)
 * Testing Prec@1 76.310
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.103 (0.103)	Data 0.089 (0.089)	Loss 0.0186 (0.0186)	Prec@1 100.000 (100.000)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.028 (0.027)	Data 0.021 (0.020)	Loss 0.0174 (0.0148)	Prec@1 100.000 (99.891)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.022 (0.026)	Data 0.015 (0.020)	Loss 0.0281 (0.0152)	Prec@1 99.500 (99.888)
 * Training Prec@1 99.872
Test: [0/50]	Time 0.113 (0.113)	Loss 1.7778 (1.7778)	Prec@1 77.500 (77.500)
 * Testing Prec@1 76.210
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.150 (0.150)	Data 0.135 (0.135)	Loss 0.0117 (0.0117)	Prec@1 100.000 (100.000)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.030 (0.027)	Data 0.024 (0.021)	Loss 0.0122 (0.0131)	Prec@1 100.000 (99.921)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.026 (0.027)	Data 0.019 (0.021)	Loss 0.0063 (0.0129)	Prec@1 100.000 (99.905)
 * Training Prec@1 99.912
Test: [0/50]	Time 0.098 (0.098)	Loss 1.7978 (1.7978)	Prec@1 77.000 (77.000)
 * Testing Prec@1 76.150
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.170 (0.170)	Data 0.157 (0.157)	Loss 0.0059 (0.0059)	Prec@1 100.000 (100.000)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.024 (0.028)	Data 0.017 (0.022)	Loss 0.0079 (0.0101)	Prec@1 100.000 (99.960)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.034 (0.027)	Data 0.026 (0.021)	Loss 0.0150 (0.0107)	Prec@1 100.000 (99.953)
 * Training Prec@1 99.948
Test: [0/50]	Time 0.095 (0.095)	Loss 1.8331 (1.8331)	Prec@1 77.500 (77.500)
 * Testing Prec@1 76.440
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.166 (0.166)	Data 0.151 (0.151)	Loss 0.0062 (0.0062)	Prec@1 100.000 (100.000)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.024 (0.026)	Data 0.018 (0.019)	Loss 0.0080 (0.0096)	Prec@1 100.000 (99.960)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.024 (0.026)	Data 0.018 (0.019)	Loss 0.0078 (0.0095)	Prec@1 100.000 (99.963)
 * Training Prec@1 99.964
Test: [0/50]	Time 0.108 (0.108)	Loss 1.8945 (1.8945)	Prec@1 77.000 (77.000)
 * Testing Prec@1 76.400
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.158 (0.158)	Data 0.144 (0.144)	Loss 0.0093 (0.0093)	Prec@1 100.000 (100.000)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.022 (0.026)	Data 0.016 (0.019)	Loss 0.0118 (0.0088)	Prec@1 100.000 (99.946)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.022 (0.025)	Data 0.016 (0.019)	Loss 0.0085 (0.0086)	Prec@1 100.000 (99.960)
 * Training Prec@1 99.966
Test: [0/50]	Time 0.104 (0.104)	Loss 1.9273 (1.9273)	Prec@1 78.000 (78.000)
 * Testing Prec@1 76.340
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.159 (0.159)	Data 0.145 (0.145)	Loss 0.0045 (0.0045)	Prec@1 100.000 (100.000)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.034 (0.025)	Data 0.028 (0.019)	Loss 0.0073 (0.0071)	Prec@1 100.000 (99.970)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.026 (0.025)	Data 0.018 (0.019)	Loss 0.0052 (0.0072)	Prec@1 100.000 (99.978)
 * Training Prec@1 99.980
Test: [0/50]	Time 0.089 (0.089)	Loss 1.9739 (1.9739)	Prec@1 78.000 (78.000)
 * Testing Prec@1 76.260
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.156 (0.156)	Data 0.141 (0.141)	Loss 0.0054 (0.0054)	Prec@1 100.000 (100.000)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.022 (0.026)	Data 0.015 (0.020)	Loss 0.0047 (0.0060)	Prec@1 100.000 (99.985)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.026)	Data 0.020 (0.020)	Loss 0.0058 (0.0060)	Prec@1 100.000 (99.988)
 * Training Prec@1 99.988
Test: [0/50]	Time 0.095 (0.095)	Loss 1.9663 (1.9663)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.300
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.118 (0.118)	Data 0.103 (0.103)	Loss 0.0078 (0.0078)	Prec@1 100.000 (100.000)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.026 (0.027)	Data 0.020 (0.021)	Loss 0.0062 (0.0057)	Prec@1 100.000 (99.990)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.025 (0.026)	Data 0.018 (0.020)	Loss 0.0060 (0.0060)	Prec@1 100.000 (99.988)
 * Training Prec@1 99.988
Test: [0/50]	Time 0.101 (0.101)	Loss 1.9711 (1.9711)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.340
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.161 (0.161)	Data 0.148 (0.148)	Loss 0.0044 (0.0044)	Prec@1 100.000 (100.000)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.023 (0.027)	Data 0.017 (0.020)	Loss 0.0067 (0.0056)	Prec@1 100.000 (99.995)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.025 (0.026)	Data 0.019 (0.020)	Loss 0.0054 (0.0058)	Prec@1 100.000 (99.990)
 * Training Prec@1 99.988
Test: [0/50]	Time 0.083 (0.083)	Loss 1.9775 (1.9775)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.310
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 0.153 (0.153)	Data 0.139 (0.139)	Loss 0.0091 (0.0091)	Prec@1 100.000 (100.000)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.027)	Data 0.022 (0.021)	Loss 0.0026 (0.0058)	Prec@1 100.000 (99.990)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.023 (0.027)	Data 0.017 (0.021)	Loss 0.0062 (0.0058)	Prec@1 100.000 (99.993)
 * Training Prec@1 99.990
Test: [0/50]	Time 0.103 (0.103)	Loss 1.9816 (1.9816)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.330
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 0.113 (0.113)	Data 0.101 (0.101)	Loss 0.0075 (0.0075)	Prec@1 100.000 (100.000)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.023 (0.028)	Data 0.016 (0.021)	Loss 0.0055 (0.0057)	Prec@1 100.000 (99.985)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.026 (0.027)	Data 0.020 (0.020)	Loss 0.0050 (0.0058)	Prec@1 100.000 (99.988)
 * Training Prec@1 99.990
Test: [0/50]	Time 0.095 (0.095)	Loss 1.9847 (1.9847)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.320
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.126 (0.126)	Data 0.112 (0.112)	Loss 0.0039 (0.0039)	Prec@1 100.000 (100.000)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.028)	Data 0.022 (0.021)	Loss 0.0082 (0.0058)	Prec@1 100.000 (99.990)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.025 (0.027)	Data 0.019 (0.020)	Loss 0.0086 (0.0055)	Prec@1 100.000 (99.995)
 * Training Prec@1 99.990
Test: [0/50]	Time 0.096 (0.096)	Loss 1.9912 (1.9912)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.300
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 0.096 (0.096)	Data 0.081 (0.081)	Loss 0.0052 (0.0052)	Prec@1 100.000 (100.000)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.022 (0.025)	Data 0.017 (0.019)	Loss 0.0048 (0.0057)	Prec@1 100.000 (99.980)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.022 (0.026)	Data 0.017 (0.019)	Loss 0.0036 (0.0057)	Prec@1 100.000 (99.988)
 * Training Prec@1 99.990
Test: [0/50]	Time 0.112 (0.112)	Loss 1.9918 (1.9918)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.290
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.164 (0.164)	Data 0.149 (0.149)	Loss 0.0067 (0.0067)	Prec@1 100.000 (100.000)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.027 (0.028)	Data 0.020 (0.022)	Loss 0.0045 (0.0056)	Prec@1 100.000 (99.995)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.027)	Data 0.021 (0.020)	Loss 0.0029 (0.0056)	Prec@1 100.000 (99.990)
 * Training Prec@1 99.990
Test: [0/50]	Time 0.114 (0.114)	Loss 1.9960 (1.9960)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.280
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.110 (0.110)	Data 0.096 (0.096)	Loss 0.0035 (0.0035)	Prec@1 100.000 (100.000)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.027 (0.025)	Data 0.020 (0.019)	Loss 0.0063 (0.0053)	Prec@1 100.000 (100.000)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.026 (0.026)	Data 0.019 (0.020)	Loss 0.0050 (0.0055)	Prec@1 100.000 (99.993)
 * Training Prec@1 99.990
Test: [0/50]	Time 0.127 (0.127)	Loss 1.9982 (1.9982)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.290
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 0.111 (0.111)	Data 0.098 (0.098)	Loss 0.0023 (0.0023)	Prec@1 100.000 (100.000)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.023 (0.027)	Data 0.017 (0.021)	Loss 0.0060 (0.0052)	Prec@1 100.000 (100.000)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.027)	Data 0.021 (0.021)	Loss 0.0069 (0.0054)	Prec@1 100.000 (99.993)
 * Training Prec@1 99.992
Test: [0/50]	Time 0.094 (0.094)	Loss 2.0018 (2.0018)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.300
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.148 (0.148)	Data 0.134 (0.134)	Loss 0.0063 (0.0063)	Prec@1 100.000 (100.000)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.024 (0.027)	Data 0.018 (0.020)	Loss 0.0064 (0.0055)	Prec@1 100.000 (99.995)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.026 (0.026)	Data 0.019 (0.020)	Loss 0.0058 (0.0054)	Prec@1 100.000 (99.993)
 * Training Prec@1 99.994
Test: [0/50]	Time 0.124 (0.124)	Loss 2.0028 (2.0028)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.310
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.146 (0.146)	Data 0.132 (0.132)	Loss 0.0048 (0.0048)	Prec@1 100.000 (100.000)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.026 (0.028)	Data 0.020 (0.021)	Loss 0.0061 (0.0055)	Prec@1 100.000 (99.990)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.025 (0.027)	Data 0.018 (0.021)	Loss 0.0064 (0.0054)	Prec@1 100.000 (99.993)
 * Training Prec@1 99.994
Test: [0/50]	Time 0.105 (0.105)	Loss 2.0057 (2.0057)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.290
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.133 (0.133)	Data 0.119 (0.119)	Loss 0.0072 (0.0072)	Prec@1 100.000 (100.000)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.027 (0.027)	Data 0.022 (0.021)	Loss 0.0031 (0.0053)	Prec@1 100.000 (100.000)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.028 (0.027)	Data 0.021 (0.020)	Loss 0.0034 (0.0054)	Prec@1 100.000 (99.995)
 * Training Prec@1 99.996
Test: [0/50]	Time 0.108 (0.108)	Loss 2.0067 (2.0067)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.320
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 0.102 (0.102)	Data 0.088 (0.088)	Loss 0.0058 (0.0058)	Prec@1 100.000 (100.000)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.027)	Data 0.022 (0.020)	Loss 0.0058 (0.0052)	Prec@1 100.000 (100.000)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.025 (0.027)	Data 0.019 (0.021)	Loss 0.0044 (0.0053)	Prec@1 100.000 (99.995)
 * Training Prec@1 99.996
Test: [0/50]	Time 0.105 (0.105)	Loss 2.0110 (2.0110)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.330
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.103 (0.103)	Data 0.088 (0.088)	Loss 0.0053 (0.0053)	Prec@1 100.000 (100.000)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.028 (0.026)	Data 0.022 (0.020)	Loss 0.0072 (0.0049)	Prec@1 100.000 (99.995)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.026 (0.027)	Data 0.020 (0.020)	Loss 0.0080 (0.0052)	Prec@1 100.000 (99.995)
 * Training Prec@1 99.996
Test: [0/50]	Time 0.103 (0.103)	Loss 2.0125 (2.0125)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.330
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.101 (0.101)	Data 0.088 (0.088)	Loss 0.0036 (0.0036)	Prec@1 100.000 (100.000)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.025 (0.027)	Data 0.018 (0.020)	Loss 0.0089 (0.0053)	Prec@1 100.000 (100.000)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.028 (0.027)	Data 0.022 (0.021)	Loss 0.0040 (0.0052)	Prec@1 100.000 (99.998)
 * Training Prec@1 99.996
Test: [0/50]	Time 0.115 (0.115)	Loss 2.0162 (2.0162)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.340
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.097 (0.097)	Data 0.083 (0.083)	Loss 0.0060 (0.0060)	Prec@1 100.000 (100.000)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.027 (0.026)	Data 0.019 (0.020)	Loss 0.0042 (0.0051)	Prec@1 100.000 (100.000)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.027 (0.026)	Data 0.021 (0.020)	Loss 0.0051 (0.0052)	Prec@1 100.000 (99.998)
 * Training Prec@1 99.996
Test: [0/50]	Time 0.097 (0.097)	Loss 2.0176 (2.0176)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.340
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 0.118 (0.118)	Data 0.105 (0.105)	Loss 0.0046 (0.0046)	Prec@1 100.000 (100.000)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.029 (0.027)	Data 0.023 (0.020)	Loss 0.0063 (0.0051)	Prec@1 100.000 (99.995)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.025 (0.026)	Data 0.019 (0.020)	Loss 0.0040 (0.0051)	Prec@1 100.000 (99.995)
 * Training Prec@1 99.996
Test: [0/50]	Time 0.122 (0.122)	Loss 2.0205 (2.0205)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.300
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.141 (0.141)	Data 0.126 (0.126)	Loss 0.0044 (0.0044)	Prec@1 100.000 (100.000)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.022 (0.027)	Data 0.018 (0.020)	Loss 0.0035 (0.0051)	Prec@1 100.000 (99.995)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.026 (0.026)	Data 0.019 (0.020)	Loss 0.0070 (0.0051)	Prec@1 100.000 (99.998)
 * Training Prec@1 99.996
Test: [0/50]	Time 0.097 (0.097)	Loss 2.0216 (2.0216)	Prec@1 78.500 (78.500)
 * Testing Prec@1 76.320
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.097 (0.097)	Data 0.084 (0.084)	Loss 0.0039 (0.0039)	Prec@1 100.000 (100.000)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.022 (0.024)	Data 0.016 (0.018)	Loss 0.0033 (0.0053)	Prec@1 100.000 (99.990)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.022 (0.024)	Data 0.015 (0.017)	Loss 0.0046 (0.0051)	Prec@1 100.000 (99.995)
 * Training Prec@1 99.996
Test: [0/50]	Time 0.107 (0.107)	Loss 2.0262 (2.0262)	Prec@1 79.000 (79.000)
 * Testing Prec@1 76.280
