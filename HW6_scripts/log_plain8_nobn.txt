Building CIFAR-10 data loader with 1 workers
Files already downloaded and verified
CIFAR-10 training data size: 50000
Files already downloaded and verified
CIFAR-10 testing data size: 10000
=> creating model 'plainnet8'
Epoch: [0/80][0/250]	LR: 0.1	Time 0.530 (0.530)	Data 0.149 (0.149)	Loss 2.3105 (2.3105)	Prec@1 11.500 (11.500)
Epoch: [0/80][100/250]	LR: 0.1	Time 0.037 (0.050)	Data 0.031 (0.040)	Loss 2.0242 (2.1584)	Prec@1 16.000 (17.802)
Epoch: [0/80][200/250]	LR: 0.1	Time 0.035 (0.045)	Data 0.029 (0.037)	Loss 1.8566 (2.0591)	Prec@1 32.500 (21.281)
 * Training Prec@1 22.600
main.py:207: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Test: [0/50]	Time 0.126 (0.126)	Loss 1.8447 (1.8447)	Prec@1 29.500 (29.500)
 * Testing Prec@1 29.170
main.py:244: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  input_var = torch.autograd.Variable(input, volatile=True)
main.py:245: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.
  target_var = torch.autograd.Variable(target, volatile=True)
main.py:253: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number
  losses.update(loss.data[0], input.size(0))
Epoch: [1/80][0/250]	LR: 0.1	Time 0.136 (0.136)	Data 0.117 (0.117)	Loss 1.8450 (1.8450)	Prec@1 29.000 (29.000)
Epoch: [1/80][100/250]	LR: 0.1	Time 0.048 (0.044)	Data 0.041 (0.037)	Loss 1.7686 (1.8983)	Prec@1 36.500 (28.446)
Epoch: [1/80][200/250]	LR: 0.1	Time 0.035 (0.041)	Data 0.030 (0.035)	Loss 1.6996 (1.8401)	Prec@1 35.500 (30.756)
 * Training Prec@1 31.700
Test: [0/50]	Time 0.145 (0.145)	Loss 1.6172 (1.6172)	Prec@1 41.500 (41.500)
 * Testing Prec@1 39.760
Epoch: [2/80][0/250]	LR: 0.1	Time 0.183 (0.183)	Data 0.169 (0.169)	Loss 1.6789 (1.6789)	Prec@1 37.500 (37.500)
Epoch: [2/80][100/250]	LR: 0.1	Time 0.036 (0.042)	Data 0.030 (0.036)	Loss 1.6510 (1.6447)	Prec@1 43.000 (37.941)
Epoch: [2/80][200/250]	LR: 0.1	Time 0.038 (0.042)	Data 0.031 (0.035)	Loss 1.5893 (1.6332)	Prec@1 44.500 (38.900)
 * Training Prec@1 39.552
Test: [0/50]	Time 0.151 (0.151)	Loss 1.5770 (1.5770)	Prec@1 41.000 (41.000)
 * Testing Prec@1 39.680
Epoch: [3/80][0/250]	LR: 0.1	Time 0.153 (0.153)	Data 0.137 (0.137)	Loss 1.7405 (1.7405)	Prec@1 37.000 (37.000)
Epoch: [3/80][100/250]	LR: 0.1	Time 0.063 (0.046)	Data 0.057 (0.039)	Loss 1.4473 (1.5520)	Prec@1 47.000 (43.381)
Epoch: [3/80][200/250]	LR: 0.1	Time 0.037 (0.045)	Data 0.030 (0.038)	Loss 1.2431 (1.5148)	Prec@1 51.000 (44.607)
 * Training Prec@1 45.200
Test: [0/50]	Time 0.137 (0.137)	Loss 1.4242 (1.4242)	Prec@1 45.500 (45.500)
 * Testing Prec@1 47.270
Epoch: [4/80][0/250]	LR: 0.1	Time 0.233 (0.233)	Data 0.217 (0.217)	Loss 1.4538 (1.4538)	Prec@1 44.500 (44.500)
Epoch: [4/80][100/250]	LR: 0.1	Time 0.040 (0.045)	Data 0.032 (0.038)	Loss 1.2995 (1.3982)	Prec@1 52.500 (48.871)
Epoch: [4/80][200/250]	LR: 0.1	Time 0.040 (0.042)	Data 0.033 (0.035)	Loss 1.4418 (1.3785)	Prec@1 44.000 (49.711)
 * Training Prec@1 50.200
Test: [0/50]	Time 0.137 (0.137)	Loss 1.3232 (1.3232)	Prec@1 52.000 (52.000)
 * Testing Prec@1 52.090
Epoch: [5/80][0/250]	LR: 0.1	Time 0.227 (0.227)	Data 0.211 (0.211)	Loss 1.4073 (1.4073)	Prec@1 48.500 (48.500)
Epoch: [5/80][100/250]	LR: 0.1	Time 0.037 (0.045)	Data 0.031 (0.038)	Loss 1.3280 (1.2964)	Prec@1 55.500 (53.668)
Epoch: [5/80][200/250]	LR: 0.1	Time 0.046 (0.043)	Data 0.039 (0.036)	Loss 1.2185 (1.2650)	Prec@1 56.000 (54.803)
 * Training Prec@1 54.958
Test: [0/50]	Time 0.143 (0.143)	Loss 1.2594 (1.2594)	Prec@1 53.500 (53.500)
 * Testing Prec@1 53.840
Epoch: [6/80][0/250]	LR: 0.1	Time 0.223 (0.223)	Data 0.207 (0.207)	Loss 1.1003 (1.1003)	Prec@1 64.000 (64.000)
Epoch: [6/80][100/250]	LR: 0.1	Time 0.036 (0.041)	Data 0.030 (0.034)	Loss 1.1722 (1.1993)	Prec@1 58.000 (57.079)
Epoch: [6/80][200/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.031 (0.032)	Loss 1.0756 (1.1778)	Prec@1 63.500 (58.139)
 * Training Prec@1 58.648
Test: [0/50]	Time 0.100 (0.100)	Loss 1.1249 (1.1249)	Prec@1 60.500 (60.500)
 * Testing Prec@1 59.840
Epoch: [7/80][0/250]	LR: 0.1	Time 0.216 (0.216)	Data 0.201 (0.201)	Loss 1.1040 (1.1040)	Prec@1 62.000 (62.000)
Epoch: [7/80][100/250]	LR: 0.1	Time 0.039 (0.044)	Data 0.032 (0.037)	Loss 1.1267 (1.1243)	Prec@1 61.500 (60.446)
Epoch: [7/80][200/250]	LR: 0.1	Time 0.048 (0.043)	Data 0.041 (0.036)	Loss 1.0086 (1.0995)	Prec@1 66.500 (61.169)
 * Training Prec@1 61.614
Test: [0/50]	Time 0.133 (0.133)	Loss 1.0785 (1.0785)	Prec@1 62.500 (62.500)
 * Testing Prec@1 62.730
Epoch: [8/80][0/250]	LR: 0.1	Time 0.227 (0.227)	Data 0.209 (0.209)	Loss 1.0524 (1.0524)	Prec@1 64.500 (64.500)
Epoch: [8/80][100/250]	LR: 0.1	Time 0.042 (0.043)	Data 0.035 (0.036)	Loss 1.1682 (1.0442)	Prec@1 59.000 (63.381)
Epoch: [8/80][200/250]	LR: 0.1	Time 0.038 (0.042)	Data 0.031 (0.036)	Loss 0.9170 (1.0455)	Prec@1 68.000 (63.229)
 * Training Prec@1 63.680
Test: [0/50]	Time 0.134 (0.134)	Loss 0.9876 (0.9876)	Prec@1 61.500 (61.500)
 * Testing Prec@1 65.180
Epoch: [9/80][0/250]	LR: 0.1	Time 0.227 (0.227)	Data 0.210 (0.210)	Loss 0.9964 (0.9964)	Prec@1 65.000 (65.000)
Epoch: [9/80][100/250]	LR: 0.1	Time 0.037 (0.047)	Data 0.032 (0.040)	Loss 0.9171 (0.9812)	Prec@1 64.500 (65.941)
Epoch: [9/80][200/250]	LR: 0.1	Time 0.036 (0.042)	Data 0.031 (0.036)	Loss 0.8613 (0.9833)	Prec@1 68.500 (65.943)
 * Training Prec@1 66.158
Test: [0/50]	Time 0.125 (0.125)	Loss 1.0219 (1.0219)	Prec@1 64.500 (64.500)
 * Testing Prec@1 66.860
Epoch: [10/80][0/250]	LR: 0.1	Time 0.182 (0.182)	Data 0.168 (0.168)	Loss 0.9643 (0.9643)	Prec@1 65.500 (65.500)
Epoch: [10/80][100/250]	LR: 0.1	Time 0.035 (0.038)	Data 0.028 (0.032)	Loss 1.0050 (0.9592)	Prec@1 63.000 (66.757)
Epoch: [10/80][200/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.030 (0.031)	Loss 0.9173 (0.9448)	Prec@1 68.500 (67.266)
 * Training Prec@1 67.698
Test: [0/50]	Time 0.139 (0.139)	Loss 0.8739 (0.8739)	Prec@1 72.500 (72.500)
 * Testing Prec@1 70.120
Epoch: [11/80][0/250]	LR: 0.1	Time 0.211 (0.211)	Data 0.195 (0.195)	Loss 0.8164 (0.8164)	Prec@1 67.500 (67.500)
Epoch: [11/80][100/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.030 (0.032)	Loss 0.8778 (0.9101)	Prec@1 73.000 (68.832)
Epoch: [11/80][200/250]	LR: 0.1	Time 0.037 (0.038)	Data 0.030 (0.031)	Loss 0.9380 (0.9068)	Prec@1 68.000 (68.878)
 * Training Prec@1 68.896
Test: [0/50]	Time 0.142 (0.142)	Loss 0.9532 (0.9532)	Prec@1 67.500 (67.500)
 * Testing Prec@1 70.340
Epoch: [12/80][0/250]	LR: 0.1	Time 0.107 (0.107)	Data 0.094 (0.094)	Loss 0.9526 (0.9526)	Prec@1 65.500 (65.500)
Epoch: [12/80][100/250]	LR: 0.1	Time 0.036 (0.042)	Data 0.030 (0.036)	Loss 0.8487 (0.8748)	Prec@1 72.000 (69.698)
Epoch: [12/80][200/250]	LR: 0.1	Time 0.046 (0.042)	Data 0.039 (0.035)	Loss 0.7197 (0.8642)	Prec@1 80.500 (70.231)
 * Training Prec@1 70.544
Test: [0/50]	Time 0.150 (0.150)	Loss 0.8551 (0.8551)	Prec@1 69.500 (69.500)
 * Testing Prec@1 71.300
Epoch: [13/80][0/250]	LR: 0.1	Time 0.230 (0.230)	Data 0.215 (0.215)	Loss 0.8923 (0.8923)	Prec@1 67.500 (67.500)
Epoch: [13/80][100/250]	LR: 0.1	Time 0.057 (0.047)	Data 0.050 (0.041)	Loss 0.8555 (0.8501)	Prec@1 74.000 (71.045)
Epoch: [13/80][200/250]	LR: 0.1	Time 0.044 (0.047)	Data 0.039 (0.040)	Loss 0.9248 (0.8526)	Prec@1 70.000 (70.836)
 * Training Prec@1 70.756
Test: [0/50]	Time 0.148 (0.148)	Loss 0.9332 (0.9332)	Prec@1 70.000 (70.000)
 * Testing Prec@1 71.940
Epoch: [14/80][0/250]	LR: 0.1	Time 0.248 (0.248)	Data 0.231 (0.231)	Loss 0.8105 (0.8105)	Prec@1 73.500 (73.500)
Epoch: [14/80][100/250]	LR: 0.1	Time 0.040 (0.049)	Data 0.033 (0.042)	Loss 0.9481 (0.8150)	Prec@1 69.000 (72.416)
Epoch: [14/80][200/250]	LR: 0.1	Time 0.036 (0.046)	Data 0.029 (0.039)	Loss 0.7940 (0.8127)	Prec@1 74.000 (72.400)
 * Training Prec@1 72.328
Test: [0/50]	Time 0.136 (0.136)	Loss 0.9402 (0.9402)	Prec@1 65.000 (65.000)
 * Testing Prec@1 67.940
Epoch: [15/80][0/250]	LR: 0.1	Time 0.199 (0.199)	Data 0.183 (0.183)	Loss 0.9470 (0.9470)	Prec@1 67.000 (67.000)
Epoch: [15/80][100/250]	LR: 0.1	Time 0.046 (0.045)	Data 0.041 (0.039)	Loss 0.8479 (0.8081)	Prec@1 72.500 (72.490)
Epoch: [15/80][200/250]	LR: 0.1	Time 0.036 (0.045)	Data 0.030 (0.039)	Loss 0.9286 (0.8114)	Prec@1 68.500 (72.435)
 * Training Prec@1 72.508
Test: [0/50]	Time 0.121 (0.121)	Loss 0.9623 (0.9623)	Prec@1 68.500 (68.500)
 * Testing Prec@1 70.930
Epoch: [16/80][0/250]	LR: 0.1	Time 0.196 (0.196)	Data 0.179 (0.179)	Loss 0.6393 (0.6393)	Prec@1 79.500 (79.500)
Epoch: [16/80][100/250]	LR: 0.1	Time 0.036 (0.039)	Data 0.029 (0.032)	Loss 0.7320 (0.7722)	Prec@1 77.000 (73.960)
Epoch: [16/80][200/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.029 (0.031)	Loss 0.7626 (0.7704)	Prec@1 70.000 (73.990)
 * Training Prec@1 73.728
Test: [0/50]	Time 0.138 (0.138)	Loss 0.8200 (0.8200)	Prec@1 72.500 (72.500)
 * Testing Prec@1 73.500
Epoch: [17/80][0/250]	LR: 0.1	Time 0.225 (0.225)	Data 0.207 (0.207)	Loss 0.7798 (0.7798)	Prec@1 74.000 (74.000)
Epoch: [17/80][100/250]	LR: 0.1	Time 0.037 (0.048)	Data 0.030 (0.041)	Loss 0.7982 (0.7586)	Prec@1 71.500 (74.178)
Epoch: [17/80][200/250]	LR: 0.1	Time 0.037 (0.045)	Data 0.030 (0.038)	Loss 0.8299 (0.7660)	Prec@1 69.000 (73.881)
 * Training Prec@1 74.046
Test: [0/50]	Time 0.144 (0.144)	Loss 0.7674 (0.7674)	Prec@1 76.000 (76.000)
 * Testing Prec@1 74.350
Epoch: [18/80][0/250]	LR: 0.1	Time 0.226 (0.226)	Data 0.211 (0.211)	Loss 0.7290 (0.7290)	Prec@1 76.000 (76.000)
Epoch: [18/80][100/250]	LR: 0.1	Time 0.050 (0.047)	Data 0.043 (0.040)	Loss 0.6787 (0.7433)	Prec@1 78.000 (74.921)
Epoch: [18/80][200/250]	LR: 0.1	Time 0.037 (0.044)	Data 0.031 (0.037)	Loss 0.7145 (0.7611)	Prec@1 75.500 (74.241)
 * Training Prec@1 74.194
Test: [0/50]	Time 0.137 (0.137)	Loss 0.9460 (0.9460)	Prec@1 72.500 (72.500)
 * Testing Prec@1 70.450
Epoch: [19/80][0/250]	LR: 0.1	Time 0.216 (0.216)	Data 0.200 (0.200)	Loss 0.9136 (0.9136)	Prec@1 69.500 (69.500)
Epoch: [19/80][100/250]	LR: 0.1	Time 0.037 (0.040)	Data 0.030 (0.033)	Loss 0.7457 (0.7443)	Prec@1 73.500 (74.683)
Epoch: [19/80][200/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.029 (0.031)	Loss 0.7627 (0.7547)	Prec@1 75.500 (74.244)
 * Training Prec@1 74.474
Test: [0/50]	Time 0.124 (0.124)	Loss 0.7798 (0.7798)	Prec@1 74.500 (74.500)
 * Testing Prec@1 74.710
Epoch: [20/80][0/250]	LR: 0.1	Time 0.219 (0.219)	Data 0.204 (0.204)	Loss 0.7119 (0.7119)	Prec@1 73.000 (73.000)
Epoch: [20/80][100/250]	LR: 0.1	Time 0.054 (0.049)	Data 0.047 (0.041)	Loss 0.5924 (0.7378)	Prec@1 78.000 (74.960)
Epoch: [20/80][200/250]	LR: 0.1	Time 0.052 (0.046)	Data 0.045 (0.039)	Loss 0.6222 (0.7348)	Prec@1 82.000 (75.032)
 * Training Prec@1 74.742
Test: [0/50]	Time 0.140 (0.140)	Loss 0.7664 (0.7664)	Prec@1 75.000 (75.000)
 * Testing Prec@1 75.370
Epoch: [21/80][0/250]	LR: 0.1	Time 0.152 (0.152)	Data 0.136 (0.136)	Loss 0.7843 (0.7843)	Prec@1 72.000 (72.000)
Epoch: [21/80][100/250]	LR: 0.1	Time 0.037 (0.049)	Data 0.031 (0.041)	Loss 0.6536 (0.7335)	Prec@1 78.500 (75.144)
Epoch: [21/80][200/250]	LR: 0.1	Time 0.038 (0.045)	Data 0.031 (0.038)	Loss 0.7910 (0.7336)	Prec@1 74.000 (75.197)
 * Training Prec@1 75.286
Test: [0/50]	Time 0.144 (0.144)	Loss 0.7945 (0.7945)	Prec@1 76.000 (76.000)
 * Testing Prec@1 74.890
Epoch: [22/80][0/250]	LR: 0.1	Time 0.187 (0.187)	Data 0.171 (0.171)	Loss 0.6745 (0.6745)	Prec@1 80.000 (80.000)
Epoch: [22/80][100/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.030 (0.032)	Loss 0.7918 (0.7134)	Prec@1 71.000 (75.639)
Epoch: [22/80][200/250]	LR: 0.1	Time 0.036 (0.038)	Data 0.030 (0.031)	Loss 0.6356 (0.7244)	Prec@1 76.000 (75.261)
 * Training Prec@1 75.336
Test: [0/50]	Time 0.142 (0.142)	Loss 0.8710 (0.8710)	Prec@1 73.000 (73.000)
 * Testing Prec@1 73.930
Epoch: [23/80][0/250]	LR: 0.1	Time 0.131 (0.131)	Data 0.116 (0.116)	Loss 0.7344 (0.7344)	Prec@1 77.000 (77.000)
Epoch: [23/80][100/250]	LR: 0.1	Time 0.035 (0.040)	Data 0.030 (0.034)	Loss 0.7639 (0.6988)	Prec@1 73.000 (76.084)
Epoch: [23/80][200/250]	LR: 0.1	Time 0.068 (0.040)	Data 0.061 (0.033)	Loss 0.9000 (0.7080)	Prec@1 69.500 (75.811)
 * Training Prec@1 76.020
Test: [0/50]	Time 0.126 (0.126)	Loss 0.7987 (0.7987)	Prec@1 74.000 (74.000)
 * Testing Prec@1 74.120
Epoch: [24/80][0/250]	LR: 0.1	Time 0.178 (0.178)	Data 0.163 (0.163)	Loss 0.7132 (0.7132)	Prec@1 75.500 (75.500)
Epoch: [24/80][100/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.030 (0.032)	Loss 0.4908 (0.6977)	Prec@1 83.500 (76.243)
Epoch: [24/80][200/250]	LR: 0.1	Time 0.047 (0.040)	Data 0.040 (0.033)	Loss 0.7394 (0.6967)	Prec@1 73.500 (76.289)
 * Training Prec@1 76.198
Test: [0/50]	Time 0.150 (0.150)	Loss 0.9072 (0.9072)	Prec@1 74.000 (74.000)
 * Testing Prec@1 75.770
Epoch: [25/80][0/250]	LR: 0.1	Time 0.228 (0.228)	Data 0.214 (0.214)	Loss 0.4945 (0.4945)	Prec@1 84.500 (84.500)
Epoch: [25/80][100/250]	LR: 0.1	Time 0.036 (0.044)	Data 0.030 (0.037)	Loss 0.7995 (0.6952)	Prec@1 73.000 (76.550)
Epoch: [25/80][200/250]	LR: 0.1	Time 0.039 (0.043)	Data 0.034 (0.036)	Loss 0.7704 (0.6860)	Prec@1 78.000 (76.781)
 * Training Prec@1 76.820
Test: [0/50]	Time 0.122 (0.122)	Loss 0.7359 (0.7359)	Prec@1 75.500 (75.500)
 * Testing Prec@1 74.640
Epoch: [26/80][0/250]	LR: 0.1	Time 0.113 (0.113)	Data 0.100 (0.100)	Loss 0.6881 (0.6881)	Prec@1 77.000 (77.000)
Epoch: [26/80][100/250]	LR: 0.1	Time 0.038 (0.040)	Data 0.033 (0.034)	Loss 0.7156 (0.6821)	Prec@1 74.000 (76.644)
Epoch: [26/80][200/250]	LR: 0.1	Time 0.036 (0.041)	Data 0.030 (0.035)	Loss 0.7734 (0.7000)	Prec@1 76.500 (76.092)
 * Training Prec@1 76.000
Test: [0/50]	Time 0.135 (0.135)	Loss 0.7720 (0.7720)	Prec@1 75.500 (75.500)
 * Testing Prec@1 76.580
Epoch: [27/80][0/250]	LR: 0.1	Time 0.237 (0.237)	Data 0.220 (0.220)	Loss 0.6302 (0.6302)	Prec@1 81.000 (81.000)
Epoch: [27/80][100/250]	LR: 0.1	Time 0.037 (0.044)	Data 0.030 (0.037)	Loss 0.7421 (0.6656)	Prec@1 77.000 (77.054)
Epoch: [27/80][200/250]	LR: 0.1	Time 0.038 (0.044)	Data 0.032 (0.037)	Loss 0.5142 (0.6669)	Prec@1 86.000 (77.137)
 * Training Prec@1 76.980
Test: [0/50]	Time 0.131 (0.131)	Loss 0.8218 (0.8218)	Prec@1 74.000 (74.000)
 * Testing Prec@1 74.620
Epoch: [28/80][0/250]	LR: 0.1	Time 0.163 (0.163)	Data 0.147 (0.147)	Loss 0.6245 (0.6245)	Prec@1 76.000 (76.000)
Epoch: [28/80][100/250]	LR: 0.1	Time 0.047 (0.040)	Data 0.040 (0.033)	Loss 0.6733 (0.6768)	Prec@1 76.000 (76.906)
Epoch: [28/80][200/250]	LR: 0.1	Time 0.038 (0.039)	Data 0.032 (0.032)	Loss 0.7592 (0.6779)	Prec@1 72.000 (76.861)
 * Training Prec@1 76.894
Test: [0/50]	Time 0.148 (0.148)	Loss 0.6958 (0.6958)	Prec@1 73.000 (73.000)
 * Testing Prec@1 77.000
Epoch: [29/80][0/250]	LR: 0.1	Time 0.237 (0.237)	Data 0.220 (0.220)	Loss 0.6605 (0.6605)	Prec@1 78.000 (78.000)
Epoch: [29/80][100/250]	LR: 0.1	Time 0.037 (0.047)	Data 0.030 (0.040)	Loss 0.7122 (0.6594)	Prec@1 78.000 (77.223)
Epoch: [29/80][200/250]	LR: 0.1	Time 0.040 (0.045)	Data 0.033 (0.038)	Loss 0.7199 (0.6691)	Prec@1 72.000 (77.055)
 * Training Prec@1 77.168
Test: [0/50]	Time 0.137 (0.137)	Loss 0.6904 (0.6904)	Prec@1 79.500 (79.500)
 * Testing Prec@1 77.670
Epoch: [30/80][0/250]	LR: 0.1	Time 0.235 (0.235)	Data 0.218 (0.218)	Loss 0.5653 (0.5653)	Prec@1 80.000 (80.000)
Epoch: [30/80][100/250]	LR: 0.1	Time 0.036 (0.046)	Data 0.029 (0.039)	Loss 0.5439 (0.6651)	Prec@1 82.500 (77.441)
Epoch: [30/80][200/250]	LR: 0.1	Time 0.039 (0.043)	Data 0.032 (0.036)	Loss 0.7309 (0.6617)	Prec@1 75.500 (77.478)
 * Training Prec@1 77.416
Test: [0/50]	Time 0.157 (0.157)	Loss 0.7348 (0.7348)	Prec@1 78.000 (78.000)
 * Testing Prec@1 77.030
Epoch: [31/80][0/250]	LR: 0.1	Time 0.223 (0.223)	Data 0.206 (0.206)	Loss 0.6820 (0.6820)	Prec@1 82.000 (82.000)
Epoch: [31/80][100/250]	LR: 0.1	Time 0.037 (0.042)	Data 0.030 (0.035)	Loss 0.6741 (0.6530)	Prec@1 76.500 (77.856)
Epoch: [31/80][200/250]	LR: 0.1	Time 0.046 (0.040)	Data 0.039 (0.033)	Loss 0.6702 (0.6501)	Prec@1 77.500 (77.886)
 * Training Prec@1 77.890
Test: [0/50]	Time 0.138 (0.138)	Loss 0.7796 (0.7796)	Prec@1 74.500 (74.500)
 * Testing Prec@1 76.070
Epoch: [32/80][0/250]	LR: 0.1	Time 0.144 (0.144)	Data 0.127 (0.127)	Loss 0.7065 (0.7065)	Prec@1 74.000 (74.000)
Epoch: [32/80][100/250]	LR: 0.1	Time 0.034 (0.042)	Data 0.027 (0.035)	Loss 0.5217 (0.6530)	Prec@1 81.500 (77.926)
Epoch: [32/80][200/250]	LR: 0.1	Time 0.042 (0.042)	Data 0.035 (0.035)	Loss 0.7372 (0.6625)	Prec@1 73.500 (77.530)
 * Training Prec@1 77.570
Test: [0/50]	Time 0.144 (0.144)	Loss 0.8699 (0.8699)	Prec@1 72.500 (72.500)
 * Testing Prec@1 74.990
Epoch: [33/80][0/250]	LR: 0.1	Time 0.186 (0.186)	Data 0.170 (0.170)	Loss 0.9595 (0.9595)	Prec@1 68.000 (68.000)
Epoch: [33/80][100/250]	LR: 0.1	Time 0.050 (0.043)	Data 0.043 (0.036)	Loss 0.6708 (0.6427)	Prec@1 77.500 (78.064)
Epoch: [33/80][200/250]	LR: 0.1	Time 0.038 (0.042)	Data 0.031 (0.035)	Loss 0.6468 (0.6439)	Prec@1 78.500 (78.169)
 * Training Prec@1 77.918
Test: [0/50]	Time 0.137 (0.137)	Loss 0.7094 (0.7094)	Prec@1 76.000 (76.000)
 * Testing Prec@1 77.800
Epoch: [34/80][0/250]	LR: 0.1	Time 0.225 (0.225)	Data 0.208 (0.208)	Loss 0.6751 (0.6751)	Prec@1 78.000 (78.000)
Epoch: [34/80][100/250]	LR: 0.1	Time 0.070 (0.046)	Data 0.063 (0.039)	Loss 0.6060 (0.6412)	Prec@1 78.000 (78.421)
Epoch: [34/80][200/250]	LR: 0.1	Time 0.050 (0.045)	Data 0.043 (0.038)	Loss 0.6636 (0.6424)	Prec@1 78.000 (78.187)
 * Training Prec@1 78.220
Test: [0/50]	Time 0.140 (0.140)	Loss 0.6801 (0.6801)	Prec@1 77.500 (77.500)
 * Testing Prec@1 77.450
Epoch: [35/80][0/250]	LR: 0.1	Time 0.150 (0.150)	Data 0.136 (0.136)	Loss 0.5687 (0.5687)	Prec@1 82.000 (82.000)
Epoch: [35/80][100/250]	LR: 0.1	Time 0.039 (0.043)	Data 0.033 (0.036)	Loss 0.5841 (0.6401)	Prec@1 79.000 (78.163)
Epoch: [35/80][200/250]	LR: 0.1	Time 0.059 (0.041)	Data 0.052 (0.034)	Loss 0.6162 (0.6400)	Prec@1 73.000 (78.097)
 * Training Prec@1 78.080
Test: [0/50]	Time 0.133 (0.133)	Loss 0.7581 (0.7581)	Prec@1 77.500 (77.500)
 * Testing Prec@1 78.070
Epoch: [36/80][0/250]	LR: 0.1	Time 0.227 (0.227)	Data 0.209 (0.209)	Loss 0.7165 (0.7165)	Prec@1 76.000 (76.000)
Epoch: [36/80][100/250]	LR: 0.1	Time 0.067 (0.052)	Data 0.059 (0.045)	Loss 0.5444 (0.6221)	Prec@1 81.000 (79.054)
Epoch: [36/80][200/250]	LR: 0.1	Time 0.036 (0.048)	Data 0.030 (0.041)	Loss 0.6819 (0.6369)	Prec@1 80.000 (78.435)
 * Training Prec@1 78.366
Test: [0/50]	Time 0.135 (0.135)	Loss 0.8720 (0.8720)	Prec@1 75.000 (75.000)
 * Testing Prec@1 74.790
Epoch: [37/80][0/250]	LR: 0.1	Time 0.156 (0.156)	Data 0.138 (0.138)	Loss 0.6700 (0.6700)	Prec@1 78.500 (78.500)
Epoch: [37/80][100/250]	LR: 0.1	Time 0.038 (0.040)	Data 0.031 (0.033)	Loss 0.5816 (0.6164)	Prec@1 81.500 (79.025)
Epoch: [37/80][200/250]	LR: 0.1	Time 0.048 (0.039)	Data 0.042 (0.033)	Loss 0.6927 (0.6379)	Prec@1 74.500 (78.328)
 * Training Prec@1 78.336
Test: [0/50]	Time 0.126 (0.126)	Loss 0.7152 (0.7152)	Prec@1 74.500 (74.500)
 * Testing Prec@1 77.500
Epoch: [38/80][0/250]	LR: 0.1	Time 0.135 (0.135)	Data 0.119 (0.119)	Loss 0.5786 (0.5786)	Prec@1 79.500 (79.500)
Epoch: [38/80][100/250]	LR: 0.1	Time 0.037 (0.039)	Data 0.031 (0.032)	Loss 0.5974 (0.6077)	Prec@1 80.000 (79.421)
Epoch: [38/80][200/250]	LR: 0.1	Time 0.039 (0.039)	Data 0.032 (0.033)	Loss 0.6966 (0.6263)	Prec@1 77.500 (78.813)
 * Training Prec@1 78.710
Test: [0/50]	Time 0.136 (0.136)	Loss 0.8069 (0.8069)	Prec@1 77.000 (77.000)
 * Testing Prec@1 77.340
Epoch: [39/80][0/250]	LR: 0.1	Time 0.127 (0.127)	Data 0.111 (0.111)	Loss 0.6822 (0.6822)	Prec@1 79.500 (79.500)
Epoch: [39/80][100/250]	LR: 0.1	Time 0.047 (0.039)	Data 0.041 (0.032)	Loss 0.7072 (0.6368)	Prec@1 80.500 (78.223)
Epoch: [39/80][200/250]	LR: 0.1	Time 0.037 (0.042)	Data 0.031 (0.035)	Loss 0.5463 (0.6397)	Prec@1 81.000 (78.042)
 * Training Prec@1 78.114
Test: [0/50]	Time 0.139 (0.139)	Loss 0.8098 (0.8098)	Prec@1 75.000 (75.000)
 * Testing Prec@1 77.900
Epoch: [40/80][0/250]	LR: 0.010000000000000002	Time 0.105 (0.105)	Data 0.091 (0.091)	Loss 0.5713 (0.5713)	Prec@1 77.000 (77.000)
Epoch: [40/80][100/250]	LR: 0.010000000000000002	Time 0.038 (0.042)	Data 0.031 (0.036)	Loss 0.4879 (0.5208)	Prec@1 84.000 (82.282)
Epoch: [40/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.042)	Data 0.033 (0.035)	Loss 0.5103 (0.5086)	Prec@1 82.500 (82.831)
 * Training Prec@1 82.932
Test: [0/50]	Time 0.136 (0.136)	Loss 0.6166 (0.6166)	Prec@1 79.500 (79.500)
 * Testing Prec@1 82.110
Epoch: [41/80][0/250]	LR: 0.010000000000000002	Time 0.202 (0.202)	Data 0.188 (0.188)	Loss 0.4723 (0.4723)	Prec@1 83.500 (83.500)
Epoch: [41/80][100/250]	LR: 0.010000000000000002	Time 0.061 (0.048)	Data 0.055 (0.041)	Loss 0.4204 (0.4749)	Prec@1 84.000 (83.624)
Epoch: [41/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.047)	Data 0.030 (0.040)	Loss 0.4136 (0.4676)	Prec@1 88.500 (84.042)
 * Training Prec@1 84.018
Test: [0/50]	Time 0.143 (0.143)	Loss 0.6018 (0.6018)	Prec@1 80.500 (80.500)
 * Testing Prec@1 82.330
Epoch: [42/80][0/250]	LR: 0.010000000000000002	Time 0.213 (0.213)	Data 0.196 (0.196)	Loss 0.4689 (0.4689)	Prec@1 85.000 (85.000)
Epoch: [42/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.041)	Data 0.031 (0.035)	Loss 0.3622 (0.4535)	Prec@1 89.000 (84.361)
Epoch: [42/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.041)	Data 0.031 (0.034)	Loss 0.4078 (0.4556)	Prec@1 88.500 (84.388)
 * Training Prec@1 84.286
Test: [0/50]	Time 0.135 (0.135)	Loss 0.6255 (0.6255)	Prec@1 81.000 (81.000)
 * Testing Prec@1 82.330
Epoch: [43/80][0/250]	LR: 0.010000000000000002	Time 0.156 (0.156)	Data 0.140 (0.140)	Loss 0.4549 (0.4549)	Prec@1 84.000 (84.000)
Epoch: [43/80][100/250]	LR: 0.010000000000000002	Time 0.036 (0.042)	Data 0.031 (0.036)	Loss 0.3585 (0.4425)	Prec@1 89.500 (84.733)
Epoch: [43/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.040)	Data 0.031 (0.034)	Loss 0.4462 (0.4482)	Prec@1 83.500 (84.614)
 * Training Prec@1 84.696
Test: [0/50]	Time 0.150 (0.150)	Loss 0.5804 (0.5804)	Prec@1 82.500 (82.500)
 * Testing Prec@1 82.560
Epoch: [44/80][0/250]	LR: 0.010000000000000002	Time 0.226 (0.226)	Data 0.210 (0.210)	Loss 0.3864 (0.3864)	Prec@1 86.000 (86.000)
Epoch: [44/80][100/250]	LR: 0.010000000000000002	Time 0.039 (0.046)	Data 0.033 (0.039)	Loss 0.3485 (0.4403)	Prec@1 86.500 (84.738)
Epoch: [44/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.045)	Data 0.031 (0.038)	Loss 0.4039 (0.4420)	Prec@1 88.500 (84.866)
 * Training Prec@1 84.880
Test: [0/50]	Time 0.125 (0.125)	Loss 0.5775 (0.5775)	Prec@1 81.500 (81.500)
 * Testing Prec@1 82.870
Epoch: [45/80][0/250]	LR: 0.010000000000000002	Time 0.135 (0.135)	Data 0.119 (0.119)	Loss 0.4070 (0.4070)	Prec@1 86.500 (86.500)
Epoch: [45/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.040)	Data 0.031 (0.033)	Loss 0.4540 (0.4356)	Prec@1 84.000 (85.153)
Epoch: [45/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.041)	Data 0.030 (0.034)	Loss 0.4099 (0.4362)	Prec@1 86.000 (85.172)
 * Training Prec@1 85.048
Test: [0/50]	Time 0.122 (0.122)	Loss 0.5721 (0.5721)	Prec@1 82.500 (82.500)
 * Testing Prec@1 82.740
Epoch: [46/80][0/250]	LR: 0.010000000000000002	Time 0.146 (0.146)	Data 0.131 (0.131)	Loss 0.4413 (0.4413)	Prec@1 87.000 (87.000)
Epoch: [46/80][100/250]	LR: 0.010000000000000002	Time 0.038 (0.040)	Data 0.031 (0.033)	Loss 0.4625 (0.4288)	Prec@1 89.000 (85.218)
Epoch: [46/80][200/250]	LR: 0.010000000000000002	Time 0.042 (0.040)	Data 0.035 (0.033)	Loss 0.3914 (0.4299)	Prec@1 86.000 (85.251)
 * Training Prec@1 85.192
Test: [0/50]	Time 0.130 (0.130)	Loss 0.5597 (0.5597)	Prec@1 82.000 (82.000)
 * Testing Prec@1 82.840
Epoch: [47/80][0/250]	LR: 0.010000000000000002	Time 0.250 (0.250)	Data 0.233 (0.233)	Loss 0.4592 (0.4592)	Prec@1 85.500 (85.500)
Epoch: [47/80][100/250]	LR: 0.010000000000000002	Time 0.047 (0.041)	Data 0.042 (0.035)	Loss 0.3924 (0.4249)	Prec@1 89.500 (85.391)
Epoch: [47/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.042)	Data 0.031 (0.036)	Loss 0.4331 (0.4273)	Prec@1 84.000 (85.224)
 * Training Prec@1 85.198
Test: [0/50]	Time 0.130 (0.130)	Loss 0.5752 (0.5752)	Prec@1 80.000 (80.000)
 * Testing Prec@1 82.930
Epoch: [48/80][0/250]	LR: 0.010000000000000002	Time 0.223 (0.223)	Data 0.207 (0.207)	Loss 0.3425 (0.3425)	Prec@1 87.500 (87.500)
Epoch: [48/80][100/250]	LR: 0.010000000000000002	Time 0.036 (0.042)	Data 0.031 (0.035)	Loss 0.3842 (0.4186)	Prec@1 86.500 (85.693)
Epoch: [48/80][200/250]	LR: 0.010000000000000002	Time 0.046 (0.040)	Data 0.041 (0.034)	Loss 0.3333 (0.4201)	Prec@1 91.000 (85.724)
 * Training Prec@1 85.570
Test: [0/50]	Time 0.148 (0.148)	Loss 0.5411 (0.5411)	Prec@1 82.000 (82.000)
 * Testing Prec@1 83.330
Epoch: [49/80][0/250]	LR: 0.010000000000000002	Time 0.210 (0.210)	Data 0.196 (0.196)	Loss 0.3625 (0.3625)	Prec@1 86.500 (86.500)
Epoch: [49/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.045)	Data 0.030 (0.038)	Loss 0.4366 (0.4155)	Prec@1 84.500 (85.738)
Epoch: [49/80][200/250]	LR: 0.010000000000000002	Time 0.041 (0.045)	Data 0.034 (0.038)	Loss 0.4159 (0.4188)	Prec@1 85.500 (85.664)
 * Training Prec@1 85.572
Test: [0/50]	Time 0.144 (0.144)	Loss 0.5588 (0.5588)	Prec@1 84.000 (84.000)
 * Testing Prec@1 83.370
Epoch: [50/80][0/250]	LR: 0.010000000000000002	Time 0.222 (0.222)	Data 0.208 (0.208)	Loss 0.3467 (0.3467)	Prec@1 88.500 (88.500)
Epoch: [50/80][100/250]	LR: 0.010000000000000002	Time 0.047 (0.042)	Data 0.041 (0.036)	Loss 0.3305 (0.4162)	Prec@1 86.500 (85.678)
Epoch: [50/80][200/250]	LR: 0.010000000000000002	Time 0.041 (0.041)	Data 0.034 (0.034)	Loss 0.4200 (0.4184)	Prec@1 86.000 (85.687)
 * Training Prec@1 85.700
Test: [0/50]	Time 0.143 (0.143)	Loss 0.5503 (0.5503)	Prec@1 85.000 (85.000)
 * Testing Prec@1 83.330
Epoch: [51/80][0/250]	LR: 0.010000000000000002	Time 0.215 (0.215)	Data 0.199 (0.199)	Loss 0.3558 (0.3558)	Prec@1 88.500 (88.500)
Epoch: [51/80][100/250]	LR: 0.010000000000000002	Time 0.038 (0.043)	Data 0.032 (0.037)	Loss 0.3668 (0.4148)	Prec@1 84.000 (85.708)
Epoch: [51/80][200/250]	LR: 0.010000000000000002	Time 0.048 (0.042)	Data 0.041 (0.036)	Loss 0.3993 (0.4141)	Prec@1 89.000 (85.711)
 * Training Prec@1 85.692
Test: [0/50]	Time 0.142 (0.142)	Loss 0.5328 (0.5328)	Prec@1 84.500 (84.500)
 * Testing Prec@1 83.590
Epoch: [52/80][0/250]	LR: 0.010000000000000002	Time 0.224 (0.224)	Data 0.206 (0.206)	Loss 0.4082 (0.4082)	Prec@1 86.500 (86.500)
Epoch: [52/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.041)	Data 0.031 (0.034)	Loss 0.3633 (0.4001)	Prec@1 89.500 (86.307)
Epoch: [52/80][200/250]	LR: 0.010000000000000002	Time 0.038 (0.040)	Data 0.032 (0.033)	Loss 0.3407 (0.4086)	Prec@1 89.500 (85.995)
 * Training Prec@1 85.916
Test: [0/50]	Time 0.148 (0.148)	Loss 0.5438 (0.5438)	Prec@1 82.000 (82.000)
 * Testing Prec@1 83.220
Epoch: [53/80][0/250]	LR: 0.010000000000000002	Time 0.142 (0.142)	Data 0.125 (0.125)	Loss 0.3565 (0.3565)	Prec@1 86.500 (86.500)
Epoch: [53/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.044)	Data 0.031 (0.037)	Loss 0.3747 (0.4032)	Prec@1 89.500 (86.332)
Epoch: [53/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.045)	Data 0.029 (0.038)	Loss 0.4843 (0.4077)	Prec@1 86.500 (86.087)
 * Training Prec@1 86.140
Test: [0/50]	Time 0.102 (0.102)	Loss 0.5666 (0.5666)	Prec@1 81.000 (81.000)
 * Testing Prec@1 83.190
Epoch: [54/80][0/250]	LR: 0.010000000000000002	Time 0.142 (0.142)	Data 0.124 (0.124)	Loss 0.3867 (0.3867)	Prec@1 83.500 (83.500)
Epoch: [54/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.042)	Data 0.032 (0.035)	Loss 0.3944 (0.4060)	Prec@1 84.500 (86.020)
Epoch: [54/80][200/250]	LR: 0.010000000000000002	Time 0.049 (0.042)	Data 0.043 (0.035)	Loss 0.3958 (0.4035)	Prec@1 86.500 (86.117)
 * Training Prec@1 86.122
Test: [0/50]	Time 0.130 (0.130)	Loss 0.5352 (0.5352)	Prec@1 83.500 (83.500)
 * Testing Prec@1 83.490
Epoch: [55/80][0/250]	LR: 0.010000000000000002	Time 0.189 (0.189)	Data 0.173 (0.173)	Loss 0.5164 (0.5164)	Prec@1 85.500 (85.500)
Epoch: [55/80][100/250]	LR: 0.010000000000000002	Time 0.036 (0.038)	Data 0.030 (0.032)	Loss 0.4069 (0.4127)	Prec@1 84.500 (85.698)
Epoch: [55/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.039)	Data 0.029 (0.032)	Loss 0.4730 (0.4095)	Prec@1 83.500 (85.896)
 * Training Prec@1 85.986
Test: [0/50]	Time 0.125 (0.125)	Loss 0.5304 (0.5304)	Prec@1 83.500 (83.500)
 * Testing Prec@1 83.280
Epoch: [56/80][0/250]	LR: 0.010000000000000002	Time 0.144 (0.144)	Data 0.129 (0.129)	Loss 0.4012 (0.4012)	Prec@1 87.000 (87.000)
Epoch: [56/80][100/250]	LR: 0.010000000000000002	Time 0.039 (0.041)	Data 0.030 (0.034)	Loss 0.4047 (0.4021)	Prec@1 86.000 (86.173)
Epoch: [56/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.040)	Data 0.030 (0.034)	Loss 0.3999 (0.4032)	Prec@1 89.000 (86.279)
 * Training Prec@1 86.290
Test: [0/50]	Time 0.123 (0.123)	Loss 0.5328 (0.5328)	Prec@1 83.500 (83.500)
 * Testing Prec@1 83.640
Epoch: [57/80][0/250]	LR: 0.010000000000000002	Time 0.215 (0.215)	Data 0.198 (0.198)	Loss 0.3763 (0.3763)	Prec@1 85.500 (85.500)
Epoch: [57/80][100/250]	LR: 0.010000000000000002	Time 0.038 (0.046)	Data 0.032 (0.038)	Loss 0.3737 (0.4012)	Prec@1 86.500 (86.297)
Epoch: [57/80][200/250]	LR: 0.010000000000000002	Time 0.049 (0.045)	Data 0.042 (0.038)	Loss 0.3999 (0.3975)	Prec@1 84.500 (86.495)
 * Training Prec@1 86.522
Test: [0/50]	Time 0.136 (0.136)	Loss 0.5256 (0.5256)	Prec@1 83.000 (83.000)
 * Testing Prec@1 83.320
Epoch: [58/80][0/250]	LR: 0.010000000000000002	Time 0.147 (0.147)	Data 0.132 (0.132)	Loss 0.4061 (0.4061)	Prec@1 85.500 (85.500)
Epoch: [58/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.042)	Data 0.031 (0.035)	Loss 0.4249 (0.3910)	Prec@1 85.500 (86.460)
Epoch: [58/80][200/250]	LR: 0.010000000000000002	Time 0.037 (0.039)	Data 0.031 (0.033)	Loss 0.4213 (0.3991)	Prec@1 84.500 (86.080)
 * Training Prec@1 86.166
Test: [0/50]	Time 0.134 (0.134)	Loss 0.5459 (0.5459)	Prec@1 83.500 (83.500)
 * Testing Prec@1 83.690
Epoch: [59/80][0/250]	LR: 0.010000000000000002	Time 0.137 (0.137)	Data 0.120 (0.120)	Loss 0.3948 (0.3948)	Prec@1 86.000 (86.000)
Epoch: [59/80][100/250]	LR: 0.010000000000000002	Time 0.037 (0.041)	Data 0.031 (0.034)	Loss 0.3909 (0.3977)	Prec@1 89.000 (86.342)
Epoch: [59/80][200/250]	LR: 0.010000000000000002	Time 0.036 (0.039)	Data 0.031 (0.032)	Loss 0.4943 (0.3975)	Prec@1 86.000 (86.443)
 * Training Prec@1 86.424
Test: [0/50]	Time 0.131 (0.131)	Loss 0.5190 (0.5190)	Prec@1 83.500 (83.500)
 * Testing Prec@1 83.680
Epoch: [60/80][0/250]	LR: 0.0010000000000000002	Time 0.148 (0.148)	Data 0.131 (0.131)	Loss 0.3998 (0.3998)	Prec@1 86.000 (86.000)
Epoch: [60/80][100/250]	LR: 0.0010000000000000002	Time 0.037 (0.043)	Data 0.030 (0.036)	Loss 0.3993 (0.3878)	Prec@1 88.000 (86.688)
Epoch: [60/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.040)	Data 0.031 (0.033)	Loss 0.5018 (0.3833)	Prec@1 83.000 (86.734)
 * Training Prec@1 86.724
Test: [0/50]	Time 0.143 (0.143)	Loss 0.5204 (0.5204)	Prec@1 85.000 (85.000)
 * Testing Prec@1 84.270
Epoch: [61/80][0/250]	LR: 0.0010000000000000002	Time 0.191 (0.191)	Data 0.173 (0.173)	Loss 0.4719 (0.4719)	Prec@1 82.500 (82.500)
Epoch: [61/80][100/250]	LR: 0.0010000000000000002	Time 0.046 (0.038)	Data 0.039 (0.032)	Loss 0.3116 (0.3706)	Prec@1 90.000 (87.267)
Epoch: [61/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.039)	Data 0.030 (0.032)	Loss 0.4416 (0.3759)	Prec@1 87.000 (87.216)
 * Training Prec@1 87.190
Test: [0/50]	Time 0.131 (0.131)	Loss 0.5121 (0.5121)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.330
Epoch: [62/80][0/250]	LR: 0.0010000000000000002	Time 0.226 (0.226)	Data 0.210 (0.210)	Loss 0.2870 (0.2870)	Prec@1 89.500 (89.500)
Epoch: [62/80][100/250]	LR: 0.0010000000000000002	Time 0.036 (0.040)	Data 0.030 (0.033)	Loss 0.3838 (0.3675)	Prec@1 87.500 (87.277)
Epoch: [62/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.039)	Data 0.030 (0.032)	Loss 0.3527 (0.3758)	Prec@1 83.500 (86.900)
 * Training Prec@1 87.012
Test: [0/50]	Time 0.142 (0.142)	Loss 0.5167 (0.5167)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.250
Epoch: [63/80][0/250]	LR: 0.0010000000000000002	Time 0.216 (0.216)	Data 0.198 (0.198)	Loss 0.3662 (0.3662)	Prec@1 90.500 (90.500)
Epoch: [63/80][100/250]	LR: 0.0010000000000000002	Time 0.046 (0.039)	Data 0.039 (0.032)	Loss 0.4265 (0.3815)	Prec@1 84.500 (86.827)
Epoch: [63/80][200/250]	LR: 0.0010000000000000002	Time 0.038 (0.039)	Data 0.031 (0.032)	Loss 0.3567 (0.3772)	Prec@1 87.000 (87.107)
 * Training Prec@1 87.108
Test: [0/50]	Time 0.138 (0.138)	Loss 0.5123 (0.5123)	Prec@1 85.000 (85.000)
 * Testing Prec@1 84.270
Epoch: [64/80][0/250]	LR: 0.0010000000000000002	Time 0.132 (0.132)	Data 0.117 (0.117)	Loss 0.5466 (0.5466)	Prec@1 83.500 (83.500)
Epoch: [64/80][100/250]	LR: 0.0010000000000000002	Time 0.045 (0.038)	Data 0.038 (0.031)	Loss 0.4603 (0.3783)	Prec@1 85.000 (87.074)
Epoch: [64/80][200/250]	LR: 0.0010000000000000002	Time 0.038 (0.042)	Data 0.031 (0.035)	Loss 0.4007 (0.3752)	Prec@1 85.500 (87.035)
 * Training Prec@1 87.042
Test: [0/50]	Time 0.147 (0.147)	Loss 0.5088 (0.5088)	Prec@1 85.000 (85.000)
 * Testing Prec@1 84.360
Epoch: [65/80][0/250]	LR: 0.0010000000000000002	Time 0.140 (0.140)	Data 0.123 (0.123)	Loss 0.3152 (0.3152)	Prec@1 87.500 (87.500)
Epoch: [65/80][100/250]	LR: 0.0010000000000000002	Time 0.034 (0.038)	Data 0.028 (0.031)	Loss 0.3378 (0.3753)	Prec@1 88.500 (87.243)
Epoch: [65/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.040)	Data 0.030 (0.033)	Loss 0.3849 (0.3717)	Prec@1 90.000 (87.296)
 * Training Prec@1 87.200
Test: [0/50]	Time 0.145 (0.145)	Loss 0.5144 (0.5144)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.250
Epoch: [66/80][0/250]	LR: 0.0010000000000000002	Time 0.108 (0.108)	Data 0.094 (0.094)	Loss 0.4258 (0.4258)	Prec@1 87.500 (87.500)
Epoch: [66/80][100/250]	LR: 0.0010000000000000002	Time 0.038 (0.042)	Data 0.029 (0.035)	Loss 0.4000 (0.3724)	Prec@1 88.000 (87.119)
Epoch: [66/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.042)	Data 0.031 (0.035)	Loss 0.4586 (0.3738)	Prec@1 83.500 (87.092)
 * Training Prec@1 87.058
Test: [0/50]	Time 0.145 (0.145)	Loss 0.5166 (0.5166)	Prec@1 85.000 (85.000)
 * Testing Prec@1 84.350
Epoch: [67/80][0/250]	LR: 0.0010000000000000002	Time 0.230 (0.230)	Data 0.213 (0.213)	Loss 0.3270 (0.3270)	Prec@1 91.000 (91.000)
Epoch: [67/80][100/250]	LR: 0.0010000000000000002	Time 0.070 (0.044)	Data 0.063 (0.037)	Loss 0.3661 (0.3645)	Prec@1 87.500 (87.455)
Epoch: [67/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.042)	Data 0.032 (0.036)	Loss 0.4521 (0.3716)	Prec@1 86.000 (87.246)
 * Training Prec@1 87.308
Test: [0/50]	Time 0.130 (0.130)	Loss 0.5196 (0.5196)	Prec@1 85.000 (85.000)
 * Testing Prec@1 84.350
Epoch: [68/80][0/250]	LR: 0.0010000000000000002	Time 0.217 (0.217)	Data 0.200 (0.200)	Loss 0.4153 (0.4153)	Prec@1 86.500 (86.500)
Epoch: [68/80][100/250]	LR: 0.0010000000000000002	Time 0.038 (0.040)	Data 0.031 (0.033)	Loss 0.4214 (0.3677)	Prec@1 87.000 (87.505)
Epoch: [68/80][200/250]	LR: 0.0010000000000000002	Time 0.039 (0.039)	Data 0.033 (0.033)	Loss 0.3303 (0.3662)	Prec@1 91.500 (87.473)
 * Training Prec@1 87.386
Test: [0/50]	Time 0.142 (0.142)	Loss 0.5161 (0.5161)	Prec@1 85.000 (85.000)
 * Testing Prec@1 84.340
Epoch: [69/80][0/250]	LR: 0.0010000000000000002	Time 0.145 (0.145)	Data 0.129 (0.129)	Loss 0.3565 (0.3565)	Prec@1 88.500 (88.500)
Epoch: [69/80][100/250]	LR: 0.0010000000000000002	Time 0.049 (0.040)	Data 0.042 (0.033)	Loss 0.3153 (0.3716)	Prec@1 90.000 (87.257)
Epoch: [69/80][200/250]	LR: 0.0010000000000000002	Time 0.060 (0.042)	Data 0.053 (0.036)	Loss 0.4285 (0.3685)	Prec@1 88.000 (87.478)
 * Training Prec@1 87.300
Test: [0/50]	Time 0.137 (0.137)	Loss 0.5125 (0.5125)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.340
Epoch: [70/80][0/250]	LR: 0.0010000000000000002	Time 0.139 (0.139)	Data 0.124 (0.124)	Loss 0.4301 (0.4301)	Prec@1 87.000 (87.000)
Epoch: [70/80][100/250]	LR: 0.0010000000000000002	Time 0.036 (0.042)	Data 0.030 (0.035)	Loss 0.2793 (0.3713)	Prec@1 89.500 (87.371)
Epoch: [70/80][200/250]	LR: 0.0010000000000000002	Time 0.038 (0.043)	Data 0.031 (0.036)	Loss 0.3944 (0.3732)	Prec@1 85.500 (87.177)
 * Training Prec@1 87.132
Test: [0/50]	Time 0.135 (0.135)	Loss 0.5190 (0.5190)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.420
Epoch: [71/80][0/250]	LR: 0.0010000000000000002	Time 0.206 (0.206)	Data 0.191 (0.191)	Loss 0.4113 (0.4113)	Prec@1 87.500 (87.500)
Epoch: [71/80][100/250]	LR: 0.0010000000000000002	Time 0.050 (0.048)	Data 0.043 (0.040)	Loss 0.4613 (0.3732)	Prec@1 86.000 (87.287)
Epoch: [71/80][200/250]	LR: 0.0010000000000000002	Time 0.036 (0.043)	Data 0.029 (0.036)	Loss 0.3731 (0.3700)	Prec@1 86.000 (87.485)
 * Training Prec@1 87.364
Test: [0/50]	Time 0.138 (0.138)	Loss 0.5078 (0.5078)	Prec@1 85.500 (85.500)
 * Testing Prec@1 84.460
Epoch: [72/80][0/250]	LR: 0.0010000000000000002	Time 0.188 (0.188)	Data 0.173 (0.173)	Loss 0.2946 (0.2946)	Prec@1 89.000 (89.000)
Epoch: [72/80][100/250]	LR: 0.0010000000000000002	Time 0.049 (0.045)	Data 0.042 (0.038)	Loss 0.3387 (0.3700)	Prec@1 86.000 (87.287)
Epoch: [72/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.045)	Data 0.031 (0.038)	Loss 0.2800 (0.3706)	Prec@1 91.000 (87.187)
 * Training Prec@1 87.180
Test: [0/50]	Time 0.148 (0.148)	Loss 0.5104 (0.5104)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.180
Epoch: [73/80][0/250]	LR: 0.0010000000000000002	Time 0.106 (0.106)	Data 0.092 (0.092)	Loss 0.3847 (0.3847)	Prec@1 86.500 (86.500)
Epoch: [73/80][100/250]	LR: 0.0010000000000000002	Time 0.052 (0.045)	Data 0.045 (0.038)	Loss 0.3322 (0.3689)	Prec@1 88.000 (87.005)
Epoch: [73/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.042)	Data 0.030 (0.035)	Loss 0.3731 (0.3690)	Prec@1 87.500 (87.179)
 * Training Prec@1 87.140
Test: [0/50]	Time 0.139 (0.139)	Loss 0.5101 (0.5101)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.350
Epoch: [74/80][0/250]	LR: 0.0010000000000000002	Time 0.130 (0.130)	Data 0.114 (0.114)	Loss 0.3887 (0.3887)	Prec@1 85.500 (85.500)
Epoch: [74/80][100/250]	LR: 0.0010000000000000002	Time 0.040 (0.042)	Data 0.031 (0.035)	Loss 0.4234 (0.3685)	Prec@1 84.000 (87.490)
Epoch: [74/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.040)	Data 0.031 (0.033)	Loss 0.3841 (0.3677)	Prec@1 89.500 (87.343)
 * Training Prec@1 87.292
Test: [0/50]	Time 0.133 (0.133)	Loss 0.5125 (0.5125)	Prec@1 85.000 (85.000)
 * Testing Prec@1 84.320
Epoch: [75/80][0/250]	LR: 0.0010000000000000002	Time 0.224 (0.224)	Data 0.206 (0.206)	Loss 0.3642 (0.3642)	Prec@1 88.500 (88.500)
Epoch: [75/80][100/250]	LR: 0.0010000000000000002	Time 0.036 (0.044)	Data 0.030 (0.037)	Loss 0.3182 (0.3688)	Prec@1 88.500 (87.411)
Epoch: [75/80][200/250]	LR: 0.0010000000000000002	Time 0.051 (0.045)	Data 0.044 (0.038)	Loss 0.2741 (0.3717)	Prec@1 89.500 (87.169)
 * Training Prec@1 87.168
Test: [0/50]	Time 0.133 (0.133)	Loss 0.5119 (0.5119)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.300
Epoch: [76/80][0/250]	LR: 0.0010000000000000002	Time 0.140 (0.140)	Data 0.125 (0.125)	Loss 0.3855 (0.3855)	Prec@1 88.500 (88.500)
Epoch: [76/80][100/250]	LR: 0.0010000000000000002	Time 0.038 (0.042)	Data 0.032 (0.035)	Loss 0.2945 (0.3621)	Prec@1 90.500 (87.292)
Epoch: [76/80][200/250]	LR: 0.0010000000000000002	Time 0.053 (0.041)	Data 0.046 (0.035)	Loss 0.2855 (0.3674)	Prec@1 91.500 (87.219)
 * Training Prec@1 87.138
Test: [0/50]	Time 0.118 (0.118)	Loss 0.5113 (0.5113)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.200
Epoch: [77/80][0/250]	LR: 0.0010000000000000002	Time 0.154 (0.154)	Data 0.139 (0.139)	Loss 0.1814 (0.1814)	Prec@1 95.500 (95.500)
Epoch: [77/80][100/250]	LR: 0.0010000000000000002	Time 0.038 (0.041)	Data 0.031 (0.035)	Loss 0.3093 (0.3659)	Prec@1 89.500 (87.554)
Epoch: [77/80][200/250]	LR: 0.0010000000000000002	Time 0.038 (0.040)	Data 0.033 (0.034)	Loss 0.3508 (0.3660)	Prec@1 87.000 (87.597)
 * Training Prec@1 87.582
Test: [0/50]	Time 0.141 (0.141)	Loss 0.5091 (0.5091)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.520
Epoch: [78/80][0/250]	LR: 0.0010000000000000002	Time 0.236 (0.236)	Data 0.218 (0.218)	Loss 0.4521 (0.4521)	Prec@1 84.000 (84.000)
Epoch: [78/80][100/250]	LR: 0.0010000000000000002	Time 0.038 (0.041)	Data 0.032 (0.034)	Loss 0.4362 (0.3605)	Prec@1 85.500 (87.183)
Epoch: [78/80][200/250]	LR: 0.0010000000000000002	Time 0.037 (0.041)	Data 0.032 (0.034)	Loss 0.4038 (0.3691)	Prec@1 87.500 (87.197)
 * Training Prec@1 87.218
Test: [0/50]	Time 0.106 (0.106)	Loss 0.5068 (0.5068)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.400
Epoch: [79/80][0/250]	LR: 0.0010000000000000002	Time 0.228 (0.228)	Data 0.211 (0.211)	Loss 0.4269 (0.4269)	Prec@1 86.500 (86.500)
Epoch: [79/80][100/250]	LR: 0.0010000000000000002	Time 0.041 (0.044)	Data 0.035 (0.037)	Loss 0.3720 (0.3763)	Prec@1 88.500 (87.050)
Epoch: [79/80][200/250]	LR: 0.0010000000000000002	Time 0.038 (0.041)	Data 0.031 (0.035)	Loss 0.4513 (0.3716)	Prec@1 83.500 (87.306)
 * Training Prec@1 87.324
Test: [0/50]	Time 0.146 (0.146)	Loss 0.5050 (0.5050)	Prec@1 84.500 (84.500)
 * Testing Prec@1 84.300
